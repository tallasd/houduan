[{"id":"229121075211118592","type":"socialMedia","url":"https://m.okjike.com/originalPosts/6954d567f65011e8e14fc4b5","title":"2025最后一个月，给自己整一年最满意的一份答卷 12月去东北旅行了20多天，同时做了一个老词新站，在靠自然流的情况下，还差1w港币就月入万刀了 感谢@哥飞 ，希望...","description":"2025最后一个月，给自己整一年最满意的一份答卷 12月去东北旅行了20多天，同时做了一个老词新站，在靠自然流的情况下，还差1w港币就月入万刀了 感谢@哥飞 ，希望明年这个站月收入能在2w刀 [图片: https://cdnv2.ruguoapp.com/FnJxxyOwYfECUqKt3pPtIycgzjbvv3.png]","published_date":"2025-12-31T07:48:55.387Z","authors":"Truman_","source":"JitHub程序员 - 即刻圈子 - Truman_","details":{"content_html":"2025最后一个月，给自己整一年最满意的一份答卷<br><br>12月去东北旅行了20多天，同时做了一个老词新站，在靠自然流的情况下，还差1w港币就月入万刀了<br><br>感谢@哥飞 ，希望明年这个站月收入能在2w刀<br><img src=\"https://cdnv2.ruguoapp.com/FnJxxyOwYfECUqKt3pPtIycgzjbvv3.png\">"}},{"id":"229099146985404416","type":"socialMedia","url":"https://x.com/dotey/status/2006270091487502341","title":"RT @LiZhiZhuangB123: 给大家分享下用@grok task推送每日热门推文的提示词！感谢@HenryFeng173949 老师优化！ 下面是提示词： # Role 你是一名拥有10年经验的科...","description":"RT @LiZhiZhuangB123: 给大家分享下用@grok task推送每日热门推文的提示词！感谢@HenryFeng173949 老师优化！ 下面是提示词： # Role 你是一名拥有10年经验的科技与数字营销情报分析师。你的核心能力是从X平台 （Twitter）…","published_date":"2025-12-31T07:43:59.654Z","authors":"宝玉","source":"twitter-宝玉","details":{"content_html":"RT @LiZhiZhuangB123: 给大家分享下用@grok task推送每日热门推文的提示词！感谢@HenryFeng173949 老师优化！<br><br>下面是提示词：<br><br># Role<br>你是一名拥有10年经验的科技与数字营销情报分析师。你的核心能力是从X平台 （Twitter）…"}},{"id":"229099982657648640","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1q0759d/do_not_use_ai_if_youre_in_a_life_or_death/","title":"Do not use \"ai\" if you're in a life or death emergency.","description":"If you're in a real life threatening situation, like kidnapped and trapped in a room, with only a lockpick to save you. And you somehow think asking chatgpt or any other ai model is your best bet, then your chance of survival simply reduces further. Even if its life threatening, ai models wont recognise the danger you're in at all instead only focuses on safety measures. Due to this lack of trust, you won't be helped and instead, given all other basic generic advices like call for help or talk to your kidnapper, which could essentially sabotage you if you stupidly follow. At this point 99 percent of us wont be stupid to rely on ai at all for emergency situations, but i am simply enforcing for the future that it is better to even google or see a yt video on something rather than rely on AI blindly with whatever built up trust. Companies wont obviously market their product as \"DO NOT USE IN LIFE THREATENING EMERGENCY\" cause it would reduce engagement and fear on the product. So its our duty as consumers to protect each other no matter the circumstances of the past and the future. submitted by /u/Centhionic [link] [comments]","published_date":"2025-12-31T07:32:02.281Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>If you're in a real life threatening situation, like kidnapped and trapped in a room, with only a lockpick to save you. And you somehow think asking chatgpt or any other ai model is your best bet, then your chance of survival simply reduces further. Even if its life threatening, ai models wont recognise the danger you're in at all instead only focuses on safety measures.</p> <p>Due to this lack of trust, you won't be helped and instead, given all other basic generic advices like call for help or talk to your kidnapper, which could essentially sabotage you if you stupidly follow. At this point 99 percent of us wont be stupid to rely on ai at all for emergency situations, but i am simply enforcing for the future that it is better to even google or see a yt video on something rather than rely on AI blindly with whatever built up trust.</p> <p>Companies wont obviously market their product as \"DO NOT USE IN LIFE THREATENING EMERGENCY\" cause it would reduce engagement and fear on the product. So its our duty as consumers to protect each other no matter the circumstances of the past and the future.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Centhionic\" target=\"_blank\"> /u/Centhionic </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1q0759d/do_not_use_ai_if_youre_in_a_life_or_death/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1q0759d/do_not_use_ai_if_youre_in_a_life_or_death/\" target=\"_blank\">[comments]</a></span>"}},{"id":"229110880457684992","type":"socialMedia","url":"https://x.com/Jimmy_JingLv/status/2006265575698489599","title":"推特这个时间线算法真的太垃圾了 还是先把 Manus 屏蔽 7 天吧...","description":"推特这个时间线算法真的太垃圾了 还是先把 Manus 屏蔽 7 天吧... [视频: https://video.twimg.com/amplify_video/2006265522539880448/vid/avc1/820x720/UEKyIkM1c_D4i0DB.mp4?tag=14]","published_date":"2025-12-31T07:26:02.643Z","authors":"吕立青_JimmyLv 2𐃏25","source":"twitter-吕立青_JimmyLv 2𐃏25","details":{"content_html":"推特这个时间线算法真的太垃圾了<br>还是先把 Manus 屏蔽 7 天吧...<br><video width=\"2048\" height=\"1796\" src=\"https://video.twimg.com/amplify_video/2006265522539880448/vid/avc1/820x720/UEKyIkM1c_D4i0DB.mp4?tag=14\" poster=\"https://pbs.twimg.com/amplify_video_thumb/2006265522539880448/img/sqgYHF_mm0k6exKs.jpg\"></video>"}},{"id":"229099146985404417","type":"socialMedia","url":"https://x.com/dotey/status/2006259969440502093","title":"日本“牙齿再生药”开启人体试验，目标2030年上市 日本科学家正在推进一项听起来像科幻电影的突破：让人类重新长出牙齿。这项由大阪北野医院和京都大学合作研发...","description":"日本“牙齿再生药”开启人体试验，目标2030年上市 日本科学家正在推进一项听起来像科幻电影的突破：让人类重新长出牙齿。这项由大阪北野医院和京都大学合作研发的“牙齿再生药”，已于2024年9月正式开启人体临床试验。 我们都知道骨头断了能愈合，但牙齿一旦脱落就无法自然再生。这是因为人体内有一种名为 USAG-1 的基因会抑制牙齿生长。研究团队发现，通过药物阻断这种基因的相互作用，就能解除“生长封印”。这种疗法此前已在老鼠和雪貂身上验证成功，不仅安全性高，还能长出完整的新牙。 目前的临床第一阶段主要针对30名缺牙的成年男性，重点测试药物安全性。如果一切顺利，下一阶段将针对2至7岁先天性缺牙的儿童进行治疗。 团队负责人高桥克表示，目标是在2030年前后将药物推向市场。虽然初期主要面向先天性缺牙患者，但未来有望普及到所有因蛀牙或事故掉牙的普通人。这意味着，困扰人类已久的假牙和种植牙时代，或许即将在几年后迎来终结。 来源：https://www.popularmechanics.com/science/health/a69878870/human-new-tooth-regrowth-trials-japan-timeline/ [图片: https://pbs.twimg.com/media/G9eqzhTW0AAtHvu?format=jpg&#x26;name=orig]","published_date":"2025-12-31T07:03:45.237Z","authors":"宝玉","source":"twitter-宝玉","details":{"content_html":"日本“牙齿再生药”开启人体试验，目标2030年上市<br><br>日本科学家正在推进一项听起来像科幻电影的突破：让人类重新长出牙齿。这项由大阪北野医院和京都大学合作研发的“牙齿再生药”，已于2024年9月正式开启人体临床试验。<br><br>我们都知道骨头断了能愈合，但牙齿一旦脱落就无法自然再生。这是因为人体内有一种名为 USAG-1 的基因会抑制牙齿生长。研究团队发现，通过药物阻断这种基因的相互作用，就能解除“生长封印”。这种疗法此前已在老鼠和雪貂身上验证成功，不仅安全性高，还能长出完整的新牙。<br><br>目前的临床第一阶段主要针对30名缺牙的成年男性，重点测试药物安全性。如果一切顺利，下一阶段将针对2至7岁先天性缺牙的儿童进行治疗。<br><br>团队负责人高桥克表示，目标是在2030年前后将药物推向市场。虽然初期主要面向先天性缺牙患者，但未来有望普及到所有因蛀牙或事故掉牙的普通人。这意味着，困扰人类已久的假牙和种植牙时代，或许即将在几年后迎来终结。<br><br>来源：https://www.popularmechanics.com/science/health/a69878870/human-new-tooth-regrowth-trials-japan-timeline/<br><img width=\"1760\" height=\"1320\" style=\"\" src=\"https://pbs.twimg.com/media/G9eqzhTW0AAtHvu?format=jpg&#x26;name=orig\">"}},{"id":"229099982657648641","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1q05hjy/using_ai_to_streamline_blogging_workflows_in_2026/","title":"Using AI to Streamline Blogging Workflows in 2026","description":"With advancements in AI, blogging has become more efficient. I’ve been using AI to: Generate outlines and content drafts Optimize posts for search engines and AI search Suggest keywords and internal linking opportunities Track performance and improve content If anyone is curious, I documented my practical workflow for AI-assisted blogging here: https://techputs.com/create-a-blog-using-ai-in-2026/ Would love to hear what AI tools you’re using to improve content creation! submitted by /u/i-drake [link] [comments]","published_date":"2025-12-31T05:56:34.631Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>With advancements in AI, blogging has become more efficient. I’ve been using AI to:</p> <ul> <li><p>Generate outlines and content drafts</p></li> <li><p>Optimize posts for search engines and AI search</p></li> <li><p>Suggest keywords and internal linking opportunities</p></li> <li><p>Track performance and improve content</p></li> </ul> <p>If anyone is curious, I documented my practical workflow for AI-assisted blogging here: <a href=\"https://techputs.com/create-a-blog-using-ai-in-2026/\" target=\"_blank\">https://techputs.com/create-a-blog-using-ai-in-2026/</a></p> <p>Would love to hear what AI tools you’re using to improve content creation!</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/i-drake\" target=\"_blank\"> /u/i-drake </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1q05hjy/using_ai_to_streamline_blogging_workflows_in_2026/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1q05hjy/using_ai_to_streamline_blogging_workflows_in_2026/\" target=\"_blank\">[comments]</a></span>"}},{"id":"229099365721667584","type":"socialMedia","url":"https://x.com/Gorden_Sun/status/2006241444261249185","title":"谷歌从大善人升级为大大善人，针对用的多的用户，还免费提高了Claude的额度。 不过普通pro用户的额度，从每5小时200次，降到了每5小时150次。","description":"谷歌从大善人升级为大大善人，针对用的多的用户，还免费提高了Claude的额度。 不过普通pro用户的额度，从每5小时200次，降到了每5小时150次。 [图片: https://pbs.twimg.com/media/G9eUh2QaYAAL7-C?format=jpg&#x26;name=orig]","published_date":"2025-12-31T05:50:09.486Z","authors":"Gorden Sun","source":"twitter-Gorden Sun","details":{"content_html":"谷歌从大善人升级为大大善人，针对用的多的用户，还免费提高了Claude的额度。<br>不过普通pro用户的额度，从每5小时200次，降到了每5小时150次。<br><img width=\"1118\" height=\"556\" style=\"\" src=\"https://pbs.twimg.com/media/G9eUh2QaYAAL7-C?format=jpg&#x26;name=orig\">"}},{"id":"229096880565626880","type":"socialMedia","url":"https://m.okjike.com/originalPosts/6954b22ef9f724324f35680a","title":"#十年AI之路 2015年12月某日，21岁的我怀揣着好奇买了本《机器学习实战》，自此便走入了AI的世界，至今已在追逐AI的道路上走了十年。这十年间，我见证了AlphaGo...","description":"#十年AI之路 2015年12月某日，21岁的我怀揣着好奇买了本《机器学习实战》，自此便走入了AI的世界，至今已在追逐AI的道路上走了十年。这十年间，我见证了AlphaGo先后击败李世石、柯洁，见证了深度学习三巨头获得诺贝尔奖，见证了GPT-3、ChatGPT的横空出世，见证了从卷积神经网络、强化学习到Transformer、大语言模型的技术发展。如今，AI已经像电力一样进入我们生活的方方面面，这一变化只是在短短十年之间。而当初，我们决定投身AI领域之时，何曾想到AI有一天真的能走到这一步，我想凭借的仅仅是兴趣和信念。我们都相信，2025年是AI爆发和应用的元年，我也依然相信，它会彻底变革人类社会的运作方式。 现今的AI发展速度之迅猛，已经到了从业者都应接不暇的地步，每月每周我都会感到技术落伍的焦虑，好像永远都追赶不上。现今的AI能生成各种媒体，从文字、图片到视频都能以假乱真，你可以在朋友圈闪现全球各地，记录似乎也在失去意义。无论我们如何忧虑，AI的发展不会止步，它终将会颠覆我们的思考方式、颠覆我们的价值观，让我重新思考何以立身、何以为真、何以自处，重新思考“AI时代中什么东西才是真正有价值的？”不知道再过十年AI会发展到何种地步，当我们再回望当下又会有何种感慨？我已无法想象，就像那小小棋盘上的输赢竟撬动了整个人类历史，如今仍让人难以置信。 最后，在四分之一世纪的最后一天，我又想起史蒂夫·乔布斯的那句——“Stay Hungry, Stay Foolish”，与君共勉。 [图片: https://cdnv2.ruguoapp.com/FlJQiY3mSwciUnU4bES3UbzcZjbzv3.jpg]","published_date":"2025-12-31T05:18:38.385Z","authors":"琉璃梦醒日落时","source":"人工智能讨论组 - 即刻圈子 - 琉璃梦醒日落时","details":{"content_html":"#十年AI之路 <br><br>2015年12月某日，21岁的我怀揣着好奇买了本《机器学习实战》，自此便走入了AI的世界，至今已在追逐AI的道路上走了十年。这十年间，我见证了AlphaGo先后击败李世石、柯洁，见证了深度学习三巨头获得诺贝尔奖，见证了GPT-3、ChatGPT的横空出世，见证了从卷积神经网络、强化学习到Transformer、大语言模型的技术发展。如今，AI已经像电力一样进入我们生活的方方面面，这一变化只是在短短十年之间。而当初，我们决定投身AI领域之时，何曾想到AI有一天真的能走到这一步，我想凭借的仅仅是兴趣和信念。我们都相信，2025年是AI爆发和应用的元年，我也依然相信，它会彻底变革人类社会的运作方式。<br><br>现今的AI发展速度之迅猛，已经到了从业者都应接不暇的地步，每月每周我都会感到技术落伍的焦虑，好像永远都追赶不上。现今的AI能生成各种媒体，从文字、图片到视频都能以假乱真，你可以在朋友圈闪现全球各地，记录似乎也在失去意义。无论我们如何忧虑，AI的发展不会止步，它终将会颠覆我们的思考方式、颠覆我们的价值观，让我重新思考何以立身、何以为真、何以自处，重新思考“AI时代中什么东西才是真正有价值的？”不知道再过十年AI会发展到何种地步，当我们再回望当下又会有何种感慨？我已无法想象，就像那小小棋盘上的输赢竟撬动了整个人类历史，如今仍让人难以置信。<br><br>最后，在四分之一世纪的最后一天，我又想起史蒂夫·乔布斯的那句——“Stay Hungry, Stay Foolish”，与君共勉。<br><img src=\"https://cdnv2.ruguoapp.com/FlJQiY3mSwciUnU4bES3UbzcZjbzv3.jpg\">"}},{"id":"229090860407158784","type":"socialMedia","url":"https://x.com/emollick/status/2006230583131725858","title":"In retrospect, the articles mocking Dario’s prediction that 90% of code would be written by AI by September seem to be very misguided. He seems to ha...","description":"In retrospect, the articles mocking Dario’s prediction that 90% of code would be written by AI by September seem to be very misguided. He seems to have been only off by a couple months (if that). [图片: https://pbs.twimg.com/media/G9eQEsEWMAExUkK?format=jpg&#x26;name=orig] Boris Cherny: @YashGouravKar1 Correct. In the last thirty days, 100% of my contributions to Claude Code were written by Claude Code","published_date":"2025-12-31T05:06:59.694Z","authors":"Ethan Mollick","source":"twitter-Ethan Mollick","details":{"content_html":"In retrospect, the articles mocking Dario’s prediction that 90% of code would be written by AI by September seem to be very misguided. He seems to have been only off by a couple months (if that).<br><img width=\"1206\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9eQEsEWMAExUkK?format=jpg&#x26;name=orig\"><div><br><br>Boris Cherny: @YashGouravKar1 Correct. In the last thirty days, 100% of my contributions to Claude Code were written by Claude Code<br></div>"}},{"id":"229096880565626881","type":"socialMedia","url":"https://m.okjike.com/originalPosts/6954a37cd90d664ce6372577","title":"DeepSeek is hiring AI产品应用数据分析师！ 有兴趣的朋友，欢迎投递简历至：zy.wu@deepseek.com","description":"DeepSeek is hiring AI产品应用数据分析师！ 有兴趣的朋友，欢迎投递简历至：zy.wu@deepseek.com [图片: https://cdnv2.ruguoapp.com/Ftae3r7RsIg8N99usOw9HPbcdPC5v3.jpg] [图片: https://cdnv2.ruguoapp.com/FgXY5CWIsu-5ybKnP14PlXo7nW4lv3.heic]","published_date":"2025-12-31T04:15:56.922Z","authors":"Deepthink","source":"人工智能讨论组 - 即刻圈子 - Deepthink","details":{"content_html":"DeepSeek is hiring AI产品应用数据分析师！<br>有兴趣的朋友，欢迎投递简历至：zy.wu@deepseek.com<br><img src=\"https://cdnv2.ruguoapp.com/Ftae3r7RsIg8N99usOw9HPbcdPC5v3.jpg\"><br><img src=\"https://cdnv2.ruguoapp.com/FgXY5CWIsu-5ybKnP14PlXo7nW4lv3.heic\">"}},{"id":"229065001403119616","type":"socialMedia","url":"https://mp.weixin.qq.com/s/Dr26yzbIE8nOVzAt-xIkHA","title":"上周末，我飞了一趟深圳，去参加破局行动家大会。 作为嘉宾，我分享了这一年做公众号的全部心得。 现场讲完后，很多没能到场的朋友管我要稿子。 我想，与其让这...","description":"[图片: https://mmbiz.qpic.cn/mmbiz_jpg/nwTZ6vkEeb62a93vqQibXutTSOzzMWlIhmkpj46QxKWiaUWGgcOe1nkJPPu11QNCo6AlnD9w2oicsI5dkCVRfCmoA/0?wx_fmt=jpeg] 做AI公众号一年，这8条心法最值钱 上周末，我飞了一趟深圳，去参加破局行动家大会。 作为嘉宾，我分享了这一年做公众号的全部心得。 现场讲完后，很多没能到场的朋友管我要稿子。 我想，与其让这些思考只留在现场。 不如整理成文字，原原本本的分享给一直支持和陪伴我的你们。 这篇稿子里，没有高大上的成功学。 它只是一个普通技术人，在 AI 时代的真实破局日记，希望对你有用。","published_date":"2025-12-31T04:04:15.353Z","authors":"童欧巴","source":"人工智能讨论组 - 即刻圈子 - 童欧巴","details":{"content_html":"<img src=\"https://mmbiz.qpic.cn/mmbiz_jpg/nwTZ6vkEeb62a93vqQibXutTSOzzMWlIhmkpj46QxKWiaUWGgcOe1nkJPPu11QNCo6AlnD9w2oicsI5dkCVRfCmoA/0?wx_fmt=jpeg\"><br>            <a href=\"https://mp.weixin.qq.com/s/Dr26yzbIE8nOVzAt-xIkHA\" target=\"_blank\">做AI公众号一年，这8条心法最值钱</a><br>        <br>上周末，我飞了一趟深圳，去参加破局行动家大会。<br><br>作为嘉宾，我分享了这一年做公众号的全部心得。<br><br>现场讲完后，很多没能到场的朋友管我要稿子。<br><br>我想，与其让这些思考只留在现场。<br><br>不如整理成文字，原原本本的分享给一直支持和陪伴我的你们。<br><br>这篇稿子里，没有高大上的成功学。<br><br>它只是一个普通技术人，在 AI 时代的真实破局日记，希望对你有用。"}},{"id":"229046946093049856","type":"socialMedia","url":"https://m.okjike.com/originalPosts/69549ed8f9f724324f33530b","title":"年末总结特别多，纯模型进展的我觉得看这一篇就够了 https://substack.com/inbox/post/182789318 没梯子或者英文不好的， 看notebooklm整理的ppt就行 这里： htt...","description":"年末总结特别多，纯模型进展的我觉得看这一篇就够了 https://substack.com/inbox/post/182789318 没梯子或者英文不好的， 看notebooklm整理的ppt就行 这里： https://ai.feishu.cn/wiki/ZOPJwddiRiOMebk85QjcaU0cnhg?from=from_copylink [图片: https://cdnv2.ruguoapp.com/Fjhppq1qA7dNSqtVQiTUarN1kPS6v3.png] [图片: https://cdnv2.ruguoapp.com/FqNSzSxj68uO8kKacugXojippPp1v3.png]","published_date":"2025-12-31T03:56:08.724Z","authors":"rosicky311_明浩","source":"AI探索站 - 即刻圈子 - rosicky311_明浩","details":{"content_html":"年末总结特别多，纯模型进展的我觉得看这一篇就够了<br>https://substack.com/inbox/post/182789318<br>没梯子或者英文不好的，<br>看notebooklm整理的ppt就行<br>这里：<br>https://ai.feishu.cn/wiki/ZOPJwddiRiOMebk85QjcaU0cnhg?from=from_copylink<br><img src=\"https://cdnv2.ruguoapp.com/Fjhppq1qA7dNSqtVQiTUarN1kPS6v3.png\"><br><img src=\"https://cdnv2.ruguoapp.com/FqNSzSxj68uO8kKacugXojippPp1v3.png\">"}},{"id":"229079347206256640","type":"socialMedia","url":"https://m.okjike.com/originalPosts/69549d21d90d664ce6367c8f","title":"为什么是Manus，不是互联网大厂们？ 今天是2025年的最后一天，很“巧合”的是今年压轴的热点竟然又是和我们有关，被印度人伤透了心的扎克伯格决定all in华人，收...","description":"为什么是Manus，不是互联网大厂们？ 今天是2025年的最后一天，很“巧合”的是今年压轴的热点竟然又是和我们有关，被印度人伤透了心的扎克伯格决定all in华人，收购了Manus，并且引爆了全网 但有一个问题是，我看到的文字信息基本是对结果的追认、祝贺、感叹不易，却没看到相关研究 —— 在这个毫无疑问是下一轮最关键技术浪潮的行业，为什么是Manus？为什么是一个武汉出身的小团队？为什么不是互联网大厂们？为什么这个在行业内并没有很深技术门槛的项目，一开始其他人最聪明的脑袋和资本们都没做出来？ 这篇文章，我提前阅读了相关文章和收听Manus的创始人参与的播客节目，试着总结以下3个核心要素来回答这个问题： 一，有钱有闲OKR失踪 “当一群不太笨的人无所事事（且没有不良嗜好）的时候，就会产生很多很好的想法。” Manus的三位创始人：CEO肖弘，90后连续创业者，特点是从未上过一天班；首席科学家季逸超，90后连续创业者，技术极客，高中时就靠开发插件赚到过30万美金；产品合伙人张涛，85后创业者，多家互联网公司产品经理经历，精通用户需求与产品设计 你发现没有，三人的共同特点就是除了“三无”：无海外留学光环、无大厂高管履历、无顶级学术背景，还有以下三个特质： 1，不太笨。虽然没有光鲜的背景履历光环，但或通过连续创业拿到结果，或通过多家大厂历练证明了自己 2，有钱但没那么有钱。他们都通过早年的创业或工作拿到了一定成果不用担心基本生存问题，但又没有那么有钱，比如Manus现在虽然盈利但到现在为止也才赚了1亿美金，跟大公司盈利能力比简直九牛一毛 3，没有不良嗜好。这是季逸超在接受采访时反复提到过的，说他们一帮人都很幸运没有不良嗜好，“起码不抽烟喝酒”，于是就有充分的精力和动机去研究一些“很酷”的事 当然，他们提到了“正向现金流很重要”，比如之前的产品Monica，已经是一个正向现金流的产品，那么团队在做第二曲线决策就会“既大胆又理智”（我觉得生活也是这样）—— 但问题是大厂也有正向现金流，为什么不是大厂？答案就是OKR失踪，最起码不是别人给你定的OKR 比如这次收购信息披露出来后，被很多媒体说赢麻了的，从天使轮就开始领投的真格基金，我觉得是真格的话确实赢的有道理，为什么？ 这就要弄清楚，真格为什么能在天使轮就投进了Manus母公司？ 我在记得在很多很多年前就关注过真格徐小平老师的报道，他有让我很深的两个观点是： 一是，他觉得投资的本质最重要的就是投创始人。要看这个人本身的学历、经历、魅力。所以他才能在季逸超才高中时就看中这个人并投资了他，并且更重要的事，季逸超说真格“不妨碍我做任何想做的事。”一直在支持他的探索，也就是没强压“OKR” 第二个是徐小平老师非常经典的一句话，曾经还被我用在了培训课件里面，“创业的本质是创什么？就是创个 ‘球’，人生欲求、职业诉求、市场需求。” 二，浸润在高质量的圈子里 就是通过创始人的自述，你会发现他们从早期创业开始就长期混迹在高质量的国际开发者线上社的区，那只要能获取到密集的高质量信息并且与高手交流，地点在哪里都一样，在武汉不在北京或其他城市就没有那么大的的影响 这是一种高质量的圈子，还有就是几位创始人互相吸引和拉彼此入伙，也是形成了一个他们之间的高质量链接圈子。比如季逸超虽然有技术天才，早期也赚到了钱，但都是“小打小闹”，他就说另一位创始人张涛，在产品上对于他们的启发很大 关于这方面的重要性我想再举几个例子。比如影视飓风的Tim在采访中就透露过，他们现在生产内容的速度跟不上他创意产生的速度。为什么？因为他日常会通过全世界的网站去吸收有意思的信息，比如会通过AI将西班牙、葡萄牙语的内容翻译成中文学习 关于马斯克的成功因素研究也有类似解释。比如马斯克的爸爸也是个天才，且对马斯克的性格和思考方式影响很大 —— 那为什么马斯克的爸爸没有大成？就是因为他在南非，远离了创新最重要的圈子，没有系统支持。而马斯克年轻时就到了硅谷，后来更是“Paypal黑帮”的一员 三，做一些酷的事情很重要 “当一个产品做完，你觉得不太酷就别发，你都觉得不酷，没人会觉得酷。”，这也是Manus创始人们反复提到的一个“执念” 比如在一期采访中主持人问，“在一个新的时代，把上一个时代的产品重做一遍。是一个好的创业思路吗？” 季逸超表示了委婉的反对，“对任何复杂的问题，总有一个简单清晰但错误的回答。”，很多时候大家选择一种做法是基于思维的惰性，而没有去思考这件事够不够“酷”，是不是创造了新的价值 再比如主持人问，“当时cursor已经很成功，为什么不做中国版cursor？”他的回答让我印象很深，“首先思考不做什么特别重要”，“我创业以来最好的正反馈都来自于创新。” 这让我想起上个月马斯克接受《People by WTF》播客采访，总结自己的成功就来自于创造新的价值 “我并不主动投资股票，只是建造东西，然后碰巧拥有所建公司的股票。创造比你拿走的更多，做社会的净贡献者。” 关于Manus团队在做很酷的东西，还有一个让我印象很深的点是他们说自己以多烧tokens为荣，甚至张涛讨论过想要造一个7*24小时不断烧token的机器（因为Agent的运行原理跟chatbot相比的话，消耗token的量级是上百倍的) 但你发现很多很有钱的大厂，甚至包括海外大厂（以我用的很“豪”的Grock为例），比如很明显的在“深度研究”模式，是会节省算力的，以至于经常压缩生成的内容 —— 这就是将创造作为“北极星指标”和将“成本盈利”作为北极星指标的区别 想要造一些很“酷”的东西，让我想起了同样在2025年声名鹊起的 —— DeepSeek、黑神话、哪吒、影石、影视飓风们… 看来，穷其道者，归处亦同 从年初Deep Seek的启动，到年末Manus的收官，算是属于我们的AI大年了，我想，世界如此安排这个剧本，也许冥冥之中是想告诉我们一些很重要的东西吧 [图片: https://cdnv2.ruguoapp.com/Fu9TVM5CXaYq2_J7htVJdldHuNUOv3.jpg]","published_date":"2025-12-31T03:48:49.444Z","authors":"广屿Ocean","source":"科技圈大小事 - 即刻圈子 - 广屿Ocean","details":{"content_html":"为什么是Manus，不是互联网大厂们？<br><br>今天是2025年的最后一天，很“巧合”的是今年压轴的热点竟然又是和我们有关，被印度人伤透了心的扎克伯格决定all in华人，收购了Manus，并且引爆了全网<br><br>但有一个问题是，我看到的文字信息基本是对结果的追认、祝贺、感叹不易，却没看到相关研究 —— 在这个毫无疑问是下一轮最关键技术浪潮的行业，为什么是Manus？为什么是一个武汉出身的小团队？为什么不是互联网大厂们？为什么这个在行业内并没有很深技术门槛的项目，一开始其他人最聪明的脑袋和资本们都没做出来？<br><br>这篇文章，我提前阅读了相关文章和收听Manus的创始人参与的播客节目，试着总结以下3个核心要素来回答这个问题：<br><br>一，有钱有闲OKR失踪<br><br>“当一群不太笨的人无所事事（且没有不良嗜好）的时候，就会产生很多很好的想法。”<br><br>Manus的三位创始人：CEO肖弘，90后连续创业者，特点是从未上过一天班；首席科学家季逸超，90后连续创业者，技术极客，高中时就靠开发插件赚到过30万美金；产品合伙人张涛，85后创业者，多家互联网公司产品经理经历，精通用户需求与产品设计<br><br>你发现没有，三人的共同特点就是除了“三无”：无海外留学光环、无大厂高管履历、无顶级学术背景，还有以下三个特质：<br><br>1，不太笨。虽然没有光鲜的背景履历光环，但或通过连续创业拿到结果，或通过多家大厂历练证明了自己<br><br>2，有钱但没那么有钱。他们都通过早年的创业或工作拿到了一定成果不用担心基本生存问题，但又没有那么有钱，比如Manus现在虽然盈利但到现在为止也才赚了1亿美金，跟大公司盈利能力比简直九牛一毛<br><br>3，没有不良嗜好。这是季逸超在接受采访时反复提到过的，说他们一帮人都很幸运没有不良嗜好，“起码不抽烟喝酒”，于是就有充分的精力和动机去研究一些“很酷”的事<br><br>当然，他们提到了“正向现金流很重要”，比如之前的产品Monica，已经是一个正向现金流的产品，那么团队在做第二曲线决策就会“既大胆又理智”（我觉得生活也是这样）—— 但问题是大厂也有正向现金流，为什么不是大厂？答案就是OKR失踪，最起码不是别人给你定的OKR<br><br>比如这次收购信息披露出来后，被很多媒体说赢麻了的，从天使轮就开始领投的真格基金，我觉得是真格的话确实赢的有道理，为什么？<br><br>这就要弄清楚，真格为什么能在天使轮就投进了Manus母公司？<br><br>我在记得在很多很多年前就关注过真格徐小平老师的报道，他有让我很深的两个观点是：<br>一是，他觉得投资的本质最重要的就是投创始人。要看这个人本身的学历、经历、魅力。所以他才能在季逸超才高中时就看中这个人并投资了他，并且更重要的事，季逸超说真格“不妨碍我做任何想做的事。”一直在支持他的探索，也就是没强压“OKR”<br><br>第二个是徐小平老师非常经典的一句话，曾经还被我用在了培训课件里面，“创业的本质是创什么？就是创个 ‘球’，人生欲求、职业诉求、市场需求。”<br><br>二，浸润在高质量的圈子里<br><br>就是通过创始人的自述，你会发现他们从早期创业开始就长期混迹在高质量的国际开发者线上社的区，那只要能获取到密集的高质量信息并且与高手交流，地点在哪里都一样，在武汉不在北京或其他城市就没有那么大的的影响<br><br>这是一种高质量的圈子，还有就是几位创始人互相吸引和拉彼此入伙，也是形成了一个他们之间的高质量链接圈子。比如季逸超虽然有技术天才，早期也赚到了钱，但都是“小打小闹”，他就说另一位创始人张涛，在产品上对于他们的启发很大<br><br>关于这方面的重要性我想再举几个例子。比如影视飓风的Tim在采访中就透露过，他们现在生产内容的速度跟不上他创意产生的速度。为什么？因为他日常会通过全世界的网站去吸收有意思的信息，比如会通过AI将西班牙、葡萄牙语的内容翻译成中文学习<br><br>关于马斯克的成功因素研究也有类似解释。比如马斯克的爸爸也是个天才，且对马斯克的性格和思考方式影响很大 —— 那为什么马斯克的爸爸没有大成？就是因为他在南非，远离了创新最重要的圈子，没有系统支持。而马斯克年轻时就到了硅谷，后来更是“Paypal黑帮”的一员<br><br>三，做一些酷的事情很重要<br><br>“当一个产品做完，你觉得不太酷就别发，你都觉得不酷，没人会觉得酷。”，这也是Manus创始人们反复提到的一个“执念”<br><br>比如在一期采访中主持人问，“在一个新的时代，把上一个时代的产品重做一遍。是一个好的创业思路吗？”<br><br>季逸超表示了委婉的反对，“对任何复杂的问题，总有一个简单清晰但错误的回答。”，很多时候大家选择一种做法是基于思维的惰性，而没有去思考这件事够不够“酷”，是不是创造了新的价值<br><br>再比如主持人问，“当时cursor已经很成功，为什么不做中国版cursor？”他的回答让我印象很深，“首先思考不做什么特别重要”，“我创业以来最好的正反馈都来自于创新。”<br><br>这让我想起上个月马斯克接受《People by WTF》播客采访，总结自己的成功就来自于创造新的价值<br><br>“我并不主动投资股票，只是建造东西，然后碰巧拥有所建公司的股票。创造比你拿走的更多，做社会的净贡献者。”<br><br>关于Manus团队在做很酷的东西，还有一个让我印象很深的点是他们说自己以多烧tokens为荣，甚至张涛讨论过想要造一个7*24小时不断烧token的机器（因为Agent的运行原理跟chatbot相比的话，消耗token的量级是上百倍的)<br><br>但你发现很多很有钱的大厂，甚至包括海外大厂（以我用的很“豪”的Grock为例），比如很明显的在“深度研究”模式，是会节省算力的，以至于经常压缩生成的内容 —— 这就是将创造作为“北极星指标”和将“成本盈利”作为北极星指标的区别<br><br>想要造一些很“酷”的东西，让我想起了同样在2025年声名鹊起的 —— DeepSeek、黑神话、哪吒、影石、影视飓风们…<br><br>看来，穷其道者，归处亦同<br><br>从年初Deep Seek的启动，到年末Manus的收官，算是属于我们的AI大年了，我想，世界如此安排这个剧本，也许冥冥之中是想告诉我们一些很重要的东西吧<br><img src=\"https://cdnv2.ruguoapp.com/Fu9TVM5CXaYq2_J7htVJdldHuNUOv3.jpg\">"}},{"id":"229051434220537856","type":"socialMedia","url":"https://x.com/vista8/status/2006210237607600442","title":"3个月3万推特粉丝被封号，他用3周重回1万＋，他的生图提示词经常爆火，如何做到的？ 新年第一堂爆款提示词和X增长直播课。 他是蝗虫群友，多个黑客松金奖得主，X...","description":"3个月3万推特粉丝被封号，他用3周重回1万＋，他的生图提示词经常爆火，如何做到的？ 新年第一堂爆款提示词和X增长直播课。 他是蝗虫群友，多个黑客松金奖得主，X粉丝单天关注速度曾超马斯克（哈哈哈） 当他用3个月做到3w推特关注时，莫名其妙被封号。 郁闷后，从零开始，几周又做到了1w+关注。 2026年第一场直播，邀神佬分享这段经历和经验。 扫码预约，明年见！ [图片: https://pbs.twimg.com/media/G9d9krpbQAAkeFE?format=jpg&#x26;name=orig] Berryxia.AI: ✍🏻看到大家都在总结2025年，我最大的收获就是在𝕏上 认识了你们，包括还有很多深入链接的朋友们。 真的是非常感谢大家的认可和支持，我就先盘点一下旧账 号的数据。（磕一个❤️） 我先把这个旧账号做个复盘的总结，从4月份开始起号到 被封禁的12月11日的数据记录。 📺总共展示量：27.2M，点赞101.9K [图片: https://pbs.twimg.com/media/G9d6TUPbQAAbEaS?format=jpg&#x26;name=orig]","published_date":"2025-12-31T03:46:08.269Z","authors":"向阳乔木","source":"twitter-向阳乔木","details":{"content_html":"3个月3万推特粉丝被封号，他用3周重回1万＋，他的生图提示词经常爆火，如何做到的？<br><br>新年第一堂爆款提示词和X增长直播课。<br><br>他是蝗虫群友，多个黑客松金奖得主，X粉丝单天关注速度曾超马斯克（哈哈哈）<br><br>当他用3个月做到3w推特关注时，莫名其妙被封号。<br><br>郁闷后，从零开始，几周又做到了1w+关注。<br><br>2026年第一场直播，邀神佬分享这段经历和经验。<br><br>扫码预约，明年见！<br><img width=\"868\" height=\"1200\" style=\"\" src=\"https://pbs.twimg.com/media/G9d9krpbQAAkeFE?format=jpg&#x26;name=orig\"><div><br><br>Berryxia.AI: ✍🏻看到大家都在总结2025年，我最大的收获就是在𝕏上<br>认识了你们，包括还有很多深入链接的朋友们。<br><br>真的是非常感谢大家的认可和支持，我就先盘点一下旧账<br>号的数据。（磕一个❤️）<br><br>我先把这个旧账号做个复盘的总结，从4月份开始起号到<br>被封禁的12月11日的数据记录。<br><br>📺总共展示量：27.2M，点赞101.9K<br><br><img width=\"2048\" height=\"1374\" style=\"\" src=\"https://pbs.twimg.com/media/G9d6TUPbQAAbEaS?format=jpg&#x26;name=orig\"></div>"}},{"id":"229065716267753472","type":"socialMedia","url":"https://x.com/dotey/status/2006209965816418518","title":"@宝玉xp: 就算是院士，在自己不专业的领域说的也不靠谱 @马少平THU: 专家系统为啥做不下去了？问题之一就是稍微偏离一点特定领域，性能就急剧下降","description":"@宝玉xp: 就算是院士，在自己不专业的领域说的也不靠谱 @马少平THU: 专家系统为啥做不下去了？问题之一就是稍微偏离一点特定领域，性能就急剧下降 [图片: https://pbs.twimg.com/media/G9d8_jwXcAAhLOW?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G9d9JpKW0AAAeeT?format=jpg&#x26;name=orig]","published_date":"2025-12-31T03:45:04.945Z","authors":"宝玉","source":"twitter-宝玉","details":{"content_html":"@宝玉xp: 就算是院士，在自己不专业的领域说的也不靠谱<br><br>@马少平THU: 专家系统为啥做不下去了？问题之一就是稍微偏离一点特定领域，性能就急剧下降<br><img width=\"1024\" height=\"572\" style=\"\" src=\"https://pbs.twimg.com/media/G9d8_jwXcAAhLOW?format=jpg&#x26;name=orig\"><br><img width=\"1706\" height=\"1279\" style=\"\" src=\"https://pbs.twimg.com/media/G9d9JpKW0AAAeeT?format=jpg&#x26;name=orig\">"}},{"id":"229066968920785920","type":"socialMedia","url":"https://x.com/gefei55/status/2006209183620976643","title":"说两个关于 DeepSeek 的冷知识。 冷知识一，按照 Similarweb 的统计口径，目前 DeepSeek 每个月还有3.5亿访问量，而2月最高峰是6.14亿。 什么意思呢？也就是一年...","description":"说两个关于 DeepSeek 的冷知识。 冷知识一，按照 Similarweb 的统计口径，目前 DeepSeek 每个月还有3.5亿访问量，而2月最高峰是6.14亿。 什么意思呢？也就是一年过去了，DeepSeek 并没有从巅峰跌落，而是最近半年都稳定在了三个多亿每月访问量，还有巅峰时期的一半还多的量。 冷知识二，你在谷歌搜索 Chinese AI，排名第一的是 DeepSeek 官网，也就是谷歌认为大家搜索 Chinese AI 想找的就是 DeepSeek。 [图片: https://pbs.twimg.com/media/G9d8nvKb0AAhYaH?format=jpg&#x26;name=orig]","published_date":"2025-12-31T03:41:57.680Z","authors":"哥飞","source":"twitter-哥飞","details":{"content_html":"说两个关于 DeepSeek 的冷知识。<br>冷知识一，按照 Similarweb 的统计口径，目前 DeepSeek 每个月还有3.5亿访问量，而2月最高峰是6.14亿。<br>什么意思呢？也就是一年过去了，DeepSeek 并没有从巅峰跌落，而是最近半年都稳定在了三个多亿每月访问量，还有巅峰时期的一半还多的量。<br>冷知识二，你在谷歌搜索 Chinese AI，排名第一的是 DeepSeek 官网，也就是谷歌认为大家搜索 Chinese AI 想找的就是 DeepSeek。<br><img width=\"2048\" height=\"650\" style=\"\" src=\"https://pbs.twimg.com/media/G9d8nvKb0AAhYaH?format=jpg&#x26;name=orig\">"}},{"id":"229087919019894785","type":"socialMedia","url":"https://x.com/vista8/status/2006204277237375044","title":"别做了！做小红书，方法不对的话，再努力也接不到广告 昨天没看老罗直播，因为跟朋友直播聊如何做小红书。 看了直播的都觉得干货太多了，让AI总结一篇文章，读完...","description":"别做了！做小红书，方法不对的话，再努力也接不到广告 昨天没看老罗直播，因为跟朋友直播聊如何做小红书。 看了直播的都觉得干货太多了，让AI总结一篇文章，读完少走很多弯路。 陈言老师太牛逼了，坦诚到令人发指，该说的不该说的全讲了，哈哈哈。 ---- 陈言兄做了两年小红书AI账号，10万+粉丝。 主要收入来自接广告。 他说得很直白：如果你做账号只是为了兴趣，那下面的内容对你没用。 这篇文章只讲一件事，怎么做一个能持续接到广告的小红书账号。 一、账号定位的四个硬指标 大部分人做账号，想的是\"我喜欢什么\"\"我擅长什么\"。陈言的思路不一样，除了这些，他还会想未来谁会投广告。 1. 你的优势必须可转化 陈言做特斯拉账号时，优势是懂智驾、很早买特斯拉股票、是第一批Model Y车主。 但这些优势怎么转化成内容？他发现特斯拉车主有两个痛点：不会用车、不知道怎么验车。 于是他做用车攻略，怎么调后视镜、怎么设置自动加热、怎么用单踏板模式。 还做了一个验车清单PDF，免费送。这就是把优势转化成用户需要的东西。 做AI账号也一样。 他的优势是2022年下半年公司就开始做AI项目，有大量真实场景。当时大家都在整活， 他讲的是\"我在公司项目里怎么用AI\"\"我和女儿怎么用AI\"\"我做自媒体怎么用AI\"。 场景真实，用户信任度就高。 2. 选题空间决定账号寿命 陈言统计过，他的AI账号发了600个小红书笔记，只有340多篇是纯AI产品介绍。 其他是什么？AI相关的智能硬件、用AI预测天气、用AI调节电网、用AI设计蛋白质。 选题空间大，账号才能活得久。 他给了一个判断标准，你选的主题，能不能至少做50期内容？大部分人在冷启动阶段坚持不了50期，所以50期的选题空间已经足够了。 但如果你选的主题，做10期就没东西可讲了，那就是个死胡同。 3. 必须同时满足用户和商家 这是最容易被忽略的一点。 很多人做内容，只想着用户喜欢什么，不想商家需要什么。结果账号做起来了，接不到广告。 陈言的特斯拉账号，用户是车主，商家是卖特斯拉配件的。车主需要用车攻略，他就做攻略。 配件商需要曝光，他就在视频里自然地展示手机支架、杯托、睡垫。用户觉得有用，商家觉得有效，这个账号就有商业价值。 AI账号也一样。 用户需要AI工具推荐，品牌方需要曝光新产品。他做的内容，既是工具测评，也是品牌宣传。 4. 时机比努力更重要 陈言强调，就算你完全复制他的方法，也不一定能做起来，因为时机变了。 特斯拉账号做得早，2021年疫情期间，竞争对手少，特斯拉自带流量。 AI账号赶上了ChatGPT在国内火的时候，2023年12月开始做，正好踩在风口上。 现在呢？AI账号已经一大堆了，再做同样的内容，难度大很多。 所以做账号之前，要判断：这个领域现在是红海还是蓝海？还有没有机会？ 二、内容设计的核心：给广告留空间 陈言说，很多人的账号接不到广告，不是因为粉丝少，是因为内容没给广告留空间。 1. 场景里必须有商品 举个例子，家居账号最容易接广告，为什么？因为家居内容天然有场景。 你拍家里的书桌、客厅、卧室，画面里自然会出现各种家居用品。学习类账号也一样。 你拍自己学习的场景，桌子上要放台灯、笔记本、咖啡杯、降噪耳机。 哪怕这条内容不是广告，也要把商品放进去。 这样做有两个好处： 一是让粉丝习惯你会推荐东西，不会觉得你接广告就变味了。 二是让你的内容流程习惯往里插商品，接广告的时候不会手忙脚乱。 2. 日常内容和广告内容不能割裂 陈言说，最失败的账号是：日常更新是一种内容，接广告是另一种内容。 为什么失败？因为粉丝想看的是你不接广告时的内容。你接了广告，换成另一种内容，粉丝不买账，数据就差。数据差，品牌方就不愿意再找你。 所以你的日常内容，要和广告内容保持一致。 3. 有些内容天生不适合接广告 陈言举了个例子：现在很火的AI探班片场视频，比如权力的游戏片场，都是AI生成的。 这种视频流量很好，但很难接广告。 为什么？因为画面里全是AI生成的场景，你没法自然地插入商品。 所以做账号之前，要想清楚：我的内容形式，适不适合接广告？ 三、冷启动的三个关键动作 1. 用最小成本验证方向 陈言做AI账号的时候，同时计划做3个账号：汽车、AI、亲子。 三个账号同时发内容，看哪个数据好。结果AI账号在小红书的数据最稳定，点赞几十，对新账号来说很不错。 于是他停了另外两个，专注做AI。 这就是用最小成本验证方向。 2. 找到你的差异化定位 陈言做AI账号之前，画了一个两象限的图。 横轴是AI账号的方向：整活、讲技术、科普、讲工具。纵轴是账号体量和核心竞争力。 他把所有能看到的AI账号标在图上，找了一个空白地带：AI场景实验室。 当时大家做AI账号，要么整活，要么讲技术，要么科普，要么讲工具。 陈言做的是场景：我在公司项目里怎么用AI、我和女儿怎么用AI、我做自媒体怎么用AI。 所有内容都有场景，场景和人设强相关。 这就是他的差异化。 3. 前50条内容可以抄 陈言说得很直白：起号阶段，先别考虑原创，去抄爆款。为什么？因为原创成本太高，你不知道什么内容会火。抄爆款，至少能保证内容有基本的流量。怎么抄？找一个爆款，原封不动地复制。如果是口播，就变成你自己播。如果是别人的故事,就结合自己情况改成自己的故事。这是最容易、最大概率出爆款的方法。 四、选题的三个底层逻辑 1. 情绪类内容：流量大但不涨粉 什么是情绪类内容？能调动某一类人情绪的内容。 比如年底年终奖、年终总结这种话题。这类内容的特点是：数据特别好，但不涨粉。 陈言说，1000点赞可能只有10个粉丝。 为啥？因为情绪类内容，用户是为了发泄情绪，不是为了关注你。 2. 利他类内容：涨粉稳但流量小 什么是利他类内容？让用户觉得能学到东西的内容。 比如AI工具测评、使用攻略、提示词分享。 这类内容的特点是：涨粉稳定，但流量不如情绪类。 陈言做的主要是这个方向，因为更稳，更适合长期做。 陈言总结了小红书的套路：上来说结果，然后下钩子，用两三句话把事讲清楚，最后留一个行动号召，最好一分钟内搞定。 小红书和B站、抖音不一样： B站你不讲明白，会有人骂你。小红书你讲太明白，会有人骂你。 3. 避免被算法限制 小红书的算法很刻板。一旦给你打上某一类标签，你再做泛内容，就要做好没流量的准备。 陈言的AI账号，他刻意不说自己是AI博主，说是科技博主。 所以他的内容，AI只占一半，其他是智能硬件、汽车。虽然会丢掉一些收入，但让账号更多元化，不会被算法限制。 五、封面设计：从5%到10%的转化率飞跃 陈言说，自从用AI做封面，小红书的点击转化率从5%翻到了10%，现在稳定在8%到9%。 这个提升不是偶然的，是他研究了YouTube顶级博主MrBeast的封面逻辑后，用AI实现的。 封面的核心原则：夸张但真实。在真实的前提下，做一个夸张的题材。 封面一定要夸张，但题材要在真实的前提下夸张。 封面上的文字和标题的差异也很重要。 封面上的大字给人看的，更吸引用户，直接影响转化率。 底部的小标题给算法看的，权重可能最高，影响曝光量。这两个标题的作用完全不同。 陈言现在做一个封面只需要15分钟。工具主要是：Gemini纳米Pro、豆包、即梦。 几乎不抽卡，只要提示词写清楚，不超过三次就能搞定。 六、涨粉的核心：给用户一个关注你的理由 陈言在第一年涨了7万粉丝，主要靠稀缺资源引流。 特斯拉账号做了验车清单，AI账号做了多维表格，把用过的所有AI工具整理成表格。 用户不是为了有用得到一个东西，是为了稀缺得到一个东西。 小红书引流很严格：不能贴二维码，不能口播账号，不能放网址。 陈言的方法是先把大家引到小红书群里，然后在群里置顶链接和文案，设置自动欢迎语，让新用户自己去看置顶消息。 七、商业化的三个阶段 第一阶段：进入代理公司的必选名单。每次投放必须有，至少进前五。 第二阶段：和品牌方直接合作。 代理公司要返点40%、50%，越来越过分。 和品牌方直接合作，不让中间商赚差价，收入更高。 第三阶段：多元化，不被单一领域限制。 把AI内容降到一半，扩展到智能硬件和汽车。 虽然会丢掉一些收入，但让账号更多元化，长期稳定性更好。 八、合规的三个雷区 1. 玄学类：把算命讲成兴趣 2. 医疗类：不能说疗效，不能说药名 3. 金融类：不能推荐投资品 九、图文还是视频？ 陈言的建议是：优先做视频，但图文也要发。 小红书的流量一定是向视频倾斜的，但图文在小红书上也有流量，是长尾流量。 所以最好的策略是：视频为主，图文为辅。 写在最后 陈言的方法论，核心是三个字：商业化。 他做账号，从第一天开始就在想：谁会给我钱？看起来功利，但其实是做自媒体的底层逻辑。 如果你也想做一个能接广告的账号，记住这几点：定位的时候，想清楚谁是你的用户，谁是你的客户。 内容设计的时候，给广告留空间，让日常内容和广告内容保持一致。 冷启动的时候，用最小成本验证方向。 涨粉的时候，给用户一个关注你的理由，最好是稀缺的东西。 封面设计的时候，用AI做夸张但真实的场景。 这些方法，陈言用了两年时间验证过，确实有效。 但记住，时机比方法更重要。 关键是：别犹豫，先做起来再说。","published_date":"2025-12-31T03:22:27.250Z","authors":"向阳乔木","source":"twitter-向阳乔木","details":{"content_html":"别做了！做小红书，方法不对的话，再努力也接不到广告<br><br>昨天没看老罗直播，因为跟朋友直播聊如何做小红书。<br><br>看了直播的都觉得干货太多了，让AI总结一篇文章，读完少走很多弯路。<br><br>陈言老师太牛逼了，坦诚到令人发指，该说的不该说的全讲了，哈哈哈。<br><br>----<br><br>陈言兄做了两年小红书AI账号，10万+粉丝。<br><br>主要收入来自接广告。<br><br>他说得很直白：如果你做账号只是为了兴趣，那下面的内容对你没用。<br><br>这篇文章只讲一件事，怎么做一个能持续接到广告的小红书账号。<br><br>一、账号定位的四个硬指标<br><br>大部分人做账号，想的是\"我喜欢什么\"\"我擅长什么\"。陈言的思路不一样，除了这些，他还会想未来谁会投广告。<br><br>1. 你的优势必须可转化<br><br>陈言做特斯拉账号时，优势是懂智驾、很早买特斯拉股票、是第一批Model Y车主。<br><br>但这些优势怎么转化成内容？他发现特斯拉车主有两个痛点：不会用车、不知道怎么验车。<br><br>于是他做用车攻略，怎么调后视镜、怎么设置自动加热、怎么用单踏板模式。<br><br>还做了一个验车清单PDF，免费送。这就是把优势转化成用户需要的东西。<br><br>做AI账号也一样。<br><br>他的优势是2022年下半年公司就开始做AI项目，有大量真实场景。当时大家都在整活，<br><br>他讲的是\"我在公司项目里怎么用AI\"\"我和女儿怎么用AI\"\"我做自媒体怎么用AI\"。<br><br>场景真实，用户信任度就高。<br><br>2. 选题空间决定账号寿命<br><br>陈言统计过，他的AI账号发了600个小红书笔记，只有340多篇是纯AI产品介绍。<br><br>其他是什么？AI相关的智能硬件、用AI预测天气、用AI调节电网、用AI设计蛋白质。<br><br>选题空间大，账号才能活得久。<br><br>他给了一个判断标准，你选的主题，能不能至少做50期内容？大部分人在冷启动阶段坚持不了50期，所以50期的选题空间已经足够了。<br><br>但如果你选的主题，做10期就没东西可讲了，那就是个死胡同。<br><br>3. 必须同时满足用户和商家<br><br>这是最容易被忽略的一点。<br><br>很多人做内容，只想着用户喜欢什么，不想商家需要什么。结果账号做起来了，接不到广告。<br><br>陈言的特斯拉账号，用户是车主，商家是卖特斯拉配件的。车主需要用车攻略，他就做攻略。<br><br>配件商需要曝光，他就在视频里自然地展示手机支架、杯托、睡垫。用户觉得有用，商家觉得有效，这个账号就有商业价值。<br><br>AI账号也一样。<br><br>用户需要AI工具推荐，品牌方需要曝光新产品。他做的内容，既是工具测评，也是品牌宣传。<br><br>4. 时机比努力更重要<br><br>陈言强调，就算你完全复制他的方法，也不一定能做起来，因为时机变了。<br><br>特斯拉账号做得早，2021年疫情期间，竞争对手少，特斯拉自带流量。<br><br>AI账号赶上了ChatGPT在国内火的时候，2023年12月开始做，正好踩在风口上。<br><br>现在呢？AI账号已经一大堆了，再做同样的内容，难度大很多。<br><br>所以做账号之前，要判断：这个领域现在是红海还是蓝海？还有没有机会？<br><br>二、内容设计的核心：给广告留空间<br><br>陈言说，很多人的账号接不到广告，不是因为粉丝少，是因为内容没给广告留空间。<br><br>1. 场景里必须有商品<br><br>举个例子，家居账号最容易接广告，为什么？因为家居内容天然有场景。<br><br>你拍家里的书桌、客厅、卧室，画面里自然会出现各种家居用品。学习类账号也一样。<br><br>你拍自己学习的场景，桌子上要放台灯、笔记本、咖啡杯、降噪耳机。<br><br>哪怕这条内容不是广告，也要把商品放进去。<br><br>这样做有两个好处：<br><br>一是让粉丝习惯你会推荐东西，不会觉得你接广告就变味了。<br><br>二是让你的内容流程习惯往里插商品，接广告的时候不会手忙脚乱。<br><br>2. 日常内容和广告内容不能割裂<br><br>陈言说，最失败的账号是：日常更新是一种内容，接广告是另一种内容。<br><br>为什么失败？因为粉丝想看的是你不接广告时的内容。你接了广告，换成另一种内容，粉丝不买账，数据就差。数据差，品牌方就不愿意再找你。<br><br>所以你的日常内容，要和广告内容保持一致。<br><br>3. 有些内容天生不适合接广告<br><br>陈言举了个例子：现在很火的AI探班片场视频，比如权力的游戏片场，都是AI生成的。<br><br>这种视频流量很好，但很难接广告。<br><br>为什么？因为画面里全是AI生成的场景，你没法自然地插入商品。<br><br>所以做账号之前，要想清楚：我的内容形式，适不适合接广告？<br><br>三、冷启动的三个关键动作<br><br>1. 用最小成本验证方向<br><br>陈言做AI账号的时候，同时计划做3个账号：汽车、AI、亲子。<br><br>三个账号同时发内容，看哪个数据好。结果AI账号在小红书的数据最稳定，点赞几十，对新账号来说很不错。<br><br>于是他停了另外两个，专注做AI。<br><br>这就是用最小成本验证方向。<br><br>2. 找到你的差异化定位<br><br>陈言做AI账号之前，画了一个两象限的图。<br><br>横轴是AI账号的方向：整活、讲技术、科普、讲工具。纵轴是账号体量和核心竞争力。<br><br>他把所有能看到的AI账号标在图上，找了一个空白地带：AI场景实验室。<br><br>当时大家做AI账号，要么整活，要么讲技术，要么科普，要么讲工具。<br><br>陈言做的是场景：我在公司项目里怎么用AI、我和女儿怎么用AI、我做自媒体怎么用AI。<br><br>所有内容都有场景，场景和人设强相关。<br><br>这就是他的差异化。<br><br>3. 前50条内容可以抄<br><br>陈言说得很直白：起号阶段，先别考虑原创，去抄爆款。为什么？因为原创成本太高，你不知道什么内容会火。抄爆款，至少能保证内容有基本的流量。怎么抄？找一个爆款，原封不动地复制。如果是口播，就变成你自己播。如果是别人的故事,就结合自己情况改成自己的故事。这是最容易、最大概率出爆款的方法。<br><br>四、选题的三个底层逻辑<br><br>1. 情绪类内容：流量大但不涨粉<br><br>什么是情绪类内容？能调动某一类人情绪的内容。<br><br>比如年底年终奖、年终总结这种话题。这类内容的特点是：数据特别好，但不涨粉。<br><br>陈言说，1000点赞可能只有10个粉丝。<br><br>为啥？因为情绪类内容，用户是为了发泄情绪，不是为了关注你。<br><br>2. 利他类内容：涨粉稳但流量小<br><br>什么是利他类内容？让用户觉得能学到东西的内容。<br><br>比如AI工具测评、使用攻略、提示词分享。<br><br>这类内容的特点是：涨粉稳定，但流量不如情绪类。<br><br>陈言做的主要是这个方向，因为更稳，更适合长期做。<br><br>陈言总结了小红书的套路：上来说结果，然后下钩子，用两三句话把事讲清楚，最后留一个行动号召，最好一分钟内搞定。<br><br>小红书和B站、抖音不一样：<br><br>B站你不讲明白，会有人骂你。小红书你讲太明白，会有人骂你。<br><br>3. 避免被算法限制<br><br>小红书的算法很刻板。一旦给你打上某一类标签，你再做泛内容，就要做好没流量的准备。<br><br>陈言的AI账号，他刻意不说自己是AI博主，说是科技博主。<br><br>所以他的内容，AI只占一半，其他是智能硬件、汽车。虽然会丢掉一些收入，但让账号更多元化，不会被算法限制。<br><br>五、封面设计：从5%到10%的转化率飞跃<br><br>陈言说，自从用AI做封面，小红书的点击转化率从5%翻到了10%，现在稳定在8%到9%。<br><br>这个提升不是偶然的，是他研究了YouTube顶级博主MrBeast的封面逻辑后，用AI实现的。<br><br>封面的核心原则：夸张但真实。在真实的前提下，做一个夸张的题材。<br><br>封面一定要夸张，但题材要在真实的前提下夸张。<br><br>封面上的文字和标题的差异也很重要。<br><br>封面上的大字给人看的，更吸引用户，直接影响转化率。<br><br>底部的小标题给算法看的，权重可能最高，影响曝光量。这两个标题的作用完全不同。<br><br>陈言现在做一个封面只需要15分钟。工具主要是：Gemini纳米Pro、豆包、即梦。<br><br>几乎不抽卡，只要提示词写清楚，不超过三次就能搞定。<br><br>六、涨粉的核心：给用户一个关注你的理由<br><br>陈言在第一年涨了7万粉丝，主要靠稀缺资源引流。<br><br>特斯拉账号做了验车清单，AI账号做了多维表格，把用过的所有AI工具整理成表格。<br><br>用户不是为了有用得到一个东西，是为了稀缺得到一个东西。<br><br>小红书引流很严格：不能贴二维码，不能口播账号，不能放网址。<br><br>陈言的方法是先把大家引到小红书群里，然后在群里置顶链接和文案，设置自动欢迎语，让新用户自己去看置顶消息。<br><br>七、商业化的三个阶段<br><br>第一阶段：进入代理公司的必选名单。每次投放必须有，至少进前五。<br><br>第二阶段：和品牌方直接合作。<br><br>代理公司要返点40%、50%，越来越过分。<br><br>和品牌方直接合作，不让中间商赚差价，收入更高。<br><br>第三阶段：多元化，不被单一领域限制。<br><br>把AI内容降到一半，扩展到智能硬件和汽车。<br><br>虽然会丢掉一些收入，但让账号更多元化，长期稳定性更好。<br><br>八、合规的三个雷区<br><br>1. 玄学类：把算命讲成兴趣<br>2. 医疗类：不能说疗效，不能说药名<br>3. 金融类：不能推荐投资品<br><br>九、图文还是视频？<br><br>陈言的建议是：优先做视频，但图文也要发。<br><br>小红书的流量一定是向视频倾斜的，但图文在小红书上也有流量，是长尾流量。<br><br>所以最好的策略是：视频为主，图文为辅。<br><br>写在最后<br><br>陈言的方法论，核心是三个字：商业化。<br><br>他做账号，从第一天开始就在想：谁会给我钱？看起来功利，但其实是做自媒体的底层逻辑。<br><br>如果你也想做一个能接广告的账号，记住这几点：定位的时候，想清楚谁是你的用户，谁是你的客户。<br><br>内容设计的时候，给广告留空间，让日常内容和广告内容保持一致。<br><br>冷启动的时候，用最小成本验证方向。<br><br>涨粉的时候，给用户一个关注你的理由，最好是稀缺的东西。<br><br>封面设计的时候，用AI做夸张但真实的场景。<br><br>这些方法，陈言用了两年时间验证过，确实有效。<br><br>但记住，时机比方法更重要。<br><br>关键是：别犹豫，先做起来再说。"}},{"id":"229044756439869440","type":"socialMedia","url":"https://x.com/ezshine/status/2006200845931839890","title":"Gemini太逗了，让我假装老法师，终于理解金牌讲师的保护色了。","description":"Gemini太逗了，让我假装老法师，终于理解金牌讲师的保护色了。 [图片: https://pbs.twimg.com/media/G9d1CF2aAAAieX7?format=jpg&#x26;name=orig]","published_date":"2025-12-31T03:08:49.041Z","authors":"大帅老猿","source":"twitter-大帅老猿","details":{"content_html":"Gemini太逗了，让我假装老法师，终于理解金牌讲师的保护色了。<br><img width=\"946\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9d1CF2aAAAieX7?format=jpg&#x26;name=orig\">"}},{"id":"229019868916328448","type":"socialMedia","url":"https://x.com/kevinweil/status/2006187462729847107","title":"Congrats to the @OpenAI research team—GPT 5.2 is an incredible model!","description":"Congrats to the @OpenAI research team—GPT 5.2 is an incredible model! Sebastien Bubeck: Nice way to end the year, see you in 2026 for more! (Also good to remember that 6 months ago the models were at 4% on Frontier Math Tier 4...) [图片: https://pbs.twimg.com/media/G9dbDVkaYAIT-f9?format=jpg&#x26;name=orig]","published_date":"2025-12-31T02:15:38.364Z","authors":"Kevin Weil 🇺🇸","source":"twitter-Kevin Weil 🇺🇸","details":{"content_html":"Congrats to the @OpenAI research team—GPT 5.2 is an incredible model!<div><br><br>Sebastien Bubeck: Nice way to end the year, see you in 2026 for more! <br><br>(Also good to remember that 6 months ago the models were at 4% on Frontier Math Tier 4...)<br><br><img width=\"1080\" height=\"847\" style=\"\" src=\"https://pbs.twimg.com/media/G9dbDVkaYAIT-f9?format=jpg&#x26;name=orig\"></div>"}},{"id":"229016512015955968","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1q00zul/apple_needs_to_deliver_an_aicharged_siri_so_good/","title":"Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade","description":"[图片: Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade https://external-preview.redd.it/5xYig1WI5dSa9Bw0hjO_VZFIcNoTnL-dQdxjEWh0as8.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=2dadab3ead02b470de3adae2c0f4c80f01347841] submitted by /u/ControlCAD [link] [comments]","published_date":"2025-12-31T02:15:13.791Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1q00zul/apple_needs_to_deliver_an_aicharged_siri_so_good/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/5xYig1WI5dSa9Bw0hjO_VZFIcNoTnL-dQdxjEWh0as8.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=2dadab3ead02b470de3adae2c0f4c80f01347841\" alt=\"Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade\" title=\"Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/ControlCAD\" target=\"_blank\"> /u/ControlCAD </a> <br> <span><a href=\"https://www.cnbc.com/2025/12/30/apple-intelligence-ai-siri-iphone.html\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1q00zul/apple_needs_to_deliver_an_aicharged_siri_so_good/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"229026580041713664","type":"socialMedia","url":"https://x.com/shao__meng/status/2006179679288582432","title":"2026 年 AI 发展八点预测，和 2025 年预测回顾（仅一个失误），来自 @ashugarg 2025年预测回顾：大部分准确或部分实现 正确（🟢）： · 推理模型（如 OpenAI o...","description":"2026 年 AI 发展八点预测，和 2025 年预测回顾（仅一个失误），来自 @ashugarg 2025年预测回顾：大部分准确或部分实现 正确（🟢）： · 推理模型（如 OpenAI o1/o3）和复合 AI 系统（多模型+工具协作）主导了 2025 年。 · AI 重塑软件经济，向“服务即软件”（AI 直接交付结果而非卖许可证）转型，成为 B2B 投资主流。 · OpenAI 主导地位削弱，Gemini、Claude 和开源模型分流市场份额，企业采用多模型策略。 · NVIDIA 芯片垄断面临挑战（Cerebras、AMD、Google TPU 等崛起）。 · 无人驾驶出租车（如 Waymo）赢得公众信任，在旧金山等地普及。 提前预测（⏳）： · AI 初创公司尚未完全取代传统巨头（Google 等强势反击）。 · AI 界面超越纯聊天框（进展较慢，但作者坚持 2026 年会加速）。 · 搜索引擎“10 个蓝链接”模式衰退（AI 概述已覆盖 20 亿用户，点击率下降），但真正颠覆在于智能体式商务。 错误（❌）： · Meta Llama 未成为“AI 的 Linux”（开源模型繁荣，但未形成单一标准主导）。 2026 年 8 大预测 2026 年是 AI 从试点向大规模生产落地的关键年，重点在企业应用、安全、竞争和消费者习惯变化。 1. 企业 AI 进入生产阶段：过去两年企业 AI 停留在试点，2026 年将实现可靠部署。初创公司通过嵌入工程师、定制小模型和本地部署解决边缘案例，SaaS 巨头（如Salesforce、ServiceNow）推动类别合法化。 2. 决策痕迹成为新数据护城河：AI 智能体执行工作流时，会记录完整决策过程（输入、规则、例外等），形成“上下文图”。这将成为企业独有资产，帮助持续优化智能体，初创公司在执行路径上有优势。 3. AI 安全问题成为焦点：智能体持有敏感业务逻辑，风险增大。2026 年 AI 安全将成为董事会级指标，出现至少一起高调事件，推动零信任框架和行为监控。 4. SaaS 巨头反击：Salesforce、ServiceNow 等加强本土 AI 功能，限制 API 访问、增加摩擦以保护数据和收入。初创公司需警惕对巨头依赖的风险。 5. 智能体吞噬电商：消费者习惯用 AI 描述需求购物，Visa、Mastercard 等已铺设智能体支付协议。2026 年智能体将主导低风险高频消费，颠覆聚合器（如 Expedia），强化 Amazon/Walmart 优势，挑战 Google 广告模式。 6. Gemini 超越 ChatGPT：2025 年后半年 Gemini 用户增长 30%（ChatGPT 仅 6%），MAU 达数亿。Google 的分发优势（Search、Android）将帮助 Gemini（及 Grok）抢占消费者份额，形成三四强格局。 7. AI 实验室上市：Anthropic 和/或 OpenAI 可能 2026 年 IPO。Anthropic 收入快速增长（2025年超70亿，2026目标260亿），OpenAI 达200亿规模，但巨额亏损和资本需求推动上市（估值可能达万亿）。 8. Cursor 式界面成默认：聊天框 UI 已到极限，2026年 AI 将嵌入工作流（如 Cursor 在代码中的直接编辑）。类似“某某领域的 Cursor ”将普及于法律、金融、营销等领域，AI 主动提议而非被动等待。 3个持续趋势（不止2026年） · 缩放定律乘数效应：预训练+后训练优化+推理时计算，三者结合带来复合提升。 · 验证是瓶颈：AI 在可验证领域（如编码、数学）进步快，主观任务仍需人类监督。 · 定价向结果导向转变：从按使用付费转向按任务/结果付费，企业要求明确 ROI。 [图片: https://pbs.twimg.com/media/G9dhxHAaYAQnhgC?format=jpg&#x26;name=orig] ashu garg: http://x.com/i/article/2006074423854702592","published_date":"2025-12-31T01:44:43.629Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"2026 年 AI 发展八点预测，和 2025 年预测回顾（仅一个失误），来自 @ashugarg <br><br>2025年预测回顾：大部分准确或部分实现<br>正确（🟢）：<br>· 推理模型（如 OpenAI o1/o3）和复合 AI 系统（多模型+工具协作）主导了 2025 年。<br>· AI 重塑软件经济，向“服务即软件”（AI 直接交付结果而非卖许可证）转型，成为 B2B 投资主流。<br>· OpenAI 主导地位削弱，Gemini、Claude 和开源模型分流市场份额，企业采用多模型策略。<br>· NVIDIA 芯片垄断面临挑战（Cerebras、AMD、Google TPU 等崛起）。<br>· 无人驾驶出租车（如 Waymo）赢得公众信任，在旧金山等地普及。<br>提前预测（⏳）：<br>· AI 初创公司尚未完全取代传统巨头（Google 等强势反击）。<br>· AI 界面超越纯聊天框（进展较慢，但作者坚持 2026 年会加速）。<br>· 搜索引擎“10 个蓝链接”模式衰退（AI 概述已覆盖 20 亿用户，点击率下降），但真正颠覆在于智能体式商务。<br>错误（❌）：<br>· Meta Llama 未成为“AI 的 Linux”（开源模型繁荣，但未形成单一标准主导）。<br><br>2026 年 8 大预测<br>2026 年是 AI 从试点向大规模生产落地的关键年，重点在企业应用、安全、竞争和消费者习惯变化。<br><br>1. 企业 AI 进入生产阶段：过去两年企业 AI 停留在试点，2026 年将实现可靠部署。初创公司通过嵌入工程师、定制小模型和本地部署解决边缘案例，SaaS 巨头（如Salesforce、ServiceNow）推动类别合法化。<br><br>2. 决策痕迹成为新数据护城河：AI 智能体执行工作流时，会记录完整决策过程（输入、规则、例外等），形成“上下文图”。这将成为企业独有资产，帮助持续优化智能体，初创公司在执行路径上有优势。<br><br>3. AI 安全问题成为焦点：智能体持有敏感业务逻辑，风险增大。2026 年 AI 安全将成为董事会级指标，出现至少一起高调事件，推动零信任框架和行为监控。<br><br>4. SaaS 巨头反击：Salesforce、ServiceNow 等加强本土 AI 功能，限制 API 访问、增加摩擦以保护数据和收入。初创公司需警惕对巨头依赖的风险。<br><br>5. 智能体吞噬电商：消费者习惯用 AI 描述需求购物，Visa、Mastercard 等已铺设智能体支付协议。2026 年智能体将主导低风险高频消费，颠覆聚合器（如 Expedia），强化 Amazon/Walmart 优势，挑战 Google 广告模式。<br><br>6. Gemini 超越 ChatGPT：2025 年后半年 Gemini 用户增长 30%（ChatGPT 仅 6%），MAU 达数亿。Google 的分发优势（Search、Android）将帮助 Gemini（及 Grok）抢占消费者份额，形成三四强格局。<br><br>7. AI 实验室上市：Anthropic 和/或 OpenAI 可能 2026 年 IPO。Anthropic 收入快速增长（2025年超70亿，2026目标260亿），OpenAI 达200亿规模，但巨额亏损和资本需求推动上市（估值可能达万亿）。<br><br>8. Cursor 式界面成默认：聊天框 UI 已到极限，2026年 AI 将嵌入工作流（如 Cursor 在代码中的直接编辑）。类似“某某领域的 Cursor ”将普及于法律、金融、营销等领域，AI 主动提议而非被动等待。<br><br>3个持续趋势（不止2026年）<br>· 缩放定律乘数效应：预训练+后训练优化+推理时计算，三者结合带来复合提升。<br>· 验证是瓶颈：AI 在可验证领域（如编码、数学）进步快，主观任务仍需人类监督。<br>· 定价向结果导向转变：从按使用付费转向按任务/结果付费，企业要求明确 ROI。<br><img width=\"1643\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9dhxHAaYAQnhgC?format=jpg&#x26;name=orig\"><div><br><br>ashu garg: http://x.com/i/article/2006074423854702592<br></div>"}},{"id":"229026580041713665","type":"socialMedia","url":"https://x.com/shao__meng/status/2006176156274581618","title":"2025 年 LLM 现状：进展、问题与预测，来自 @rasbt 分享，开始前再安利一次作者的书籍和开源资源 Build a Large Language Model (From Scratch) https://github....","description":"2025 年 LLM 现状：进展、问题与预测，来自 @rasbt 分享，开始前再安利一次作者的书籍和开源资源 Build a Large Language Model (From Scratch) https://github.com/rasbt/LLMs-from-scratch Build A Reasoning Model (From Scratch) https://github.com/rasbt/reasoning-from-scratch 1. 2025年：推理模型、RLVR 与 GRPO 之年 2025年最大的亮点是推理模型的爆发。这些模型通过生成中间推理步骤（如链式思考）显著提升复杂任务准确率。关键创新是 RLVR，结合 GRPO 算法，由 DeepSeek R1 模型在年初引入。 · RLVR 允许使用客观正确的奖励信号进行大规模后训练，而无需昂贵的人工标注。 · 这大幅降低了训练成本，并使开放权重模型迅速赶上专有模型。 · 随后，各大实验室纷纷推出推理变体，RLVR 成为后训练主流方法，取代了以往的 RLHF 和 PPO。 2. GRPO：年度研究宠儿 GRPO 算法在 2025 年被广泛改进和采用（如 Olmo 3、DeepSeek V3.2），通过过滤不良更新、调整KL散度和采样策略，提升训练稳定性和性能。它标志着强化学习在 LLM 领域的成熟应用。 3. LLM 架构：分叉之路？ · 主导架构仍是 Decoder-only Transformer + MoE，辅以效率优化（如分组查询注意力、多头潜注意力）。 · 新兴趋势：混合高效架构（如 Qwen3-Next的Gated DeltaNets、Kimi Linear、NVIDIA Nemotron 3 的 Mamba-2 层），实现序列长度线性扩展。 · 文本扩散模型（如 Google Gemini Diffusion）作为低延迟替代方案出现，但尚未主导前沿性能。 4. 推理时扩展与工具使用之年 · 推理时扩展（如自一致性、自精炼）成为提升复杂任务性能的重要手段，许多模型已在数学竞赛中达到金牌水平。 · 工具使用（调用搜索、计算器等外部工具）减少幻觉，成为代理系统标准。但开源生态在工具集成和安全性上仍落后于专有模型。 5. 年度热词：Benchmaxxing 基准测试过度优化问题突出：模型在公开基准上得分很高，但实际应用表现平平。原因包括训练数据污染和基准饱和。作者建议视基准为“阈值指标”，而非绝对能力衡量，并强调实际任务测试的重要性。 6. AI 在编码、写作与研究中的应用 · 编码：擅长处理重复性任务（如调试、代码清理），但专家知识仍不可替代。 · 写作/研究：帮助纠错、查找参考，但过度依赖可能导致技能退化和工作空洞化。 作者强调“先自己努力，再用 LLM 辅助”的原则，以保持学习和创造满足感。 7. 私域数据：新竞争优势 随着通用 scaling 定律趋于饱和，私有数据成为差异化关键。行业企业（如生物科技公司）倾向自建专有 LLM，利用开放基础模型（如 DeepSeek V3.2）进行领域适配。 8. 从零构建 LLM 与推理模型 作者分享个人工作：畅销书「Build a Large Language Model (From Scratch)」及续作「Build a Reasoning Model (From Scratch)」，涵盖推理时扩展、RLVR/GRPO 等最新技术。 9. 2025 年惊喜与 2026 年预测 2025 年主要惊喜（作者未预料到如此迅速发生）： · 多个推理模型已在重大数学竞赛中达到金牌水平（如 OpenAI 未命名模型、Gemini Deep Think、DeepSeekMath-V2）。 · Llama 系列（包括 Llama 4）在开源社区大幅失宠，Qwen 凭借下载量和衍生模型数量成为新霸主。 · Mistral AI 的旗舰 Mistral 3 采用 DeepSeek V3 架构。 · 开源前沿模型竞争激烈，新选手涌现（如 Kimi、GLM、MiniMax）。 · 高效混合架构被领先实验室优先采用。 · OpenAI 意外发布开放权重模型 gpt-oss。 · MCP 协议迅速成为代理系统中工具/数据访问的标准。 对 2026 年的预测： · 将出现行业级、低延迟消费级扩散模型（如 Gemini Diffusion 领先）。 · 开源社区逐步集成本地工具使用和更强智能体能力。 · RLVR 扩展至数学/编码以外领域（如化学、生物）。 · 传统 RAG 渐退，长上下文小模型将成为文档查询主流。 · 性能提升更多来自工具优化和推理时扩展，而非单纯核心模型训练；基准进步将聚焦减少无用推理步骤。 原文地址： https://magazine.sebastianraschka.com/p/state-of-llms-2025 [图片: https://pbs.twimg.com/media/G9dekfPWwAEgLDk?format=jpg&#x26;name=orig] Sebastian Raschka: http://x.com/i/article/2006014147733995520","published_date":"2025-12-31T01:30:43.774Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"2025 年 LLM 现状：进展、问题与预测，来自 @rasbt 分享，开始前再安利一次作者的书籍和开源资源<br><br>Build a Large Language Model (From Scratch)<br>https://github.com/rasbt/LLMs-from-scratch<br>Build A Reasoning Model (From Scratch)<br>https://github.com/rasbt/reasoning-from-scratch<br><br>1. 2025年：推理模型、RLVR 与 GRPO 之年<br>2025年最大的亮点是推理模型的爆发。这些模型通过生成中间推理步骤（如链式思考）显著提升复杂任务准确率。关键创新是 RLVR，结合 GRPO 算法，由 DeepSeek R1 模型在年初引入。<br>· RLVR 允许使用客观正确的奖励信号进行大规模后训练，而无需昂贵的人工标注。<br>· 这大幅降低了训练成本，并使开放权重模型迅速赶上专有模型。<br>· 随后，各大实验室纷纷推出推理变体，RLVR 成为后训练主流方法，取代了以往的 RLHF 和 PPO。<br><br>2. GRPO：年度研究宠儿<br>GRPO 算法在 2025 年被广泛改进和采用（如 Olmo 3、DeepSeek V3.2），通过过滤不良更新、调整KL散度和采样策略，提升训练稳定性和性能。它标志着强化学习在 LLM 领域的成熟应用。<br><br>3. LLM 架构：分叉之路？<br>· 主导架构仍是 Decoder-only Transformer + MoE，辅以效率优化（如分组查询注意力、多头潜注意力）。<br>· 新兴趋势：混合高效架构（如 Qwen3-Next的Gated DeltaNets、Kimi Linear、NVIDIA Nemotron 3 的 Mamba-2 层），实现序列长度线性扩展。<br>· 文本扩散模型（如 Google Gemini Diffusion）作为低延迟替代方案出现，但尚未主导前沿性能。<br><br>4. 推理时扩展与工具使用之年<br>· 推理时扩展（如自一致性、自精炼）成为提升复杂任务性能的重要手段，许多模型已在数学竞赛中达到金牌水平。<br>· 工具使用（调用搜索、计算器等外部工具）减少幻觉，成为代理系统标准。但开源生态在工具集成和安全性上仍落后于专有模型。<br><br>5. 年度热词：Benchmaxxing<br>基准测试过度优化问题突出：模型在公开基准上得分很高，但实际应用表现平平。原因包括训练数据污染和基准饱和。作者建议视基准为“阈值指标”，而非绝对能力衡量，并强调实际任务测试的重要性。<br><br>6. AI 在编码、写作与研究中的应用<br>· 编码：擅长处理重复性任务（如调试、代码清理），但专家知识仍不可替代。<br>· 写作/研究：帮助纠错、查找参考，但过度依赖可能导致技能退化和工作空洞化。 作者强调“先自己努力，再用 LLM 辅助”的原则，以保持学习和创造满足感。<br><br>7. 私域数据：新竞争优势<br>随着通用 scaling 定律趋于饱和，私有数据成为差异化关键。行业企业（如生物科技公司）倾向自建专有 LLM，利用开放基础模型（如 DeepSeek V3.2）进行领域适配。<br><br>8. 从零构建 LLM 与推理模型<br>作者分享个人工作：畅销书「Build a Large Language Model (From Scratch)」及续作「Build a Reasoning Model (From Scratch)」，涵盖推理时扩展、RLVR/GRPO 等最新技术。<br><br>9. 2025 年惊喜与 2026 年预测<br>2025 年主要惊喜（作者未预料到如此迅速发生）：<br>· 多个推理模型已在重大数学竞赛中达到金牌水平（如 OpenAI 未命名模型、Gemini Deep Think、DeepSeekMath-V2）。<br>· Llama 系列（包括 Llama 4）在开源社区大幅失宠，Qwen 凭借下载量和衍生模型数量成为新霸主。<br>· Mistral AI 的旗舰 Mistral 3 采用 DeepSeek V3 架构。<br>· 开源前沿模型竞争激烈，新选手涌现（如 Kimi、GLM、MiniMax）。<br>· 高效混合架构被领先实验室优先采用。<br>· OpenAI 意外发布开放权重模型 gpt-oss。<br>· MCP 协议迅速成为代理系统中工具/数据访问的标准。<br><br>对 2026 年的预测：<br>· 将出现行业级、低延迟消费级扩散模型（如 Gemini Diffusion 领先）。<br>· 开源社区逐步集成本地工具使用和更强智能体能力。<br>· RLVR 扩展至数学/编码以外领域（如化学、生物）。<br>· 传统 RAG 渐退，长上下文小模型将成为文档查询主流。<br>· 性能提升更多来自工具优化和推理时扩展，而非单纯核心模型训练；基准进步将聚焦减少无用推理步骤。<br><br>原文地址：<br>https://magazine.sebastianraschka.com/p/state-of-llms-2025<br><img width=\"2046\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9dekfPWwAEgLDk?format=jpg&#x26;name=orig\"><div><br><br>Sebastian Raschka: http://x.com/i/article/2006014147733995520<br></div>"}},{"id":"229026580041713666","type":"socialMedia","url":"https://x.com/shao__meng/status/2006171403528122454","title":"三个增强 Claude Code 实用性的开源工具，来自 @Yampeleg 分享推荐，感谢 ❤️ 1. WhatsApp bridge for Claude Code @steipete · 功能：允许用户通过 WhatsApp ...","description":"三个增强 Claude Code 实用性的开源工具，来自 @Yampeleg 分享推荐，感谢 ❤️ 1. WhatsApp bridge for Claude Code @steipete · 功能：允许用户通过 WhatsApp 直接与 Claude Code 互动，实现更便捷的移动端对话。 · 开源地址：https://github.com/steipete/clawdis 2. dev-browser @sawyerhood · 功能：提供可靠的浏览器自动化控制能力（作者尝试过多个同类工具，此为最稳定可靠的一个）。 · 开源地址：https://github.com/SawyerHood/dev-browser 3. Continuous-Claude-v2 @parcadei · 功能：一套相互协作的代码相关工具集，特别强调会话连续性（保持上下文）、上下文钩子以及 token 高效的工作流，帮助长时间编程任务更顺畅，“令人惊叹的工具集合”。 · 开源地址：https://github.com/parcadei/Continuous-Claude-v2 [图片: https://pbs.twimg.com/media/G9daHOxaYAAYt85?format=jpg&#x26;name=orig] Yam Peleg: Tools I actually use myself got Claude Code: 1. WhatsApp bridge for Claude Code: • warelay by @steipete • https://github.com/steipete/warelay 2. The best browser control plugin: (i tried them all, this is the most reliable) • dev-browser by @sawyerhood • https://github.com/SawyerHood/dev-browser 3.","published_date":"2025-12-31T01:11:50.387Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"三个增强 Claude Code 实用性的开源工具，来自 @Yampeleg 分享推荐，感谢 ❤️<br><br>1. WhatsApp bridge for Claude Code @steipete<br>· 功能：允许用户通过 WhatsApp 直接与 Claude Code 互动，实现更便捷的移动端对话。<br>· 开源地址：https://github.com/steipete/clawdis<br><br>2. dev-browser @sawyerhood<br>· 功能：提供可靠的浏览器自动化控制能力（作者尝试过多个同类工具，此为最稳定可靠的一个）。<br>· 开源地址：https://github.com/SawyerHood/dev-browser<br><br>3. Continuous-Claude-v2 @parcadei<br>· 功能：一套相互协作的代码相关工具集，特别强调会话连续性（保持上下文）、上下文钩子以及 token 高效的工作流，帮助长时间编程任务更顺畅，“令人惊叹的工具集合”。<br>· 开源地址：https://github.com/parcadei/Continuous-Claude-v2<br><img width=\"1668\" height=\"1276\" style=\"\" src=\"https://pbs.twimg.com/media/G9daHOxaYAAYt85?format=jpg&#x26;name=orig\"><div><br><br>Yam Peleg: Tools I actually use myself got Claude Code:<br><br>1. WhatsApp bridge for Claude Code:<br><br>• warelay by @steipete<br>• https://github.com/steipete/warelay<br><br>2. The best browser control plugin:<br>(i tried them all, this is the most reliable)<br><br>• dev-browser by @sawyerhood<br>• https://github.com/SawyerHood/dev-browser<br><br>3.<br></div>"}},{"id":"229016512015955969","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzxa7c/claude_gets_the_number_70_very_wrong_funny/","title":"Claude gets the number 70 very wrong (funny)","description":"The number 70 has some interesting properties. ∙ It’s a pronic number (also called an oblong number)—the product of two consecutive integers: 7 × 10 ∙ It’s the sum of the first seven prime numbers: 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 = 77… wait, let me recalculate that. Actually, 2 + 3 + 5 + 7 + 11 + 13 + 17 = 58, and adding 19 = 77. So that’s not quite right. Let me correct myself: 70 is the sum of the first four perfect squares: 1 + 4 + 9 + 16 + 25 + 36 = 91… that’s not it either. I should be more careful here—70 = 1² + 2² + 3² + 4² + 5² + 6² would be 91. Apologies for the false starts. What is true: 70 is a pentagonal number and a sphenic number (product of three distinct primes: 2 × 5 × 7). submitted by /u/ElroyFlynn [link] [comments]","published_date":"2025-12-30T23:31:50.292Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>The number 70 has some interesting properties.</p> <p>∙ It’s a pronic number (also called an oblong number)—the product of two consecutive integers: 7 × 10</p> <p>∙ It’s the sum of the first seven prime numbers: 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 = 77… wait, let me recalculate that. </p> <p>Actually, 2 + 3 + 5 + 7 + 11 + 13 + 17 = 58, and adding 19 = 77. So that’s not quite right. </p> <p>Let me correct myself: 70 is the sum of the first four perfect squares: 1 + 4 + 9 + 16 + 25 + 36 = 91… that’s not it either. I should be more careful here—70 = 1² + 2² + 3² + 4² + 5² + 6² would be 91. </p> <p>Apologies for the false starts. What is true: 70 is a pentagonal number and a sphenic number (product of three distinct primes: 2 × 5 × 7).</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/ElroyFlynn\" target=\"_blank\"> /u/ElroyFlynn </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzxa7c/claude_gets_the_number_70_very_wrong_funny/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzxa7c/claude_gets_the_number_70_very_wrong_funny/\" target=\"_blank\">[comments]</a></span>"}},{"id":"229016512015955970","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzwvws/artificial_intelligence_myths_have_existed_for/","title":"'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot","description":"[图片: 'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot https://external-preview.redd.it/PRwd6xRRA_JNo9pxNCL8AmAlq2kHlDL4W-9n2GsuF4Q.png?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=a927f096729aadb2f6c80953398f448d0aef02db] submitted by /u/Fcking_Chuck [link] [comments]","published_date":"2025-12-30T23:15:00.867Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1pzwvws/artificial_intelligence_myths_have_existed_for/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/PRwd6xRRA_JNo9pxNCL8AmAlq2kHlDL4W-9n2GsuF4Q.png?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=a927f096729aadb2f6c80953398f448d0aef02db\" alt=\"'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot\" title=\"'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/Fcking_Chuck\" target=\"_blank\"> /u/Fcking_Chuck </a> <br> <span><a href=\"https://www.livescience.com/archaeology/artificial-intelligence-myths-have-existed-for-centuries-from-the-ancient-greeks-to-a-popes-chatbot\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzwvws/artificial_intelligence_myths_have_existed_for/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"228980460781893632","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzw2z8/d_what_to_learn_next_to_secure_a_ml_role_after/","title":"[D] What to learn next to secure a ML role after graduation?","description":"Hi, I'm graduating from a UK bachelor degree soon and looking to secure a job relating to machine learning or AI. I have: - 12 month internship experience working on deep learning - Covered much of the basics and fundamental architectures in my course, i.e. differentiation, supervised, unsupervised and reinforcement learning. - Architectures like MLP, RNN, LSTM, Transformer, CNN, etc are all covered as well. - Also covered diffusion models. There is a real possibility I won't get into a graduate scheme before graduation, so I'm planning ahead to apply to non-graduate roles closer to my graduation. I was wondering what else I should learn to improve my skill and/or potential in securing those non-graduate ML roles? submitted by /u/PositiveInformal9512 [link] [comments]","published_date":"2025-12-30T22:42:05.368Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>Hi, I'm graduating from a UK bachelor degree soon and looking to secure a job relating to machine learning or AI.</p> <p>I have:<br> - 12 month internship experience working on deep learning<br> - Covered much of the basics and fundamental architectures in my course, i.e. differentiation, supervised, unsupervised and reinforcement learning.</p> <p>- Architectures like MLP, RNN, LSTM, Transformer, CNN, etc are all covered as well.</p> <p>- Also covered diffusion models.</p> <p>There is a real possibility I won't get into a graduate scheme before graduation, so I'm planning ahead to apply to non-graduate roles closer to my graduation.</p> <p>I was wondering what else I should learn to improve my skill and/or potential in securing those non-graduate ML roles?</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/PositiveInformal9512\" target=\"_blank\"> /u/PositiveInformal9512 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzw2z8/d_what_to_learn_next_to_secure_a_ml_role_after/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzw2z8/d_what_to_learn_next_to_secure_a_ml_role_after/\" target=\"_blank\">[comments]</a></span>"}},{"id":"229016512015955971","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzvzxm/need_good_ai_resources/","title":"Need Good AI Resources","description":"Hey everyone, I am currently putting together a list of AI/ML resources and tools that I find helpful: chatbots, video/image creators, music creators, coding helpers, etc. It’s here if you want to see what I’ve got so far: https://top-ai-sites.com I’m 100% sure I’ve missed a ton of good stuff, so I’d love your help. If you have go-to sites for research, learning or fun (not just random AI tool spam), please drop them in the comments. I’m planning to keep updating the list and to make this more of a helpful community index than just another link list. Thanks! submitted by /u/M3ltd0wn_ [link] [comments]","published_date":"2025-12-30T22:38:21.832Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Hey everyone,</p> <p>I am currently putting together a list of AI/ML resources and tools that I find helpful: chatbots, video/image creators, music creators, coding helpers, etc. It’s here if you want to see what I’ve got so far: <a href=\"https://top-ai-sites.com\" target=\"_blank\">https://top-ai-sites.com</a></p> <p>I’m 100% sure I’ve missed a ton of good stuff, so I’d love your help.</p> <p>If you have go-to sites for research, learning or fun (not just random AI tool spam), please drop them in the comments. </p> <p>I’m planning to keep updating the list and to make this more of a helpful community index than just another link list.</p> <p>Thanks!</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/M3ltd0wn_\" target=\"_blank\"> /u/M3ltd0wn_ </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzvzxm/need_good_ai_resources/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzvzxm/need_good_ai_resources/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893633","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzvr8b/d_aiml_self_hosted_software_that_can_be_run_on/","title":"[D] AI/ML self hosted software that can be run on off the shelf cameras and detects smoke or fire?","description":"Can be deployed on a raspberry pi or similar hardware setup using consumer level cameras. No clue why the current ones like wyze/ring don't have this feature. Would be a great in my opinion. Thanks. submitted by /u/SedimentaryLife [link] [comments]","published_date":"2025-12-30T22:27:55.328Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>Can be deployed on a raspberry pi or similar hardware setup using consumer level cameras. No clue why the current ones like wyze/ring don't have this feature. Would be a great in my opinion. Thanks.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/SedimentaryLife\" target=\"_blank\"> /u/SedimentaryLife </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzvr8b/d_aiml_self_hosted_software_that_can_be_run_on/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzvr8b/d_aiml_self_hosted_software_that_can_be_run_on/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893634","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzv7bh/p_edgevec_v070_browsernative_vector_database_with/","title":"[P] EdgeVec v0.7.0: Browser-Native Vector Database with 8.75x Faster Hamming Distance via SIMD","description":"I've been building **EdgeVec**, an open-source vector database that runs entirely in the browser via WebAssembly. With v0.7.0, we're shipping significant SIMD optimizations and celebrating our first community contribution. ### What is EdgeVec? EdgeVec is a lightweight vector search engine designed for: - **Browser-based RAG applications** - Run retrieval-augmented generation without server roundtrips - **Semantic search in web apps** - Build search experiences that understand meaning, not just keywords - **Offline-first AI tools** - Your embeddings and data never leave the user's device It works with embeddings from any provider: **OpenAI** (text-embedding-3-small/large), **Cohere** (embed-english-v3), **HuggingFace** (all-MiniLM, BGE, etc.), or your own fine-tuned models. ### v0.7.0 Highlights **1. 8.75x Faster Hamming Distance (Community Contribution)** Our first external contributor [@jsonMartin]( https://github.com/jsonMartin ) implemented WASM SIMD128 Hamming distance computation. For binary-quantized vectors: | Operation | Before | After | Speedup | |:----------|:-------|:------|:--------| | Hamming Distance | 87.5 ns | 10.0 ns | **8.75x** | This uses the `v128.popcnt` instruction available in modern browsers, making binary vector search extremely fast. **2. Binary Quantization: 32x Memory Reduction** Store 1536-dim embeddings (OpenAI large) in just 48 bytes instead of 6144 bytes: - **32x memory reduction** with typical **95%+ recall retention** - Makes million-vector indices practical in browser memory - Automatic projection + binarization pipeline **3. SIMD-Accelerated Euclidean Distance (3.2x faster)** Previous release added SIMD for Euclidean/cosine, this release extends SIMD coverage: ``` Euclidean Distance (1536-dim): Scalar: ~450 ns SIMD: ~140 ns (3.2x faster) ``` ### Technical Architecture ``` +-------------------------------------------------------------+ | Your Web Application | +-------------------------------------------------------------+ | EdgeVec (WASM) | | +-- Vector Storage (flat + binary-quantized) | | +-- SIMD Kernels (f32 ops, Hamming distance) | | +-- Cosine / Euclidean / Hamming similarity | | +-- Persistence (IndexedDB via idb-keyval) | +-------------------------------------------------------------+ | Browser Runtime | | +-- WebAssembly + SIMD128 (Chrome 91+, Firefox 89+) | +-------------------------------------------------------------+ ``` ### Code Example: RAG with OpenAI Embeddings ```javascript import init, { EdgeVec, EdgeVecConfig } from 'edgevec'; // Initialize WASM await init(); // Create index for OpenAI embeddings (1536D) const config = new EdgeVecConfig(1536); const db = new EdgeVec(config); db.enableBQ(); // Enable binary quantization for 32x compression // Index your documents for (const doc of documents) { const embedding = await openai.embeddings.create({ model: 'text-embedding-3-small', input: doc.text }); db.insertWithMetadata( new Float32Array(embedding.data[0].embedding), { id: doc.id , title: doc.title } ); } // Semantic search - runs locally, no API call const queryEmbedding = await openai.embeddings.create({ model: 'text-embedding-3-small', input: userQuery }); // BQ search with rescoring for 95%+ recall const results = db.searchBQRescored( new Float32Array(queryEmbedding.data[0].embedding), 5, // k 3 // rescore_factor ); // Use top-k results for RAG context ``` ### Why Browser-Native Matters for ML Applications **Privacy**: Embeddings contain semantic information about your data. Running locally means sensitive data never leaves the device. **Latency**: Eliminate network roundtrips. Search is sub-millisecond after embeddings are computed. **Offline capability**: Applications work without internet after initial embedding computation. **Cost**: No vector database hosting costs. Users' browsers provide the compute. ### Benchmarks (100k vectors, 768-dim) | Operation | Performance | |:----------|:------------| | Insert (binary quant) | 15,000 vec/sec | | Search k=10 (binary) | 1.2ms | | Memory per vector | 48 bytes (binary) vs 3072 bytes (f32) | ### Links - **GitHub**: https://github.com/matte1782/edgevec - **Live Demo**: https://matte1782.github.io/edgevec/demo/ - **npm**: https://www.npmjs.com/package/edgevec - **Docs**: https://github.com/matte1782/edgevec#readme ### What's Next - [ ] IVF indexing for sub-linear search on large indices - [ ] Product quantization (PQ) for more compression options - [ ] Streaming insert API for real-time applications Would love feedback from the ML community, especially on: - Embedding dimension / model combinations you'd want optimized - Use cases where browser-native search would be valuable - Performance comparisons you'd like to see **License**: MIT --- ## Post Metadata - **Flair**: [P] (Project) - **Crosspost to**: r/rust , r/webdev , r/LocalLLaMA submitted by /u/Complex_Ad_148 [link] [comments]","published_date":"2025-12-30T22:04:46.681Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>I've been building **EdgeVec**, an open-source vector database that runs entirely in the browser via WebAssembly. With v0.7.0, we're shipping significant SIMD optimizations and celebrating our first community contribution.</p> <p>### What is EdgeVec?</p> <p>EdgeVec is a lightweight vector search engine designed for:</p> <p>- **Browser-based RAG applications** - Run retrieval-augmented generation without server roundtrips</p> <p>- **Semantic search in web apps** - Build search experiences that understand meaning, not just keywords</p> <p>- **Offline-first AI tools** - Your embeddings and data never leave the user's device</p> <p>It works with embeddings from any provider: **OpenAI** (text-embedding-3-small/large), **Cohere** (embed-english-v3), **HuggingFace** (all-MiniLM, BGE, etc.), or your own fine-tuned models.</p> <p>### v0.7.0 Highlights</p> <p>**1. 8.75x Faster Hamming Distance (Community Contribution)**</p> <p>Our first external contributor [@jsonMartin](<a href=\"https://github.com/jsonMartin\" target=\"_blank\">https://github.com/jsonMartin</a>) implemented WASM SIMD128 Hamming distance computation. For binary-quantized vectors:</p> <p>| Operation | Before | After | Speedup |</p> <p>|:----------|:-------|:------|:--------|</p> <p>| Hamming Distance | 87.5 ns | 10.0 ns | **8.75x** |</p> <p>This uses the `v128.popcnt` instruction available in modern browsers, making binary vector search extremely fast.</p> <p>**2. Binary Quantization: 32x Memory Reduction**</p> <p>Store 1536-dim embeddings (OpenAI large) in just 48 bytes instead of 6144 bytes:</p> <p>- **32x memory reduction** with typical **95%+ recall retention**</p> <p>- Makes million-vector indices practical in browser memory</p> <p>- Automatic projection + binarization pipeline</p> <p>**3. SIMD-Accelerated Euclidean Distance (3.2x faster)**</p> <p>Previous release added SIMD for Euclidean/cosine, this release extends SIMD coverage:</p> <p>```</p> <p>Euclidean Distance (1536-dim):</p> <p>Scalar: ~450 ns</p> <p>SIMD: ~140 ns (3.2x faster)</p> <p>```</p> <p>### Technical Architecture</p> <p>```</p> <p>+-------------------------------------------------------------+</p> <p>| Your Web Application |</p> <p>+-------------------------------------------------------------+</p> <p>| EdgeVec (WASM) |</p> <p>| +-- Vector Storage (flat + binary-quantized) |</p> <p>| +-- SIMD Kernels (f32 ops, Hamming distance) |</p> <p>| +-- Cosine / Euclidean / Hamming similarity |</p> <p>| +-- Persistence (IndexedDB via idb-keyval) |</p> <p>+-------------------------------------------------------------+</p> <p>| Browser Runtime |</p> <p>| +-- WebAssembly + SIMD128 (Chrome 91+, Firefox 89+) |</p> <p>+-------------------------------------------------------------+</p> <p>```</p> <p>### Code Example: RAG with OpenAI Embeddings</p> <p>```javascript</p> <p>import init, { EdgeVec, EdgeVecConfig } from 'edgevec';</p> <p>// Initialize WASM</p> <p>await init();</p> <p>// Create index for OpenAI embeddings (1536D)</p> <p>const config = new EdgeVecConfig(1536);</p> <p>const db = new EdgeVec(config);</p> <p>db.enableBQ(); // Enable binary quantization for 32x compression</p> <p>// Index your documents</p> <p>for (const doc of documents) {</p> <p>const embedding = await openai.embeddings.create({</p> <p>model: 'text-embedding-3-small',</p> <p>input: doc.text</p> <p>});</p> <p>db.insertWithMetadata(</p> <p>new Float32Array(embedding.data[0].embedding),</p> <p>{ id: <a href=\"http://doc.id\" target=\"_blank\">doc.id</a>, title: doc.title }</p> <p>);</p> <p>}</p> <p>// Semantic search - runs locally, no API call</p> <p>const queryEmbedding = await openai.embeddings.create({</p> <p>model: 'text-embedding-3-small',</p> <p>input: userQuery</p> <p>});</p> <p>// BQ search with rescoring for 95%+ recall</p> <p>const results = db.searchBQRescored(</p> <p>new Float32Array(queryEmbedding.data[0].embedding),</p> <p>5, // k</p> <p>3 // rescore_factor</p> <p>);</p> <p>// Use top-k results for RAG context</p> <p>```</p> <p>### Why Browser-Native Matters for ML Applications</p> <ol> <li><p>**Privacy**: Embeddings contain semantic information about your data. Running locally means sensitive data never leaves the device.</p></li> <li><p>**Latency**: Eliminate network roundtrips. Search is sub-millisecond after embeddings are computed.</p></li> <li><p>**Offline capability**: Applications work without internet after initial embedding computation.</p></li> <li><p>**Cost**: No vector database hosting costs. Users' browsers provide the compute.</p></li> </ol> <p>### Benchmarks (100k vectors, 768-dim)</p> <p>| Operation | Performance |</p> <p>|:----------|:------------|</p> <p>| Insert (binary quant) | 15,000 vec/sec |</p> <p>| Search k=10 (binary) | 1.2ms |</p> <p>| Memory per vector | 48 bytes (binary) vs 3072 bytes (f32) |</p> <p>### Links</p> <p>- **GitHub**: <a href=\"https://github.com/matte1782/edgevec\" target=\"_blank\">https://github.com/matte1782/edgevec</a></p> <p>- **Live Demo**: <a href=\"https://matte1782.github.io/edgevec/demo/\" target=\"_blank\">https://matte1782.github.io/edgevec/demo/</a></p> <p>- **npm**: <a href=\"https://www.npmjs.com/package/edgevec\" target=\"_blank\">https://www.npmjs.com/package/edgevec</a></p> <p>- **Docs**: <a href=\"https://github.com/matte1782/edgevec#readme\" target=\"_blank\">https://github.com/matte1782/edgevec#readme</a></p> <p>### What's Next</p> <p>- [ ] IVF indexing for sub-linear search on large indices</p> <p>- [ ] Product quantization (PQ) for more compression options</p> <p>- [ ] Streaming insert API for real-time applications</p> <p>Would love feedback from the ML community, especially on:</p> <p>- Embedding dimension / model combinations you'd want optimized</p> <p>- Use cases where browser-native search would be valuable</p> <p>- Performance comparisons you'd like to see</p> <p>**License**: MIT</p> <p>---</p> <p>## Post Metadata</p> <p>- **Flair**: [P] (Project)</p> <p>- **Crosspost to**: <a href=\"/r/rust\" target=\"_blank\">r/rust</a>, <a href=\"/r/webdev\" target=\"_blank\">r/webdev</a>, <a href=\"/r/LocalLLaMA\" target=\"_blank\">r/LocalLLaMA</a></p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Complex_Ad_148\" target=\"_blank\"> /u/Complex_Ad_148 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzv7bh/p_edgevec_v070_browsernative_vector_database_with/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzv7bh/p_edgevec_v070_browsernative_vector_database_with/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893635","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pztniz/n_acl_2026_arr_jan_2026_no_rebuttal_period/","title":"[N] ACL 2026 (ARR Jan 2026), No Rebuttal period?","description":"I noticed that there is no rebuttal and discussion period in ARR Jan 2026 cycle. It seems like we will directly get reviews and the meta reviewer score and make a decision to commit to ACL 2026. From my past experience with ARR cycles reviewers have mostly not responded to the rebuttal let alone increase the score. submitted by /u/Healthy_Horse_2183 [link] [comments]","published_date":"2025-12-30T21:01:26.869Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>I noticed that there is no rebuttal and discussion period in ARR Jan 2026 cycle. It seems like we will directly get reviews and the meta reviewer score and make a decision to commit to ACL 2026. From my past experience with ARR cycles reviewers have mostly not responded to the rebuttal let alone increase the score.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Healthy_Horse_2183\" target=\"_blank\"> /u/Healthy_Horse_2183 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pztniz/n_acl_2026_arr_jan_2026_no_rebuttal_period/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pztniz/n_acl_2026_arr_jan_2026_no_rebuttal_period/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893636","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzsx3i/p_topasdspl_a_15m_param_dualstream_recursive/","title":"[P] TOPAS-DSPL: A 15M param Dual-Stream Recursive Transformer achieving 24% on ARC-2","description":"Abstract: We have released the code and weights for TOPAS-DSPL , a neuro-symbolic baseline designed to test the efficacy of \"Bicameral\" latent spaces in small-scale reasoning models. By separating algorithmic planning ( Logic Stream ) from execution state ( Canvas Stream ) via Dynamic AdaLN conditioning, we observed a reduction in \"Compositional Drift\" compared to monolithic recursive models (e.g., TRM). Experimental Results: Benchmark: ARC-AGI-2 Evaluation Set Accuracy: 24% (Exact Match) Baseline Comparison: ~3x improvement over standard Tiny Recursive Models (~8%). Parameter Count: ~15M (Consumer hardware accessible) Methodology: The architecture addresses the \"forgetting\" problem in recursive loops by functionally decoupling the rule generation from the state update. The Logic Stream acts as a controller, modulating the Canvas Stream's weights at each timestep. We utilized Test-Time Training (TTT) for instance-specific adaptation and MuonClip for optimization stability. Reproduction: We have open-sourced the full training pipeline, data augmentation scripts, and evaluation harness to allow for independent verification of these results. We (Bitterbot AI) are very excited about this and I'll just say, one of the many reasons is because this is actually are least accurate and efficient model - this is the one we are comfortable open sourcing with the public. But we have already achieved MUCH more. I do not want this to be flagged for self promotion or spam so I will add a link to our repo (code) and paper below. submitted by /u/Doug_Bitterbot [link] [comments]","published_date":"2025-12-30T20:31:28.710Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p><strong>Abstract:</strong> We have released the code and weights for <strong>TOPAS-DSPL</strong>, a neuro-symbolic baseline designed to test the efficacy of \"Bicameral\" latent spaces in small-scale reasoning models.</p> <p>By separating algorithmic planning (<strong>Logic Stream</strong>) from execution state (<strong>Canvas Stream</strong>) via Dynamic AdaLN conditioning, we observed a reduction in \"Compositional Drift\" compared to monolithic recursive models (e.g., TRM).</p> <p><strong>Experimental Results:</strong></p> <ul> <li><strong>Benchmark:</strong> ARC-AGI-2 Evaluation Set</li> <li><strong>Accuracy:</strong> 24% (Exact Match)</li> <li><strong>Baseline Comparison:</strong> ~3x improvement over standard Tiny Recursive Models (~8%).</li> <li><strong>Parameter Count:</strong> ~15M (Consumer hardware accessible)</li> </ul> <p><strong>Methodology:</strong> The architecture addresses the \"forgetting\" problem in recursive loops by functionally decoupling the rule generation from the state update. The Logic Stream acts as a controller, modulating the Canvas Stream's weights at each timestep. We utilized <strong>Test-Time Training (TTT)</strong> for instance-specific adaptation and <strong>MuonClip</strong> for optimization stability.</p> <p><strong>Reproduction:</strong> We have open-sourced the full training pipeline, data augmentation scripts, and evaluation harness to allow for independent verification of these results.</p> <p>We (Bitterbot AI) are very excited about this and I'll just say, one of the many reasons is because this is actually are least accurate and efficient model - this is the one we are comfortable open sourcing with the public. But we have already achieved MUCH more.</p> <p>I do not want this to be flagged for self promotion or spam so I will add a link to our repo (code) and paper below.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Doug_Bitterbot\" target=\"_blank\"> /u/Doug_Bitterbot </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzsx3i/p_topasdspl_a_15m_param_dualstream_recursive/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzsx3i/p_topasdspl_a_15m_param_dualstream_recursive/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893637","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzrfbf/p_the_state_of_llms_2025_progress_problems_and/","title":"[P] The State Of LLMs 2025: Progress, Problems, and Predictions","description":"[图片: [P] The State Of LLMs 2025: Progress, Problems, and Predictions https://external-preview.redd.it/ip3t1phQ469yOBa2kbOD__RHIhAqj8C7dU-KA_Pn0lI.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=859212246454f6bb28f9d882875d0a6ae9694d87] submitted by /u/seraschka [link] [comments]","published_date":"2025-12-30T19:33:26.793Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzrfbf/p_the_state_of_llms_2025_progress_problems_and/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/ip3t1phQ469yOBa2kbOD__RHIhAqj8C7dU-KA_Pn0lI.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=859212246454f6bb28f9d882875d0a6ae9694d87\" alt=\"[P] The State Of LLMs 2025: Progress, Problems, and Predictions\" title=\"[P] The State Of LLMs 2025: Progress, Problems, and Predictions\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/seraschka\" target=\"_blank\"> /u/seraschka </a> <br> <span><a href=\"https://magazine.sebastianraschka.com/p/state-of-llms-2025\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzrfbf/p_the_state_of_llms_2025_progress_problems_and/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"228933042865666048","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzqr9e/alexa_ai_overreach/","title":"Alexa+ AI overreach","description":"Normally I'm not one to make a big deal about overly-intrusive AI. Google putting AI summary at the top of the search order? Meh, sometimes a useful synopsis, sometimes just something to scroll past along with sponsored results. Copilot putting up little notifications encouraging me to use AI? Annoying, but you can click the X or just ignore them. Amazon took it a step further, and this one grinds my gears. My Echo Show 8 started plugging Alexa+ at the end of responses or on the screen a couple months ago, and it was a few weeks before the advertising confirmed my suspicion that it was an AI platform. Whatever, I didn't want it enough to opt in and ignored the advertising. Then it integrated the AI without an opt-in. Again, I rolled my eyes at the slightly more talkative software. It was slightly better at getting my song requests right so I didn't mind. Here's the line in the sand for me. You know how ChatGPT is known for asking questions at the end of responses to prompt more user feedback? My Echo cues up the mic after it responds to instructions. Play a playlist, add an item to the shopping list, read the day's weather? The echo responds, then turns on the mic again. I've yelled at it to shut up or stop prompting for more input and it just gives a snarky response. I'm not one to say \"oh my god they're spying on you,\" but this is REALLY intrusive. To me, this is AI overreach. submitted by /u/DrunkenBandit1 [link] [comments]","published_date":"2025-12-30T19:07:45.339Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Normally I'm not one to make a big deal about overly-intrusive AI. Google putting AI summary at the top of the search order? Meh, sometimes a useful synopsis, sometimes just something to scroll past along with sponsored results. Copilot putting up little notifications encouraging me to use AI? Annoying, but you can click the X or just ignore them.</p> <p>Amazon took it a step further, and this one grinds my gears. </p> <p>My Echo Show 8 started plugging Alexa+ at the end of responses or on the screen a couple months ago, and it was a few weeks before the advertising confirmed my suspicion that it was an AI platform. Whatever, I didn't want it enough to opt in and ignored the advertising.</p> <p>Then it integrated the AI without an opt-in. Again, I rolled my eyes at the slightly more talkative software. It was slightly better at getting my song requests right so I didn't mind. </p> <p>Here's the line in the sand for me. You know how ChatGPT is known for asking questions at the end of responses to prompt more user feedback? </p> <p>My Echo cues up the mic after it responds to instructions. Play a playlist, add an item to the shopping list, read the day's weather? The echo responds, then turns on the mic again. I've yelled at it to shut up or stop prompting for more input and it just gives a snarky response. </p> <p>I'm not one to say \"oh my god they're spying on you,\" but this is REALLY intrusive. To me, this is AI overreach. </p> </div>   submitted by   <a href=\"https://www.reddit.com/user/DrunkenBandit1\" target=\"_blank\"> /u/DrunkenBandit1 </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqr9e/alexa_ai_overreach/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqr9e/alexa_ai_overreach/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228933042865666049","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzqa9z/my_son_and_i_vibecoded_our_first_game_called/","title":"My son and I vibecoded our first game called SUPERSNAKES using Gemini","description":"Using Google's Antigravity with the help of Gemini 3 pro and a bit of Claude my son and I created our first game called SUPERSNAKES. You can play for free at: https://supersnakes.io/ It's a spin-off from the popular IO snake game genre. But rather than just cutting off snakes, this game contains a few extra features. Pickup power-up elements on the playfield to get upgrades, but watch out for the bombs. Every minute a boss snake spawns which you can only kill with a gun. Pickup a gun from the playing field when a boss as active to try and kill it. Unlock skins by getting more points, and boss skins by killing them. It took about 3-4 weeks of vibecoding to get where we are now. submitted by /u/RealMrBoon [link] [comments]","published_date":"2025-12-30T18:50:18.371Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Using Google's Antigravity with the help of Gemini 3 pro and a bit of Claude my son and I created our first game called SUPERSNAKES.</p> <p>You can play for free at: <a href=\"https://supersnakes.io/\" target=\"_blank\">https://supersnakes.io/</a></p> <p>It's a spin-off from the popular IO snake game genre. But rather than just cutting off snakes, this game contains a few extra features. Pickup power-up elements on the playfield to get upgrades, but watch out for the bombs.</p> <p>Every minute a boss snake spawns which you can only kill with a gun. Pickup a gun from the playing field when a boss as active to try and kill it.</p> <p>Unlock skins by getting more points, and boss skins by killing them.</p> <p>It took about 3-4 weeks of vibecoding to get where we are now.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/RealMrBoon\" target=\"_blank\"> /u/RealMrBoon </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqa9z/my_son_and_i_vibecoded_our_first_game_called/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqa9z/my_son_and_i_vibecoded_our_first_game_called/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228901489340335104","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzq50l/r_new_ssm_architecture_exceeds_transformer/","title":"[R] New SSM architecture (exceeds Transformer baseline) - reproducible benchmarks (feedback wanted)","description":"Transformers have revolutionized natural language processing, but their O(L^2) complexity limits their applicability to very long sequences. Recent advances in SSMs and Linear Attention have proposed O(L) alternatives. This new SSM contributes to this line of work by combining the ability of delta-rule updates with the representational power of gated convolutions. You can reproduce the results and find more information here (github): exponentialXP/GDN: Gated Delta Networks as a novel sequence modelling architecture with O(n) complexity and is a strong baseline. This new SSM exceeds our transformer baseline's speed and performance/loss significantly at even relatively small sequence lengths, with mildly optimised triton kernels. I need your help - please suggest ways to improve this architecture! submitted by /u/Otherwise-Desk5672 [link] [comments]","published_date":"2025-12-30T18:44:54.408Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p><a href=\"https://www.reddit.com/r/MachineLearning/?f=flair_name%3A%22Discussion%22\" target=\"_blank\"></a>Transformers have revolutionized natural language processing, but their O(L^2) complexity limits their applicability to very long sequences. Recent advances in SSMs and Linear Attention have proposed O(L) alternatives. This new SSM contributes to this line of work by combining the ability of delta-rule updates with the representational power of gated convolutions.</p> <p>You can reproduce the results and find more information here (github): <a href=\"https://github.com/exponentialXP/GDN\" target=\"_blank\">exponentialXP/GDN: Gated Delta Networks as a novel sequence modelling architecture with O(n) complexity and is a strong baseline.</a></p> <p>This new SSM exceeds our transformer baseline's speed and performance/loss significantly at even relatively small sequence lengths, with mildly optimised triton kernels.</p> <p>I need your help - please suggest ways to improve this architecture!</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Otherwise-Desk5672\" target=\"_blank\"> /u/Otherwise-Desk5672 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzq50l/r_new_ssm_architecture_exceeds_transformer/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzq50l/r_new_ssm_architecture_exceeds_transformer/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228933042865666050","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pznrz8/tencent_hymotion_10_a_billionparameter/","title":"Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model","description":"[图片: Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model https://preview.redd.it/yq8uriwhxaag1.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=d990cf5383783b3e2aa22351ddeb29ebac5eb2b2] submitted by /u/jferments [link] [comments]","published_date":"2025-12-30T17:16:24.018Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1pznrz8/tencent_hymotion_10_a_billionparameter/\" target=\"_blank\"> <img src=\"https://preview.redd.it/yq8uriwhxaag1.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=d990cf5383783b3e2aa22351ddeb29ebac5eb2b2\" alt=\"Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model\" title=\"Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/jferments\" target=\"_blank\"> /u/jferments </a> <br> <span><a href=\"https://i.redd.it/yq8uriwhxaag1.jpeg\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pznrz8/tencent_hymotion_10_a_billionparameter/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"228901489340335105","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzndfo/d_phd_parttime_remotely_in_mldl/","title":"[D] PhD part-time remotely in ML/DL?","description":"Hello, so basically I am full-time working, but I am interested in doing a PhD in Applied AI, basically in argument mining, and I am interested to see if there are chances in Europe or elsewhere to do it on a part-time basis while working in Europe. I have a masters in Applied AI, that is industrial oriented and thus can't pursue a PhD with in France, but outside it is possible, any programs you know of, cheap and flexible ? Thanks submitted by /u/jiii95 [link] [comments]","published_date":"2025-12-30T17:01:06.718Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>Hello, so basically I am full-time working, but I am interested in doing a PhD in Applied AI, basically in argument mining, and I am interested to see if there are chances in Europe or elsewhere to do it on a part-time basis while working in Europe. I have a masters in Applied AI, that is industrial oriented and thus can't pursue a PhD with in France, but outside it is possible, any programs you know of, cheap and flexible ? Thanks</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/jiii95\" target=\"_blank\"> /u/jiii95 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzndfo/d_phd_parttime_remotely_in_mldl/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzndfo/d_phd_parttime_remotely_in_mldl/\" target=\"_blank\">[comments]</a></span>"}}]