[{"id":"229106264099013632","type":"news","url":"https://www.jiqizhixin.com/articles/2025-12-31-6","title":"卓驭打造科技平权，端到端辅助驾驶延伸至重卡高速、无人物流","description":"12 月 30 日，卓驭品牌盛典 2025 在深圳举行。 不同于常规的技术参数发布会，本次卓驭科技的发布更侧重技术路线阐释、工程哲学与未来布局。 [图片: https://image.jiqizhixin.com/uploads/editor/451dfb1d-22e4-4bcf-8346-e497dd023433/QQ20251231-161006.jpg] 作为从大疆独立仅一年多的智能驾驶公司，卓驭首次系统对外解读了其从规则驱动到数据驱动的技术转型、软硬一体的工程能力，以及从乘用车向商用车等多场景延伸的战略路径。 卓驭科技 CEO 沈劭劼在演讲中系统回顾了卓驭团队自 2016 年创立至今、从大疆车载迈向独立主体的发展历程，介绍了多模态端到端世界模型体系，并宣告了其 “数据驱动的空间智能移动基座” 正式成型。 卓驭的技术根基源自大疆的机器人工程基因，早期沿用规则驱动方案。但随着智能驾驶场景复杂度提升，基于规则的辅助驾驶系统陷入了 “解决一个问题，冒出十个新问题” 的工程困境。 2024 年 10 月 14 日，卓驭做出关键决策：全删原有代码库，全面转向端到端架构。在转型初期，团队面临模型不成熟、交付压力大、输出不稳定等多重挑战，但最终探索出一条差异化的技术路径。 借鉴 “巧力出奇迹” 的总体思路，卓驭不盲目堆算力与参数量，而是将视觉 - 语言 - 动作（VLA）模型拆解为多个可解释、可分工的模块。他们以较低成本攻克了行业公认的 “因果推理” 与 “低频数据生成” 两大难题，实现了端到端系统在中等算力平台上的可用性与可部署性。 卓驭提供高质量、低价格的辅助驾驶解决方案，通过极致优化，能够让 10 万元级车型也能具备城市领航辅助驾驶能力：其在地平线征程 8650 芯片上实现性能媲美 Orin X，通过网络压缩与优化，将端到端网络成功部署在 TI TDA4 等中算力平台，实现了 “中算力城市 NOA”。 与此同时，卓驭推出高通 8775 舱驾一体方案，以单芯片同时驱动智能座舱与智能驾驶系统，推动了整车架构向中央计算的方向演进。 历时九年，卓驭的辅助驾驶系统已历经千万公里真实道路的考验，卓驭也已经从行业新生力量成长为业界领军企业，乘用车领域覆盖 9 大客户 15 大品牌，量产覆盖 50 多个车型和所有动力构型，此外还有 30 + 款即将量产车型。 [图片: https://image.jiqizhixin.com/uploads/editor/73703826-6a81-4e1d-ac18-a52da2ee00ac/QQ20251231-160528.jpg] 卓驭着重建设 “全场景兜底能力”，希望通过持续建设全流程产业链能力、完善的软硬件能力，以及对客户 “产品交付”、对用户 “不放弃每一位” 的兜底能力。 基于这一判断，卓驭选择在统一架构上向上延展，而非重新搭建高算力方案。从 TDA4（中算力）到 8650 及更高算力平台，再到 8775（舱驾一体），其核心架构保持一致且可规模化复用。 目前，卓驭已推出两大高算力方案：一是 L3/L4 方案，搭载两块 Thor 芯片，配合自研激目前向感知系统和知周补盲雷达；二是舱驾一体方案，采用高通 SA8797，将 VLA 融入统一架构。基于对算力的极致运用，卓驭的工程实力获得英伟达、德州仪器等芯片厂商认可 ——“同样的芯片，在我们手里能跑出更高的效率”。\" 面向未来，卓驭希望构建空间智能的移动基座，引领自主移动机器人时代，其技术能力将不再局限于乘用车辅助驾驶，而是依托数据驱动的开发范式、成熟的基座模型及软硬一体的工程能力，将移动智能的边界拓展至商用车等更广泛的业务场景。 [图片: https://image.jiqizhixin.com/uploads/editor/2e0a68be-8bec-42f3-8929-5ed313113a8d/QQ20251231-160615.jpg] 卓驭宣布，在 2026 年上半年会上线重卡 NOA 辅助驾驶。 目前，卓驭已启动重卡高速 NOA 项目，旨在解决重卡司机长时间驾驶疲劳的痛点，提升干线物流的安全与效率水平，且已与徐工、陕汽、重汽三大业界头部客户确立合作，首批重卡车型将于 2026 年上半年正式量产。 基于端到端的辅助驾驶方式，正在为智能的泛化提供便利。卓驭透露，从乘用车到重卡的能力迁移，所需的时间不超过 1 个月。 [图片: https://image.jiqizhixin.com/uploads/editor/4cacd87b-d570-4a4f-9085-b1675e333c75/QQ20251231-160722.jpg] 同时，卓驭正联合商用车头部企业，共同设计和定义无人物流车，应用于矿山、港口等场景，这意味着在该项目中卓驭将不只是 tier1 供应商，而会参与到产品设计等更多环节。 昨天，卓驭发布了全新的使命、价值观与愿景：使命从原本的 “让给所有人带来安全轻松的出行体验”，升级为 “为世界提供安全、轻松的移动智能”，价值观升级为 “激极尽志、求真品诚、用户为本、成就客户”，并希望以此实现 “引领自主移动机器人时代” 的愿景。 未来，卓驭将会把移动智能推向更多场景。 ]]>","published_date":"2025-12-31T08:18:42.647Z","authors":"李泽南","source":"机器之心 - 李泽南","details":{"content_html":"12 月 30 日，卓驭品牌盛典 2025 在深圳举行。<p></p><p>不同于常规的技术参数发布会，本次卓驭科技的发布更侧重技术路线阐释、工程哲学与未来布局。</p><p><img src=\"https://image.jiqizhixin.com/uploads/editor/451dfb1d-22e4-4bcf-8346-e497dd023433/QQ20251231-161006.jpg\" style=\"width: 67.52%;\"></p><p>作为从大疆独立仅一年多的智能驾驶公司，卓驭首次系统对外解读了其从规则驱动到数据驱动的技术转型、软硬一体的工程能力，以及从乘用车向商用车等多场景延伸的战略路径。</p><p>卓驭科技 CEO 沈劭劼在演讲中系统回顾了卓驭团队自 2016 年创立至今、从大疆车载迈向独立主体的发展历程，介绍了多模态端到端世界模型体系，并宣告了其 “数据驱动的空间智能移动基座” 正式成型。</p><p>卓驭的技术根基源自大疆的机器人工程基因，早期沿用规则驱动方案。但随着智能驾驶场景复杂度提升，基于规则的辅助驾驶系统陷入了 “解决一个问题，冒出十个新问题” 的工程困境。</p><p>2024 年 10 月 14 日，卓驭做出关键决策：全删原有代码库，全面转向端到端架构。在转型初期，团队面临模型不成熟、交付压力大、输出不稳定等多重挑战，但最终探索出一条差异化的技术路径。</p><p>借鉴 “巧力出奇迹” 的总体思路，卓驭不盲目堆算力与参数量，而是将视觉 - 语言 - 动作（VLA）模型拆解为多个可解释、可分工的模块。他们以较低成本攻克了行业公认的 “因果推理” 与 “低频数据生成” 两大难题，实现了端到端系统在中等算力平台上的可用性与可部署性。</p><p>卓驭提供高质量、低价格的辅助驾驶解决方案，通过极致优化，能够让 10 万元级车型也能具备城市领航辅助驾驶能力：其在地平线征程 8650 芯片上实现性能媲美 Orin X，通过网络压缩与优化，将端到端网络成功部署在 TI TDA4 等中算力平台，实现了 “中算力城市 NOA”。</p><p>与此同时，卓驭推出高通 8775 舱驾一体方案，以单芯片同时驱动智能座舱与智能驾驶系统，推动了整车架构向中央计算的方向演进。</p><p>历时九年，卓驭的辅助驾驶系统已历经千万公里真实道路的考验，卓驭也已经从行业新生力量成长为业界领军企业，乘用车领域覆盖 9 大客户 15 大品牌，量产覆盖 50 多个车型和所有动力构型，此外还有 30 + 款即将量产车型。</p><p><img src=\"https://image.jiqizhixin.com/uploads/editor/73703826-6a81-4e1d-ac18-a52da2ee00ac/QQ20251231-160528.jpg\" style=\"width: 700%;\"></p><p>卓驭着重建设 “全场景兜底能力”，希望通过持续建设全流程产业链能力、完善的软硬件能力，以及对客户 “产品交付”、对用户 “不放弃每一位” 的兜底能力。</p><p>基于这一判断，卓驭选择在统一架构上向上延展，而非重新搭建高算力方案。从 TDA4（中算力）到 8650 及更高算力平台，再到 8775（舱驾一体），其核心架构保持一致且可规模化复用。</p><p>目前，卓驭已推出两大高算力方案：一是 L3/L4 方案，搭载两块 Thor 芯片，配合自研激目前向感知系统和知周补盲雷达；二是舱驾一体方案，采用高通 SA8797，将 VLA 融入统一架构。基于对算力的极致运用，卓驭的工程实力获得英伟达、德州仪器等芯片厂商认可 ——“同样的芯片，在我们手里能跑出更高的效率”。\"</p><p>面向未来，卓驭希望构建空间智能的移动基座，引领自主移动机器人时代，其技术能力将不再局限于乘用车辅助驾驶，而是依托数据驱动的开发范式、成熟的基座模型及软硬一体的工程能力，将移动智能的边界拓展至商用车等更广泛的业务场景。</p><p><img src=\"https://image.jiqizhixin.com/uploads/editor/2e0a68be-8bec-42f3-8929-5ed313113a8d/QQ20251231-160615.jpg\" style=\"width: 700%;\"></p><p>卓驭宣布，在 2026 年上半年会上线重卡 NOA 辅助驾驶。</p><p>目前，卓驭已启动重卡高速 NOA 项目，旨在解决重卡司机长时间驾驶疲劳的痛点，提升干线物流的安全与效率水平，且已与徐工、陕汽、重汽三大业界头部客户确立合作，首批重卡车型将于 2026 年上半年正式量产。</p><p>基于端到端的辅助驾驶方式，正在为智能的泛化提供便利。卓驭透露，从乘用车到重卡的能力迁移，所需的时间不超过 1 个月。</p><p><img src=\"https://image.jiqizhixin.com/uploads/editor/4cacd87b-d570-4a4f-9085-b1675e333c75/QQ20251231-160722.jpg\" style=\"width: 700%;\"></p><p>同时，卓驭正联合商用车头部企业，共同设计和定义无人物流车，应用于矿山、港口等场景，这意味着在该项目中卓驭将不只是 tier1 供应商，而会参与到产品设计等更多环节。</p><p>昨天，卓驭发布了全新的使命、价值观与愿景：使命从原本的 “让给所有人带来安全轻松的出行体验”，升级为 “为世界提供安全、轻松的移动智能”，价值观升级为 “激极尽志、求真品诚、用户为本、成就客户”，并希望以此实现 “引领自主移动机器人时代” 的愿景。</p><p>未来，卓驭将会把移动智能推向更多场景。</p>]]>"}},{"id":"229104787892749312","type":"news","url":"https://www.aibase.com/zh/news/24171","title":"2030年前，20万欧洲银行岗位面临 AI 威胁","description":"根据摩根士丹利的分析，预计到2030年，人工智能将在欧洲金融行业中对约20万个银行职位造成威胁。分析师指出，最受影响的将是后端和中间办公岗位，这些职位通常涉及数据处理、文书工作及其他例行事务。 [图片: AI助教 机器人 https://pic.chinaz.com/picmap/202310270933190076_7.jpg] 图源备注:图片由AI生成，图片授权服务商Midjourney 随着金融科技的迅速发展，许多传统银行正在逐步采用智能化解决方案，以提高效率并降低成本。人工智能技术的应用使得银行在客户服务、风险管理和合规等领域变得更加高效，然而，这也意味着许多职位将会被机器取代。尤其是在后台支持和数据分析等领域，AI 的引入可能会导致岗位需求的显著减少。 分析师表示，尽管 AI 能够提升工作效率，但这也会使得银行面临如何处理裁员和岗位转移的挑战。为了应对这些变化，银行需要制定新的战略，帮助员工适应不断变化的工作环境，并寻找新的技能培训机会。 随着科技的进步和行业的转型，传统银行在未来的竞争中必须更加灵活，以保持其市场地位。摩根士丹利的报告强调了人工智能在金融行业中的潜力，同时也提醒了相关人员需为未来做好准备，以应对即将到来的职场变革。 划重点: 🔍 预计到2030年，AI 将约20万个欧洲银行岗位，尤其是后台和中间办公职位。 🤖 金融科技的快速发展促使银行采用 AI 以提高效率，但也意味着传统岗位的减少。 📈 银行需制定战略应对裁员挑战，并提供技能培训以帮助员工适应新环境。","published_date":"2025-12-31T07:31:17.774Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>根据摩根士丹利的分析，预计到2030年，人工智能将在欧洲金融行业中对约20万个银行职位造成威胁。分析师指出，最受影响的将是后端和中间办公岗位，这些职位通常涉及数据处理、文书工作及其他例行事务。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202310270933190076_7.jpg\" title=\"AI助教 机器人 (图片来源：AI合成)\" alt=\"AI助教 机器人\"></p><p style=\"text-align: center;\">图源备注:图片由AI生成，图片授权服务商Midjourney</p><p>随着金融科技的迅速发展，许多传统银行正在逐步采用智能化解决方案，以提高效率并降低成本。人工智能技术的应用使得银行在客户服务、风险管理和合规等领域变得更加高效，然而，这也意味着许多职位将会被机器取代。尤其是在后台支持和数据分析等领域，AI 的引入可能会导致岗位需求的显著减少。</p><p>分析师表示，尽管 AI 能够提升工作效率，但这也会使得银行面临如何处理裁员和岗位转移的挑战。为了应对这些变化，银行需要制定新的战略，帮助员工适应不断变化的工作环境，并寻找新的技能培训机会。</p><p>随着科技的进步和行业的转型，传统银行在未来的竞争中必须更加灵活，以保持其市场地位。摩根士丹利的报告强调了人工智能在金融行业中的潜力，同时也提醒了相关人员需为未来做好准备，以应对即将到来的职场变革。</p><blockquote><p>划重点:</p><p>🔍 预计到2030年，AI 将约20万个欧洲银行岗位，尤其是后台和中间办公职位。</p><p>🤖 金融科技的快速发展促使银行采用 AI 以提高效率，但也意味着传统岗位的减少。</p><p>📈 银行需制定战略应对裁员挑战，并提供技能培训以帮助员工适应新环境。</p></blockquote>"}},{"id":"229104787892749313","type":"news","url":"https://www.aibase.com/zh/news/24170","title":"源 Yuan3.0Flash:开源多模态基础大模型引领 AI 新潮流","description":"近日，YuanLab.ai 团队正式发布了源 Yuan3.0Flash 多模态基础大模型，这一模型的开源将为 AI 领域带来新的机遇。该模型不仅包括16bit 与4bit 的模型权重，还提供了详细的技术报告和训练方法，支持社区进行二次开发和行业定制，极大地促进了 AI 技术的普及。 [图片: image.png https://upload.chinaz.com/2025/1231/6390279109339079463158304.png] Yuan3.0Flash 的参数规模达到40B，采用了创新的稀疏混合专家（MoE）架构，在推理过程中，仅激活约3.7B 的参数。这种设计不仅提高了推理的准确性，还大幅降低了算力消耗，体现了 “更少算力、更高智能” 的理念。此外，模型还引入了强化学习训练方法(RAPO)，通过反思抑制奖励机制(RIRM)，有效地引导模型减少无效反思，进一步提升了性能。 在模型的结构上，Yuan3.0Flash 由视觉编码器、语言主干网络和多模态对齐模块组成。语言主干网络采用了局部过滤增强的 Attention 结构（LFA）和混合专家结构(MoE)，在保证注意力精度的同时，显著减少了训练和推理过程中的算力开销。视觉编码器能够将视觉信号转化为 token，与语言 token 共同输入，从而实现高效的跨模态特征对齐。 在实际应用方面，Yuan3.0Flash 在企业场景中的表现已超越了 GPT-5.1，特别是在 RAG（ChatRAG）、多模态检索(Docmatix)以及多模态表格理解(MMTab)等任务上，展现了显著的能力优势。多模态推理与语言推理的评测中，该模型的精度接近于更大规模的模型，如 Qwen3-VL235B-A22B(235B)和 DeepSeek-R1-0528(671B)，但其 token 消耗仅为后者的1/4到1/2，有效降低了企业在大模型应用上的成本。 未来，源 Yuan3.0将推出多个版本，包括 Flash、Pro 和 Ultra，参数规模涵盖40B、200B 和1T 等选择，进一步丰富了 AI 模型的应用可能性。 划重点: 🌟 Yuan3.0Flash 是一款开源的40B 参数规模多模态基础大模型，包含多种模型权重和详细的技术报告。 💡 该模型采用创新的稀疏混合专家架构，推理过程显著降低算力消耗，提升智能表现。 🚀 在企业应用中，Yuan3.0Flash 已超越 GPT-5.1，展现出优秀的多模态推理能力，降低了应用成本。","published_date":"2025-12-31T07:18:42.315Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>近日，YuanLab.ai 团队正式发布了源 Yuan3.0Flash 多模态基础大模型，这一模型的开源将为 AI 领域带来新的机遇。该模型不仅包括16bit 与4bit 的模型权重，还提供了详细的技术报告和训练方法，支持社区进行二次开发和行业定制，极大地促进了 AI 技术的普及。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/1231/6390279109339079463158304.png\" title=\"image.png\" alt=\"image.png\"></p><p>Yuan3.0Flash 的参数规模达到40B，采用了创新的稀疏混合专家（MoE）架构，在推理过程中，仅激活约3.7B 的参数。这种设计不仅提高了推理的准确性，还大幅降低了算力消耗，体现了 “更少算力、更高智能” 的理念。此外，模型还引入了强化学习训练方法(RAPO)，通过反思抑制奖励机制(RIRM)，有效地引导模型减少无效反思，进一步提升了性能。</p><p>在模型的结构上，Yuan3.0Flash 由视觉编码器、语言主干网络和多模态对齐模块组成。语言主干网络采用了局部过滤增强的 Attention 结构（LFA）和混合专家结构(MoE)，在保证注意力精度的同时，显著减少了训练和推理过程中的算力开销。视觉编码器能够将视觉信号转化为 token，与语言 token 共同输入，从而实现高效的跨模态特征对齐。</p><p>在实际应用方面，Yuan3.0Flash 在企业场景中的表现已超越了 GPT-5.1，特别是在 RAG（ChatRAG）、多模态检索(Docmatix)以及多模态表格理解(MMTab)等任务上，展现了显著的能力优势。多模态推理与语言推理的评测中，该模型的精度接近于更大规模的模型，如 Qwen3-VL235B-A22B(235B)和 DeepSeek-R1-0528(671B)，但其 token 消耗仅为后者的1/4到1/2，有效降低了企业在大模型应用上的成本。</p><p>未来，源 Yuan3.0将推出多个版本，包括 Flash、Pro 和 Ultra，参数规模涵盖40B、200B 和1T 等选择，进一步丰富了 AI 模型的应用可能性。</p><blockquote><p>划重点:</p><p>🌟 Yuan3.0Flash 是一款开源的40B 参数规模多模态基础大模型，包含多种模型权重和详细的技术报告。  </p><p>💡 该模型采用创新的稀疏混合专家架构，推理过程显著降低算力消耗，提升智能表现。  </p><p>🚀 在企业应用中，Yuan3.0Flash 已超越 GPT-5.1，展现出优秀的多模态推理能力，降低了应用成本。</p></blockquote>"}},{"id":"229104787892749314","type":"news","url":"https://www.aibase.com/zh/news/24169","title":"夸克AI眼镜首次OTA：AI能力进一步增强，新增图文备忘录等五项功能","description":"12月31日，搭载千问AI助手的夸克AI眼镜迎来 首次 OTA，AI能力进一步增强。新增录音纪要、图文备忘录、大模型多意图理解和执行、蓝环支付、社区服务五项新功能，并对受到用户欢迎的翻译、行程查询、音乐播放等功能场景进行优化。 在录音场景下，基于自研的Quark Audio语音增强模型和原有的5麦克风阵列加骨传导硬件配置，升级后的夸克AI眼镜支持十米范围内收音，并有效降噪。此外，眼镜能精准识别不同说话对象，根据录音内容进行AI要点提炼，自动生成待办事项等。目前，这一功能支持中文、英语、日语、韩语四种语言的录音转写及互译。 [图片: image.png https://upload.chinaz.com/2025/1231/6390279106978441613959484.png] 在备忘录场景下，夸克AI眼镜支持拍照和语音两种方式使用备忘录，如站在停车位前，只需要一句“千问同学，帮我记一下停车位”，眼镜就会拍下停车位照片并进行记录。更智能的是，系统具备AI分类与语义理解能力，当用户提问“最近一个月我想买的家具有哪些”，眼镜将自动检索历史记录并汇总回复。 此外，本次升级的一大亮点是大模型支持的多意图理解与执行。多数AI眼镜通常只能处理单一指令，而夸克AI眼镜已支持理解并执行2-3个复合任务。如“导航去公司，来点我喜欢的音乐”、“明天上午八点要去发布会、九点要赶飞机，记得提醒我”，夸克AI眼镜都能理解到位，并调度地图、音乐、日历等多项服务，提升在工作和生活中的效率与便捷性。 随身翻译功能也同步升级，支持89种语言翻译，不仅包括英、日、韩、法、德等主流语种，还覆盖多个国家和地区的小众语言，满足跨境旅行、商务交流等不同需求。 本次OTA通过夸克AI眼镜APP推送，用户可点击完成升级。APP端同步上线用户交流社区，用户可在社区内了解产品信息，并分享使用技巧和感受，还可参与官方组织的各种摄影、玩法、创作大赛。 作为阿里千问C端事业群的重要业务方向，夸克AI眼镜目前已推出S1、G1两个系列六个SKU产品。搭载的千问AI助手正以APP为核心入口，加速向眼镜、PC、汽车等多终端延伸。","published_date":"2025-12-31T07:18:03.236Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>12月31日，搭载千问AI助手的夸克AI眼镜迎来<span>首次</span>OTA，AI能力进一步增强。新增录音纪要、图文备忘录、大模型多意图理解和执行、蓝环支付、社区服务五项新功能，并对受到用户欢迎的翻译、行程查询、音乐播放等功能场景进行优化。</p><p>在录音场景下，基于自研的Quark Audio语音增强模型和原有的5麦克风阵列加骨传导硬件配置，升级后的夸克AI眼镜支持十米范围内收音，并有效降噪。此外，眼镜能精准识别不同说话对象，根据录音内容进行AI要点提炼，自动生成待办事项等。目前，这一功能支持中文、英语、日语、韩语四种语言的录音转写及互译。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/1231/6390279106978441613959484.png\" title=\"image.png\" alt=\"image.png\"></p><p>在备忘录场景下，夸克AI眼镜支持拍照和语音两种方式使用备忘录，如站在停车位前，只需要一句“千问同学，帮我记一下停车位”，眼镜就会拍下停车位照片并进行记录。更智能的是，系统具备AI分类与语义理解能力，当用户提问“最近一个月我想买的家具有哪些”，眼镜将自动检索历史记录并汇总回复。</p><p>此外，本次升级的一大亮点是大模型支持的多意图理解与执行。多数AI眼镜通常只能处理单一指令，而夸克AI眼镜已支持理解并执行2-3个复合任务。如“导航去公司，来点我喜欢的音乐”、“明天上午八点要去发布会、九点要赶飞机，记得提醒我”，夸克AI眼镜都能理解到位，并调度地图、音乐、日历等多项服务，提升在工作和生活中的效率与便捷性。</p><p>随身翻译功能也同步升级，支持89种语言翻译，不仅包括英、日、韩、法、德等主流语种，还覆盖多个国家和地区的小众语言，满足跨境旅行、商务交流等不同需求。</p><p>本次OTA通过夸克AI眼镜APP推送，用户可点击完成升级。APP端同步上线用户交流社区，用户可在社区内了解产品信息，并分享使用技巧和感受，还可参与官方组织的各种摄影、玩法、创作大赛。</p><p>作为阿里千问C端事业群的重要业务方向，夸克AI眼镜目前已推出S1、G1两个系列六个SKU产品。搭载的千问AI助手正以APP为核心入口，加速向眼镜、PC、汽车等多终端延伸。</p>"}},{"id":"229104787892749315","type":"news","url":"https://www.aibase.com/zh/news/24167","title":"腾讯炸场！10亿参数文生3D动作神器开源，游戏NPC一键“活”了！","description":"2025年12月30日，腾讯混元团队重磅开源HY-Motion1.0（Hunyuan-Motion-1.0），一款十亿参数级文本到3D动作生成大模型。该模型基于Diffusion Transformer(DiT)架构与流匹配机制，仅需一句自然语言描述，即可生成高保真、流畅多样的3D角色骨骼动画，直接兼容Blender、Unity、UE等主流3D工具，极大降低了动画制作门槛。 [图片: image.png https://upload.chinaz.com/2025/1231/6390278994463366277156776.png] 核心技术亮点 HY-Motion1.0采用全阶段训练策略:首先在超3000小时多样化动作数据上预训练，构建通用运动先验;随后在400小时精选高质量数据上微调，提升细节流畅性;最后通过强化学习（RLHF）结合人类反馈和奖励模型，优化物理合理性与语义对齐。 模型覆盖6大类超200种动作，包括基础位移、体育竞技、健身户外、社交休闲、日常活动及游戏角色动作（如持剑格挡、僵尸行走）。输出为SMPL-H骨骼格式，支持原子动作、组合序列及并发动作生成。 实测表现亮眼 社区实测显示，模型在日常场景下还原度 极高 :如“跑步”“坐到椅子上”“双腿往上跳两次”等prompt，生成动作自然连贯;复杂动作如《黑客帝国》子弹时间下腰，也能精准复现流畅姿态。 性能评估中，指令遵循能力达78.6%（SSAE指标），动作质量平均3.43分(5分制)，全面超越MoMask、DART等开源基线，尤其在复杂指令和多类别覆盖上领先。 极限挑战:职业运动员动作（如跳台滑雪、跳水、小轮车）还原欠佳，关节过渡偶有不自然，但整体物理合理性远超前辈。 游戏动画应用前景广阔 这款端到端模型特别适合游戏开发:快速生成NPC日常生活动作（如走动、互动），显著加速预研与迭代;主要角色设计虽需后期微调，但已能无缝导入引擎，助力MMO、动作类游戏制作。影视分镜、广告走位、VR内容创作同样受益。 轻量版HY-Motion-1.0-Lite（0.46B参数）也同步开源，部署更友好。 项目地址：https://hunyuan.tencent.com/motion?tabIndex=0","published_date":"2025-12-31T06:59:27.872Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>2025年12月30日，腾讯混元团队重磅开源HY-Motion1.0（Hunyuan-Motion-1.0），一款十亿参数级文本到3D动作生成大模型。该模型基于Diffusion Transformer(DiT)架构与流匹配机制，仅需一句自然语言描述，即可生成高保真、流畅多样的3D角色骨骼动画，直接兼容Blender、Unity、UE等主流3D工具，极大降低了动画制作门槛。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/1231/6390278994463366277156776.png\" title=\"image.png\" alt=\"image.png\"></p><p><strong>核心技术亮点  </strong></p><p>HY-Motion1.0采用全阶段训练策略:首先在超3000小时多样化动作数据上预训练，构建通用运动先验;随后在400小时精选高质量数据上微调，提升细节流畅性;最后通过强化学习（RLHF）结合人类反馈和奖励模型，优化物理合理性与语义对齐。  </p><p>模型覆盖6大类超200种动作，包括基础位移、体育竞技、健身户外、社交休闲、日常活动及游戏角色动作（如持剑格挡、僵尸行走）。输出为SMPL-H骨骼格式，支持原子动作、组合序列及并发动作生成。</p><p><strong>实测表现亮眼  </strong></p><p>社区实测显示，模型在日常场景下还原度<span>极高</span>:如“跑步”“坐到椅子上”“双腿往上跳两次”等prompt，生成动作自然连贯;复杂动作如《黑客帝国》子弹时间下腰，也能精准复现流畅姿态。  </p><p>性能评估中，指令遵循能力达78.6%（SSAE指标），动作质量平均3.43分(5分制)，全面超越MoMask、DART等开源基线，尤其在复杂指令和多类别覆盖上领先。  </p><p>极限挑战:职业运动员动作（如跳台滑雪、跳水、小轮车）还原欠佳，关节过渡偶有不自然，但整体物理合理性远超前辈。</p><p><strong>游戏动画应用前景广阔</strong>  </p><p>这款端到端模型特别适合游戏开发:快速生成NPC日常生活动作（如走动、互动），显著加速预研与迭代;主要角色设计虽需后期微调，但已能无缝导入引擎，助力MMO、动作类游戏制作。影视分镜、广告走位、VR内容创作同样受益。  </p><p>轻量版HY-Motion-1.0-Lite（0.46B参数）也同步开源，部署更友好。</p><p>项目地址：https://hunyuan.tencent.com/motion?tabIndex=0</p>"}},{"id":"229087934572283904","type":"news","url":"https://newshacker.me/story?id=46390621","title":"📚 AI 动画可视化：资源汇总与教学有效性争议","description":"原标题： 《Animated AI》 评分: 23 | 作者: frozenseven 💭 只靠动画讲解就能建立正确的心智模型吗？ 🎯 讨论背景 这是对名为“Animated AI”帖子的讨论，主题是用动画/动图可视化机器学习概念的教学价值与资源。评论中有人分享用 manim（一个数学/动画库）制作的 CNN cheatsheet、专门演示 Transformer 架构的交互页面、解释神经网络与决策树的动画教程，以及 Vincent Dumoulin 的 conv_arithmetic GIF 等经典可视化资源。讨论基于两大前提：复杂模块（如卷积、前向/反向传播、Transformer 的 attention）在抽象层面难以直观理解，以及教学方法存在分歧——动画能增强直觉但是否能替代实践和数学推导存在争议。该话题与在线教学、可视化工具和机器学习教育实践密切相关。 📌 讨论焦点 动画可视化作为教学工具的正面评价 多位评论认为动画化的可视化能把复杂的机器学习概念直观化，提升理解效率。具体例子包括将前向与反向传播可视化以帮助建立正确的心智模型，以及用凸面和梯度下降的动画来强化对优化过程的直觉。评论还指出，卷积的动图/GIF 能使卷积核如何影响输出尺寸与通道的细节更清晰。有人建议进一步覆盖 Transformer 架构与 attention 机制，因为这些结构更抽象、更难通过文字理解。 [来源1] [来源2] [来源3] [来源4] 社区分享的可视化资源与项目实例 许多评论分享了现成的教学与可视化资源作为学习或复现材料：有人用 manim（一个数学/动画库）做了 CNN cheatsheet，也有专门演示 Transformer 架构的交互页面。其他被提及的资源包括解释神经网络与决策树的动画教程、Vincent Dumoulin 与 Francesco Visin 的 conv_arithmetic GIF（用于讲解卷积算子细节），以及 r2d3 等交互式可视化收藏。这些链接既包含直观演示，也常提供源码或可交互实验，便于读者边看边复现以加深理解。 [来源1] [来源2] [来源3] [来源4] [来源5] 反对观点：动图不能替代动手实践与做数学 少数评论指出，仅看动画并不足以真正掌握概念，主张通过动手实现和手工数学推导来加深理解。具体建议包括实现简单网络去拟合一维函数（如 sin）、用卷积核理解图像模糊的机制，并把相关数学计算手工算一遍以理解梯度与参数更新。这些评论强调“by doing math by hand”和实际编程实验带来的理解深度超过纯粹的视觉演示。结论是动画适合引导直觉，但不能完全替代实践和数值实验。 [来源1] [来源2] 📚 术语解释 卷积（Convolution / CNN）: 一种在格状数据（如图像）上作用的局部线性算子，用于提取局部特征；CNN（Convolutional Neural Network）通过卷积层与池化等操作捕获空间层次结构，conv_arithmetic 类可视化常用于展示卷积核如何影响输出尺寸与通道。 Transformer（Transformer 架构 / attention）: 基于 self-attention（自注意力）的序列模型，使用 attention 机制建模序列中元素之间的依赖，广泛用于 NLP 与视觉任务；attention 是 Transformer 中最难直观化的部分，因此常被作为可视化重点。 神经网络（Neural Network / 前向传播与反向传播）: 由多层参数化节点（neurons）构成的函数逼近器，通过前向传播计算输出、通过反向传播计算梯度并用优化器（如梯度下降）更新参数；可视化常用于展示激活、损失和权重随训练变化以帮助建立心智模型。 类别： AI | Programming | Guide | Animated AI | Neural networks | Visualization | Transformer | Convolution","published_date":"2025-12-31T06:50:52.776Z","authors":"","source":"News Hacker | 极客洞察","details":{"content_html":"<p><strong>原标题：</strong>《Animated AI》</p><p><strong>评分:</strong> 23 | <strong>作者:</strong> frozenseven</p><blockquote>💭 只靠动画讲解就能建立正确的心智模型吗？</blockquote><hr><h2>🎯 讨论背景</h2><p>这是对名为“Animated AI”帖子的讨论，主题是用动画/动图可视化机器学习概念的教学价值与资源。评论中有人分享用 manim（一个数学/动画库）制作的 CNN cheatsheet、专门演示 Transformer 架构的交互页面、解释神经网络与决策树的动画教程，以及 Vincent Dumoulin 的 conv_arithmetic GIF 等经典可视化资源。讨论基于两大前提：复杂模块（如卷积、前向/反向传播、Transformer 的 attention）在抽象层面难以直观理解，以及教学方法存在分歧——动画能增强直觉但是否能替代实践和数学推导存在争议。该话题与在线教学、可视化工具和机器学习教育实践密切相关。</p><hr><h2>📌 讨论焦点</h2><h3>动画可视化作为教学工具的正面评价</h3><p>多位评论认为动画化的可视化能把复杂的机器学习概念直观化，提升理解效率。具体例子包括将前向与反向传播可视化以帮助建立正确的心智模型，以及用凸面和梯度下降的动画来强化对优化过程的直觉。评论还指出，卷积的动图/GIF 能使卷积核如何影响输出尺寸与通道的细节更清晰。有人建议进一步覆盖 Transformer 架构与 attention 机制，因为这些结构更抽象、更难通过文字理解。</p><p><a href=\"https://news.ycombinator.com/item?id=46441128\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46440975\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441104\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441058\" target=\"_blank\">[来源4]</a></p><h3>社区分享的可视化资源与项目实例</h3><p>许多评论分享了现成的教学与可视化资源作为学习或复现材料：有人用 manim（一个数学/动画库）做了 CNN cheatsheet，也有专门演示 Transformer 架构的交互页面。其他被提及的资源包括解释神经网络与决策树的动画教程、Vincent Dumoulin 与 Francesco Visin 的 conv_arithmetic GIF（用于讲解卷积算子细节），以及 r2d3 等交互式可视化收藏。这些链接既包含直观演示，也常提供源码或可交互实验，便于读者边看边复现以加深理解。</p><p><a href=\"https://news.ycombinator.com/item?id=46441058\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441509\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441484\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441618\" target=\"_blank\">[来源4]</a> <a href=\"https://news.ycombinator.com/item?id=46441104\" target=\"_blank\">[来源5]</a></p><h3>反对观点：动图不能替代动手实践与做数学</h3><p>少数评论指出，仅看动画并不足以真正掌握概念，主张通过动手实现和手工数学推导来加深理解。具体建议包括实现简单网络去拟合一维函数（如 sin）、用卷积核理解图像模糊的机制，并把相关数学计算手工算一遍以理解梯度与参数更新。这些评论强调“by doing math by hand”和实际编程实验带来的理解深度超过纯粹的视觉演示。结论是动画适合引导直觉，但不能完全替代实践和数值实验。</p><p><a href=\"https://news.ycombinator.com/item?id=46441304\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441474\" target=\"_blank\">[来源2]</a></p><hr><h2>📚 术语解释</h2><p><strong>卷积（Convolution / CNN）:</strong> 一种在格状数据（如图像）上作用的局部线性算子，用于提取局部特征；CNN（Convolutional Neural Network）通过卷积层与池化等操作捕获空间层次结构，conv_arithmetic 类可视化常用于展示卷积核如何影响输出尺寸与通道。</p><p><strong>Transformer（Transformer 架构 / attention）:</strong> 基于 self-attention（自注意力）的序列模型，使用 attention 机制建模序列中元素之间的依赖，广泛用于 NLP 与视觉任务；attention 是 Transformer 中最难直观化的部分，因此常被作为可视化重点。</p><p><strong>神经网络（Neural Network / 前向传播与反向传播）:</strong> 由多层参数化节点（neurons）构成的函数逼近器，通过前向传播计算输出、通过反向传播计算梯度并用优化器（如梯度下降）更新参数；可视化常用于展示激活、损失和权重随训练变化以帮助建立心智模型。</p><hr><p><strong>类别：</strong>AI | Programming | Guide | Animated AI | Neural networks | Visualization | Transformer | Convolution</p>"}},{"id":"229104787892749316","type":"news","url":"https://www.aibase.com/zh/news/24166","title":"OpenAI 员工年均股权激励达150万美元，引发科技行业薪酬大战","description":"据《华尔街日报》报道，OpenAI 最近向投资者披露的财务数据显示，该公司的员工薪酬水平达到了现代科技初创企业的顶峰。OpenAI 目前员工总数约为4000人，平均每位员工获得的股权激励高达150万美元，折合人民币约1051万元。 [图片: OpenAI https://pic.chinaz.com/picmap/202502061719384092_4.jpg] 图源备注：图片由AI生成，图片授权服务商Midjourney 这一数字是谷歌在2003年公布的股权激励薪酬的7倍以上，当时谷歌尚未在2004年上市。而与其他18家大型科技公司相比，这一薪酬数字是它们上市前一年人均薪酬的34倍。这些数据均已根据通货膨胀因素进行了调整，以符合2025年的美元计价标准。 OpenAI 之所以能提供如此高额的股权激励，主要是为了在竞争激烈的人工智能领域吸引和留住 顶尖 人才。这些高薪让 OpenAI 的员工跻身硅谷收入 最高 的行列。然而，这样的薪酬模式也给公司带来了巨大的运营亏损，并迅速稀释了现有股东的股权。 随着人工智能行业竞争的加剧，其他科技巨头也纷纷推出丰厚的薪酬方案。例如，Meta 首席执行官马克・扎克伯格曾宣布，将为竞争对手的高管和 顶尖 研究员提供价值数亿美元的薪酬，个别岗位甚至高达10亿美元。这使得 OpenAI 面临更大的薪资压力，并导致了一些关键员工的流失。 扎克伯格的大规模挖人行动已吸引了 OpenAI 的20多名员工，其中包括 ChatGPT 的联合开发者赵晟佳。今年夏天，OpenAI 还向部分研发人员和工程师发放了一次性奖金，部分员工获得了高达数百万美元的奖金。 预计到2030年，OpenAI 的股权激励支出将每年增加约30亿美元。近期公司还修改了原有规定，员工在任职满6个月后才能获得股权归属资格的政策被废止，这将进一步推高薪酬支出。预计到2025年，OpenAI 薪酬支出占公司营收的比例将达到46%，这一比例在18家大型科技公司中仅次于电动汽车制造商 Rivian。 划重点: 💰 OpenAI 员工年均股权激励达到150万美元，远超行业水平。 📉 薪酬模式给 OpenAI 带来运营亏损，加剧了股东股权稀释。 🚀 竞争加剧，科技巨头纷纷提升薪酬方案，以吸引 顶尖 人才。","published_date":"2025-12-31T06:44:35.474Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>据《华尔街日报》报道，OpenAI 最近向投资者披露的财务数据显示，该公司的员工薪酬水平达到了现代科技初创企业的顶峰。OpenAI 目前员工总数约为4000人，平均每位员工获得的股权激励高达150万美元，折合人民币约1051万元。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202502061719384092_4.jpg\" title=\"OpenAI (图片来源：AI合成)\" alt=\"OpenAI\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>这一数字是谷歌在2003年公布的股权激励薪酬的7倍以上，当时谷歌尚未在2004年上市。而与其他18家大型科技公司相比，这一薪酬数字是它们上市前一年人均薪酬的34倍。这些数据均已根据通货膨胀因素进行了调整，以符合2025年的美元计价标准。</p><p>OpenAI 之所以能提供如此高额的股权激励，主要是为了在竞争激烈的人工智能领域吸引和留住<span>顶尖</span>人才。这些高薪让 OpenAI 的员工跻身硅谷收入<span>最高</span>的行列。然而，这样的薪酬模式也给公司带来了巨大的运营亏损，并迅速稀释了现有股东的股权。</p><p>随着人工智能行业竞争的加剧，其他科技巨头也纷纷推出丰厚的薪酬方案。例如，Meta 首席执行官马克・扎克伯格曾宣布，将为竞争对手的高管和<span>顶尖</span>研究员提供价值数亿美元的薪酬，个别岗位甚至高达10亿美元。这使得 OpenAI 面临更大的薪资压力，并导致了一些关键员工的流失。</p><p>扎克伯格的大规模挖人行动已吸引了 OpenAI 的20多名员工，其中包括 ChatGPT 的联合开发者赵晟佳。今年夏天，OpenAI 还向部分研发人员和工程师发放了一次性奖金，部分员工获得了高达数百万美元的奖金。</p><p>预计到2030年，OpenAI 的股权激励支出将每年增加约30亿美元。近期公司还修改了原有规定，员工在任职满6个月后才能获得股权归属资格的政策被废止，这将进一步推高薪酬支出。预计到2025年，OpenAI 薪酬支出占公司营收的比例将达到46%，这一比例在18家大型科技公司中仅次于电动汽车制造商 Rivian。</p><blockquote><p>划重点:</p><p>💰 OpenAI 员工年均股权激励达到150万美元，远超行业水平。  </p><p>📉 薪酬模式给 OpenAI 带来运营亏损，加剧了股东股权稀释。  </p><p>🚀 竞争加剧，科技巨头纷纷提升薪酬方案，以吸引<span>顶尖</span>人才。</p></blockquote>"}},{"id":"229104787892749317","type":"news","url":"https://www.aibase.com/zh/news/24165","title":"AI “套壳” 产品能否脱颖而出？揭示创业机会与竞争策略","description":"近年来，人工智能技术的迅猛发展催生了大量的 “AI 套壳” 产品。这些产品往往被简单地看作是利用现有 AI 模型或 API 的轻量级应用，开发过程相对简单，容易被市场忽视。然而，一项新的分析指出，这些 “套壳” 应用并不应被轻视，能否在激烈的竞争中生存下来，关键在于它们是否能有效嵌入用户工作流、积累独特的数据以及应对来自行业巨头的挑战。 首先，文章明确区分了 “功能型” 和 “产品型” 的 AI 套壳应用。功能型应用通常只能解决某个特定问题，例如与 PDF 文档进行交互，缺乏独立性，一旦大平台整合这类功能，这些应用就可能被市场淘汰。而产品型应用则能够通过深度集成和数据积累，建立起自己的护城河，增加竞争力。 [图片: image.png https://upload.chinaz.com/2025/1231/6390278874006722929742577.png] 其次，创业公司面临着双重挑战。一方面，它们需要依赖于大型模型提供商的技术支持，另一方面，又要在分发渠道上与这些巨头竞争。例如，编程助手类应用如 Cursor 正在努力转型为集成开发环境，但它们依然受到 API 调用限制的困扰。与此同时，巨头们如 OpenAI 和 Google 可能会迅速将相似功能融入自己的产品中，创业公司必须抢占市场先机。 最后，文章分析了传统企业在 AI 时代的竞争策略，强调了控制用户流程和积累自有数据的重要性。成功的 “套壳” 产品需要能与用户的日常工作流程紧密结合，不仅仅是一个简单的工具，而是能够解决实际问题的有效方案。","published_date":"2025-12-31T06:39:07.496Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>近年来，人工智能技术的迅猛发展催生了大量的 “AI 套壳” 产品。这些产品往往被简单地看作是利用现有 AI 模型或 API 的轻量级应用，开发过程相对简单，容易被市场忽视。然而，一项新的分析指出，这些 “套壳” 应用并不应被轻视，能否在激烈的竞争中生存下来，关键在于它们是否能有效嵌入用户工作流、积累独特的数据以及应对来自行业巨头的挑战。</p><p>首先，文章明确区分了 “功能型” 和 “产品型” 的 AI 套壳应用。功能型应用通常只能解决某个特定问题，例如与 PDF 文档进行交互，缺乏独立性，一旦大平台整合这类功能，这些应用就可能被市场淘汰。而产品型应用则能够通过深度集成和数据积累，建立起自己的护城河，增加竞争力。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/1231/6390278874006722929742577.png\" title=\"image.png\" alt=\"image.png\"></p><p>其次，创业公司面临着双重挑战。一方面，它们需要依赖于大型模型提供商的技术支持，另一方面，又要在分发渠道上与这些巨头竞争。例如，编程助手类应用如 Cursor 正在努力转型为集成开发环境，但它们依然受到 API 调用限制的困扰。与此同时，巨头们如 OpenAI 和 Google 可能会迅速将相似功能融入自己的产品中，创业公司必须抢占市场先机。</p><p>最后，文章分析了传统企业在 AI 时代的竞争策略，强调了控制用户流程和积累自有数据的重要性。成功的 “套壳” 产品需要能与用户的日常工作流程紧密结合，不仅仅是一个简单的工具，而是能够解决实际问题的有效方案。</p>"}},{"id":"229093538638034944","type":"news","url":"https://www.qbitai.com/2025/12/366302.html","title":"MiniMax作价461亿港元募资46亿，1月9日敲钟代码00100","description":"MiniMax作价461亿港元募资46亿，1月9日敲钟代码00100 [图片: http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg] Jay 2025-12-31 14:31:32 来源： 量子位 「不完美，但不曾止步」 Jay 发自 凹非寺量子位 | 公众号 QbitAI 又一家中国AI公司来到了敲钟台前。 MiniMax今起招股，作价461亿港元，拟募资超6亿美元。预计将于1月9日正式挂牌上市，代号00100。 核心信息如下—— 股票名称： MiniMax 股份代号：00100 预计募资总额：超6亿美元 发行估值：超461亿港元 发行规模：2538.9万股 定价区间：151-165港元/股 招股期：2025年12月31日–2026年1月6日 上市日：2026年1月9日 魔幻的2025年底，AI公司频频抛出重磅消息。先是Manus加入Meta麾下，紧接着智谱宣布冲刺「全球大模型第一股」。 如今，Minimax，同样推开了港交所的大门。 最后的百米冲刺 AI大新闻，一桩接一桩。 前脚， 智谱刚迈进港交所的大门，MiniMax便紧随其后，手持钟锤冲了进来 。 根据招股书，MiniMax本次IPO拟募资超过6亿美元，估值将超461亿港元，预计于2026年1月9日完成挂牌上市，代号00100。 作为「百模大战」中凯旋而归的代表性玩家，MiniMax此番开启百米冲刺，共有 14家基石投资者 为其撑腰，认购总额约27.23亿港元。其中， 阿里巴巴、阿布扎比投资局 赫然在列。 此外，IDG资本、Perseverance Asset Management以及韩国未来资产，也将成为本次发行的基石投资者之一。 而在AI行业迎来年末大狂欢的同时，港股也进入近年来最为狂热的一次上市窗口期—— 12月是自2019年以来香港IPO最繁忙的一个月，共有25家公司完成上市。 恰值港股年底上新季，智谱和MiniMax先后抓住这道热浪，几乎以并肩之姿，闯入了「全球大模型第一股」的赛道。 二者选择在同一时间点启动招股，一方面点燃了AI圈的市场情绪，另一方面，这波流量不可避免地被一分为二，分别流向两家公司。 究竟谁会在敲钟声响起那天赢得更多的关注度，我们暂未可知。 但可以确定的是，如今离敲钟台近在咫尺的两个身影，皆属于中国大模型公司—— 智谱，和MiniMax。 MiniMax是谁？ 如果用MiniMax给自己的定位来说，这是一家全球化的通用人工智能（AGI）科技公司。 全球化不难理解，MiniMax的服务已经覆盖了全球200多个国家和地区，国际化业务收入占比达70%，公司人才也有30%拥有海外背景。 AGI，则是MiniMax的终极探索目标。 对此，MiniMax创始人闫俊杰曾在与罗永浩的对谈中如此解释： 我们觉得真正的AGI，一定要支持多模态的输入、多模态的输出，只是这件事实在太难了，三年多以前，我们刚开始做的时候，创业的时候，那个时候其实完全没有技术路线，我们的想法就是每个模态至少先走通，到了时机合适的时候就可以再起来整合。 时过境迁，现实成功证明了MiniMax选择的这种模式不是广种薄收，而是多个模态齐头并进。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/0817fa1ce5ffbcba202bc84b24c81c96.jpeg] 先说我们最常接触的文本。 今年6月，MiniMax发布并开源了M1模型，四个月后，M2也闪亮登场。 MiniMax M2 发布期间，在Artificial Analysis榜单刷新了国产文本模型最高成绩——全球前五，开源第一。 而且专为智能体和编程而生，编程能力和Agent表现出众，同时经济高效，推理速度是Claude 4.5 Sonnet的两倍，API价格却只有8%。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/0eca67e6f35c981fa91a95a0df2a7658.jpeg] 这个成绩不是花拳绣腿，从市场反应上看，开发者们用实际行动选择了MiniMax M2—— 在知名模型聚合平台OpenRouter上，MiniMax M2其日消耗量最高跻身全球前三，成为该平台上最受欢迎的中国大模型之一。 再来看语音，2023年起， MiniMax推出国内首个基于Transformer架构的语音大模型Speech 01，2024年，推出升级版本Speech 02，综合性能位列第一。 截至目前，MiniMax语音模型已经迭代到2.6版本，支持40+种语言，帮助用户生成了累计超过2.2亿小时（约2.5万年）的语音。 就连支撑ChatGPT高级语音模式的LiveKit，也是选择了MiniMax Speech作为底层技术引擎，同时该模型也受到了智能玩具、智能眼镜等新物种的青睐。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/5a7ac3f37bcf82e3205f883ec24a1c4f.jpeg] 声音除了有语音之外，还包括音乐， MiniMax音乐模型Music 2.0 ，也被誉为AI界的「全能制作人」。 它支持生成长达5分钟、包含主歌副歌完整结构的专业级歌曲，拥有极高的人声拟真度和精细的编曲控制。 再看视频。 MiniMax视频模型Hailuo ，支持文生视频、图生视频、主体参考、首尾帧等功能，在VBench和Video Arena等国际榜单第三方独立测试结果中综合排名位于第一梯队。 而且性价比依旧超高，再次刷新了全球视频模型效果成本纪录。 海螺AI已成为全球领先的AI视频生成平台，截至目前已帮助全球用户创作超5.9亿视频。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/c70ebc2082185720334d038e6b4e406f.jpeg] 在此之外，MiniMax还积极拥抱智能体热潮，推出了国内首款全栈通用智能体MiniMax Agent，以及支持用户自由创造和分享AI Agent的交互平台 星野 （Talkie）。 B端业务，MiniMax有销售API的 MiniMax开放平台 。前面提到过的所有模型，都能在MiniMax开放平台上找到对应的API服务。 该平台日均处理超万亿Token请求，已累计面向来自超过100个国家及地区的企业客户和开发者提供服务。 另外，还有多家海内外知名应用平台和开源项目同时接入了MiniMax M2。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/7fae19399b0a069bb9300fed2004b5b6.jpeg] 那么，这样的成果和路径选择，又给MiniMax带来了怎样的财务业绩呢？ 先看营收： MiniMax从2023年开始进行商业化，营收已达到346万美元，2024年直接飙升到3052万美元，同比暴涨 782.2% 。 2025年前9个月，公司的营收额再度大涨175%，达到5344万美元，已经远远超越了去年全年的水平。 截至今年9月30日，公司C端收入同比增长了181%，B端收入同比增长了160%。 利润层面，MiniMax的毛利率已出现明显改善：从2023年的-24.7%转正至2024年的12.2%，并在今年前9个月进一步提升至23.3%。 不过，作为对照， 主营B端业务的智谱，毛利率长期维持在50%以上 。 通过这一差异，或许能勾勒出当前AI商业模式的K型分叉——在既有技术条件下，相比C端应用，AI在B端的落地更容易看到价值，企业客户的付费意愿也因此更强。 以MiniMax今年前9个月的数据拆解来看，公司C端与B端业务的毛利率分别为4.7%和69.4%。 因此，若剔除C端产品星野的影响，MiniMax整体毛利率同样将接近50%。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/b10ab859364e37cf85038b0073cfa269.jpeg] 即便如此，和所有AI公司一样，「研发投入」这一黑洞，依然在疯狂抽吸Minimax的财务氧气。 以训练相关的云计算服务开支为例： 2022年、2023年、2024年及2025年前九个月，训练成本分别为415万美元、4723万美元、1.4亿美元和1.42亿美元。整体呈现持续攀升。 不过，从训练成本占收入的比例来看，这一压力已有所缓解。2023年，该比例一度超过1365%，而在2025年前九个月已降至266.5%。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/fa10c10b722d5e702e1b8ddf4d580fd8.jpeg] 尽管如此， 这把高悬的达摩克利斯之剑依然锋利。与智谱一样，MiniMax目前仍处于亏损状态： 2022年、2023年和2024年，公司经调整净亏损分别为1215万美元、8907万美元和2.44亿美元；今年前9个月，MiniMax的经调整净亏损为1.86亿美元。 庆幸的是，MiniMax背后有较为充裕的「现金弹药库」—— 截至2025年9月30日，公司的现金储备合计为 11.02亿美元 （包括现金及等价物和理财产品）。 以公司目前的现金消耗率来看，即便没有IPO募资，账上的现金也足够支持正常运营53个月以上。 能有如此长的续航，除了公司自身运营效率的优化，当然也离不开其背后一众投资人的支持。 谁在吹响上市号角？ MiniMax成立于2022年，放在大模型公司里算得上年轻。 别看成立至今，满打满算只有近4年，但公司背后的投资队伍已是众星云集，其中不乏顶尖资本—— 既有米哈游、阿里、腾讯、小红书、小米、金山、PCG和正大集团这样的战略投资人，亦包括高瓴、IDG、红杉、经纬、明势、云启等知名投资机构，累计融资金融超15亿美元（折合人民币约106亿元）。 一旦成功上市，MiniMax将成为从成立到完成IPO用时最短的公司。 事实上，作为中国的AGI独角兽代表，MiniMax的创始团队拥有极其浓厚的AI积累。 创始人兼CEO 闫俊杰 ，在创立MiniMax之前，就是商汤科技的副总裁，同时也担任商汤科技研究院副院长和智慧城市事业群首席技术官。 他是商汤早期的关键技术人物之一，负责搭建了商汤深引以为傲的深度学习工具链和底层算法体系。 除了闫俊杰本人，MiniMax的早期核心团队中也汇聚了多位具有AI落地经验的技术人才。 早期联合创始人 周彧聪 （商汤算法团队原负责人）和 贠烨祎 （商汤CEO办公室原战略负责人）均曾在AI1.0时代历经实战，这种人才构成的连贯性使得MiniMax在成立之初就具备了成熟的工程化落地能力和算法研究体系。 [图片: https://i.qbitai.com/wp-content/uploads/replace/2025/12/6cee91cb7ed7d6e4a6b4c771826dc6bb.jpeg] 这种「AI基因」对MiniMax最显著的影响，就在于其虽然年轻，却拥有准确的技术路径选择与极高的执行效率。 不仅创始人年轻，MiniMax同样集结了一批年轻员工——全员385人，平均 年龄29岁 （95后）。 而这385名员工中， 研发人员占比高达73.8% 。 而正是这么一家平均年龄不到三十岁的公司，在AI公司普遍向二级市场发起冲刺的人潮涌动中，率先来到了敲钟台前。 敲钟声即将响起之际，MiniMax选择用一场「AI小剧场」，为这「魔幻」的一年作注。 MiniMax稀宇科技 ，赞2593 在这场特别的「聚会」中，MiniMax并未回避当下AIGC仍未克服的种种技术难题，而是以幽默的方式，将这些瑕疵直接呈现在大荧幕上。 MiniMax对此的解读是： 在这段5分钟的故事里，没有炫技，只有最真实、甚至有些狼狈的告白。 有一个影子或许就是你，或者是每一个在过去一年里努力奔跑、却偶尔踉跄的我们。 当公司因研发投入持续失血，市场为泡沫争论不休之际，该行业依然选择继续全仓加码。 硅谷的选择是「资本内循环」，模型厂商和芯片供应商左手倒右手，左脚踩右脚拉高估值。而智谱和MiniMax，选择面向二级市场，率先走上了敲钟台。 AGI的彼岸究竟还有多远，没有人知道。但牌桌上的玩家，今年仍在全速奔跑。 就用MiniMax自己的话，作为其2025年的注脚吧—— 「不完美，但不曾止步」。 参考链接： [1]https://www.bloomberg.com/news/articles/2025-12-30/alibaba-abu-dhabi-set-to-invest-in-minimax-s-600-million-ipo?embedded-checkout=true [2]https://baijiahao.baidu.com/s?id=1852980336240113598&#x26;wfr=spider&#x26;for=pc [3]https://mp.weixin.qq.com/s/rMgkUAvZElPmxyVDMENFHw 版权所有，未经授权不得以任何形式转载及使用，违者必究。","published_date":"2025-12-31T06:31:32.454Z","authors":"量子位","source":"量子位 - 资讯 - 量子位","details":{"content_html":"<h1>MiniMax作价461亿港元募资46亿，1月9日敲钟代码00100</h1>\n       <div>\n             <span><img src=\"http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg\" height=\"200\" width=\"200\"><em><a href=\"https://www.qbitai.com/author/jay\" title=\"由 Jay 发布\" target=\"_blank\">Jay</a></em></span>\n                          <span>2025-12-31</span>\n             <span>14:31:32</span>\n          <span>\n          来源：<a href=\"https://www.qbitai.com/\" target=\"_blank\">量子位</a>            </span></div>\n                          \n            <div><p>「不完美，但不曾止步」</p>\n</div>                <blockquote>\n<p>Jay 发自 凹非寺量子位 | 公众号 QbitAI</p>\n</blockquote>\n<p>又一家中国AI公司来到了敲钟台前。</p>\n<p>MiniMax今起招股，作价461亿港元，拟募资超6亿美元。预计将于1月9日正式挂牌上市，代号00100。</p>\n<p><strong>核心信息如下——</strong></p>\n<ul>\n<li>股票名称： MiniMax</li>\n<li>股份代号：00100</li>\n<li>预计募资总额：超6亿美元</li>\n<li>发行估值：超461亿港元</li>\n<li>发行规模：2538.9万股</li>\n<li>定价区间：151-165港元/股</li>\n<li>招股期：2025年12月31日–2026年1月6日</li>\n<li>上市日：2026年1月9日</li>\n</ul>\n<p>魔幻的2025年底，AI公司频频抛出重磅消息。先是Manus加入Meta麾下，紧接着智谱宣布冲刺「全球大模型第一股」。</p>\n<p>如今，Minimax，同样推开了港交所的大门。</p>\n<h1>最后的百米冲刺</h1>\n<p>AI大新闻，一桩接一桩。</p>\n<p>前脚，<strong>智谱刚迈进港交所的大门，MiniMax便紧随其后，手持钟锤冲了进来</strong>。</p>\n<p>根据招股书，MiniMax本次IPO拟募资超过6亿美元，估值将超461亿港元，预计于2026年1月9日完成挂牌上市，代号00100。</p>\n<p>作为「百模大战」中凯旋而归的代表性玩家，MiniMax此番开启百米冲刺，共有<strong>14家基石投资者</strong>为其撑腰，认购总额约27.23亿港元。其中，<strong>阿里巴巴、阿布扎比投资局</strong>赫然在列。</p>\n<p>此外，IDG资本、Perseverance Asset Management以及韩国未来资产，也将成为本次发行的基石投资者之一。</p>\n<p>而在AI行业迎来年末大狂欢的同时，港股也进入近年来最为狂热的一次上市窗口期——</p>\n<p><strong>12月是自2019年以来香港IPO最繁忙的一个月，共有25家公司完成上市。</strong></p>\n<p>恰值港股年底上新季，智谱和MiniMax先后抓住这道热浪，几乎以并肩之姿，闯入了「全球大模型第一股」的赛道。</p>\n<p>二者选择在同一时间点启动招股，一方面点燃了AI圈的市场情绪，另一方面，这波流量不可避免地被一分为二，分别流向两家公司。</p>\n<p>究竟谁会在敲钟声响起那天赢得更多的关注度，我们暂未可知。</p>\n<p>但可以确定的是，如今离敲钟台近在咫尺的两个身影，皆属于中国大模型公司——</p>\n<p><strong>智谱，和MiniMax。</strong></p>\n<h1>MiniMax是谁？</h1>\n<p>如果用MiniMax给自己的定位来说，这是一家全球化的通用人工智能（AGI）科技公司。</p>\n<p>全球化不难理解，MiniMax的服务已经覆盖了全球200多个国家和地区，国际化业务收入占比达70%，公司人才也有30%拥有海外背景。</p>\n<p>AGI，则是MiniMax的终极探索目标。</p>\n<p>对此，MiniMax创始人闫俊杰曾在与罗永浩的对谈中如此解释：</p>\n<blockquote>\n<p>我们觉得真正的AGI，一定要支持多模态的输入、多模态的输出，只是这件事实在太难了，三年多以前，我们刚开始做的时候，创业的时候，那个时候其实完全没有技术路线，我们的想法就是每个模态至少先走通，到了时机合适的时候就可以再起来整合。</p>\n</blockquote>\n<p>时过境迁，现实成功证明了MiniMax选择的这种模式不是广种薄收，而是多个模态齐头并进。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/0817fa1ce5ffbcba202bc84b24c81c96.jpeg\"></div>\n<p>先说我们最常接触的文本。</p>\n<p>今年6月，MiniMax发布并开源了M1模型，四个月后，M2也闪亮登场。</p>\n<p><strong>MiniMax M2</strong>发布期间，在Artificial Analysis榜单刷新了国产文本模型最高成绩——全球前五，开源第一。</p>\n<p>而且专为智能体和编程而生，编程能力和Agent表现出众，同时经济高效，推理速度是Claude 4.5 Sonnet的两倍，API价格却只有8%。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/0eca67e6f35c981fa91a95a0df2a7658.jpeg\"></div>\n<p>这个成绩不是花拳绣腿，从市场反应上看，开发者们用实际行动选择了MiniMax M2——</p>\n<p>在知名模型聚合平台OpenRouter上，MiniMax M2其日消耗量最高跻身全球前三，成为该平台上最受欢迎的中国大模型之一。</p>\n<p>再来看语音，2023年起， MiniMax推出国内首个基于Transformer架构的语音大模型Speech 01，2024年，推出升级版本Speech 02，综合性能位列第一。</p>\n<p>截至目前，MiniMax语音模型已经迭代到2.6版本，支持40+种语言，帮助用户生成了累计超过2.2亿小时（约2.5万年）的语音。</p>\n<p>就连支撑ChatGPT高级语音模式的LiveKit，也是选择了MiniMax Speech作为底层技术引擎，同时该模型也受到了智能玩具、智能眼镜等新物种的青睐。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/5a7ac3f37bcf82e3205f883ec24a1c4f.jpeg\"></div>\n<p>声音除了有语音之外，还包括音乐，<strong>MiniMax音乐模型Music 2.0</strong>，也被誉为AI界的「全能制作人」。</p>\n<p>它支持生成长达5分钟、包含主歌副歌完整结构的专业级歌曲，拥有极高的人声拟真度和精细的编曲控制。</p>\n<p>再看视频。</p>\n<p><strong>MiniMax视频模型Hailuo</strong>，支持文生视频、图生视频、主体参考、首尾帧等功能，在VBench和Video Arena等国际榜单第三方独立测试结果中综合排名位于第一梯队。</p>\n<p>而且性价比依旧超高，再次刷新了全球视频模型效果成本纪录。</p>\n<p>海螺AI已成为全球领先的AI视频生成平台，截至目前已帮助全球用户创作超5.9亿视频。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/c70ebc2082185720334d038e6b4e406f.jpeg\"></div>\n<p>在此之外，MiniMax还积极拥抱智能体热潮，推出了国内首款全栈通用智能体MiniMax Agent，以及支持用户自由创造和分享AI Agent的交互平台<strong>星野</strong>（Talkie）。</p>\n<p>B端业务，MiniMax有销售API的<strong>MiniMax开放平台</strong>。前面提到过的所有模型，都能在MiniMax开放平台上找到对应的API服务。</p>\n<p>该平台日均处理超万亿Token请求，已累计面向来自超过100个国家及地区的企业客户和开发者提供服务。</p>\n<p>另外，还有多家海内外知名应用平台和开源项目同时接入了MiniMax M2。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/7fae19399b0a069bb9300fed2004b5b6.jpeg\"></div>\n<p>那么，这样的成果和路径选择，又给MiniMax带来了怎样的财务业绩呢？</p>\n<p>先看营收：</p>\n<p>MiniMax从2023年开始进行商业化，营收已达到346万美元，2024年直接飙升到3052万美元，同比暴涨<strong>782.2%</strong>。</p>\n<p>2025年前9个月，公司的营收额再度大涨175%，达到5344万美元，已经远远超越了去年全年的水平。</p>\n<p>截至今年9月30日，公司C端收入同比增长了181%，B端收入同比增长了160%。</p>\n<p>利润层面，MiniMax的毛利率已出现明显改善：从2023年的-24.7%转正至2024年的12.2%，并在今年前9个月进一步提升至23.3%。</p>\n<p>不过，作为对照，<strong>主营B端业务的智谱，毛利率长期维持在50%以上</strong>。</p>\n<p>通过这一差异，或许能勾勒出当前AI商业模式的K型分叉——在既有技术条件下，相比C端应用，AI在B端的落地更容易看到价值，企业客户的付费意愿也因此更强。</p>\n<p>以MiniMax今年前9个月的数据拆解来看，公司C端与B端业务的毛利率分别为4.7%和69.4%。</p>\n<p>因此，若剔除C端产品星野的影响，MiniMax整体毛利率同样将接近50%。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/b10ab859364e37cf85038b0073cfa269.jpeg\"></div>\n<p>即便如此，和所有AI公司一样，「研发投入」这一黑洞，依然在疯狂抽吸Minimax的财务氧气。</p>\n<p><strong>以训练相关的云计算服务开支为例：</strong></p>\n<p>2022年、2023年、2024年及2025年前九个月，训练成本分别为415万美元、4723万美元、1.4亿美元和1.42亿美元。整体呈现持续攀升。</p>\n<p>不过，从训练成本占收入的比例来看，这一压力已有所缓解。2023年，该比例一度超过1365%，而在2025年前九个月已降至266.5%。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/fa10c10b722d5e702e1b8ddf4d580fd8.jpeg\"></div>\n<p>尽管如此， 这把高悬的达摩克利斯之剑依然锋利。与智谱一样，MiniMax目前仍处于亏损状态：</p>\n<p>2022年、2023年和2024年，公司经调整净亏损分别为1215万美元、8907万美元和2.44亿美元；今年前9个月，MiniMax的经调整净亏损为1.86亿美元。</p>\n<p>庆幸的是，MiniMax背后有较为充裕的「现金弹药库」——</p>\n<p>截至2025年9月30日，公司的现金储备合计为<strong>11.02亿美元</strong>（包括现金及等价物和理财产品）。</p>\n<p>以公司目前的现金消耗率来看，即便没有IPO募资，账上的现金也足够支持正常运营53个月以上。</p>\n<p>能有如此长的续航，除了公司自身运营效率的优化，当然也离不开其背后一众投资人的支持。</p>\n<h1>谁在吹响上市号角？</h1>\n<p>MiniMax成立于2022年，放在大模型公司里算得上年轻。</p>\n<p>别看成立至今，满打满算只有近4年，但公司背后的投资队伍已是众星云集，其中不乏顶尖资本——</p>\n<p>既有米哈游、阿里、腾讯、小红书、小米、金山、PCG和正大集团这样的战略投资人，亦包括高瓴、IDG、红杉、经纬、明势、云启等知名投资机构，累计融资金融超15亿美元（折合人民币约106亿元）。</p>\n<p>一旦成功上市，MiniMax将成为从成立到完成IPO用时最短的公司。</p>\n<p>事实上，作为中国的AGI独角兽代表，MiniMax的创始团队拥有极其浓厚的AI积累。</p>\n<p>创始人兼CEO<strong>闫俊杰</strong>，在创立MiniMax之前，就是商汤科技的副总裁，同时也担任商汤科技研究院副院长和智慧城市事业群首席技术官。</p>\n<p>他是商汤早期的关键技术人物之一，负责搭建了商汤深引以为傲的深度学习工具链和底层算法体系。</p>\n<p>除了闫俊杰本人，MiniMax的早期核心团队中也汇聚了多位具有AI落地经验的技术人才。</p>\n<p>早期联合创始人<strong>周彧聪</strong>（商汤算法团队原负责人）和<strong>贠烨祎</strong>（商汤CEO办公室原战略负责人）均曾在AI1.0时代历经实战，这种人才构成的连贯性使得MiniMax在成立之初就具备了成熟的工程化落地能力和算法研究体系。</p>\n<div><img src=\"https://i.qbitai.com/wp-content/uploads/replace/2025/12/6cee91cb7ed7d6e4a6b4c771826dc6bb.jpeg\"></div>\n<p>这种「AI基因」对MiniMax最显著的影响，就在于其虽然年轻，却拥有准确的技术路径选择与极高的执行效率。</p>\n<p>不仅创始人年轻，MiniMax同样集结了一批年轻员工——全员385人，平均<strong>年龄29岁</strong>（95后）。</p>\n<p>而这385名员工中，<strong>研发人员占比高达73.8%</strong>。</p>\n<p>而正是这么一家平均年龄不到三十岁的公司，在AI公司普遍向二级市场发起冲刺的人潮涌动中，率先来到了敲钟台前。</p>\n<p>敲钟声即将响起之际，MiniMax选择用一场「AI小剧场」，为这「魔幻」的一年作注。</p>\n<p>MiniMax稀宇科技</p>\n<p>，赞2593</p>\n<p>在这场特别的「聚会」中，MiniMax并未回避当下AIGC仍未克服的种种技术难题，而是以幽默的方式，将这些瑕疵直接呈现在大荧幕上。</p>\n<p>MiniMax对此的解读是：</p>\n<blockquote>\n<p>在这段5分钟的故事里，没有炫技，只有最真实、甚至有些狼狈的告白。 有一个影子或许就是你，或者是每一个在过去一年里努力奔跑、却偶尔踉跄的我们。</p>\n</blockquote>\n<p>当公司因研发投入持续失血，市场为泡沫争论不休之际，该行业依然选择继续全仓加码。</p>\n<p>硅谷的选择是「资本内循环」，模型厂商和芯片供应商左手倒右手，左脚踩右脚拉高估值。而智谱和MiniMax，选择面向二级市场，率先走上了敲钟台。</p>\n<p>AGI的彼岸究竟还有多远，没有人知道。但牌桌上的玩家，今年仍在全速奔跑。</p>\n<p>就用MiniMax自己的话，作为其2025年的注脚吧——</p>\n<p><strong>「不完美，但不曾止步」。</strong></p>\n<p>参考链接：<br>\n[1]https://www.bloomberg.com/news/articles/2025-12-30/alibaba-abu-dhabi-set-to-invest-in-minimax-s-600-million-ipo?embedded-checkout=true<br>\n[2]https://baijiahao.baidu.com/s?id=1852980336240113598&#x26;wfr=spider&#x26;for=pc<br>\n[3]https://mp.weixin.qq.com/s/rMgkUAvZElPmxyVDMENFHw</p>\n<p> </p>\n                \n                \n                <div><span></span><em>版权所有，未经授权不得以任何形式转载及使用，违者必究。</em><span></span></div>\n            "}},{"id":"229087934572283905","type":"news","url":"https://newshacker.me/story?id=46388445","title":"🤔 如果文件能“有重量”：触觉映射的可行性、可用性与先例","description":"原标题： 《What If Heavy Files Felt Heavy?》 评分: 24 | 作者: shiveeshfotedar 💭 既然文件会有重量，是不是要算运费和保险？ 🎯 讨论背景 讨论源于一个交互实验“如果文件有重量会怎样？”，演示地址为 pressureinteraction.netlify.app。作者用压力感应/触觉反馈或视觉手法把文件大小映射为“重量”或阻力，触发了关于可用性、可访问性与技术实现的讨论。评论回顾了触觉交互的先例（如 Immersion，一家触觉技术公司；Logitech 的 Wingman Force Feedback Mouse，一款 90 年代力反馈鼠标），并提出通过 Active Accessibility（操作系统无障碍 API）、Hall effect 传感器或 Android 触点半径等手段实现压力输入的可行路径。讨论还涉及实际场景（游戏、备份/磁盘整理、系统指标监测）与替代设计（视觉深度或数值显示），同时指出平台支持与直觉映射的局限。 📌 讨论焦点 可用性与用户体验担忧 很多评论认为把文件“变重”违反良好的界面设计原则：让大文件变得难以移动会增加不必要的认知与操作负担。有人指出鼠标无法真正施力（it just clicks），所以用力感作为交互会很快令人厌烦。Force Touch 的压力方向和用户对重量的直觉不一致（更像浮力），演示中在施加足够向下压力后重物与轻物的拖动没有差异，这削弱了概念的直观性。另有观点强调“重是相对的”：在视频工作流中多数文件都很大，而小文本文件可能更重要，单以大小来表达重要性会产生误导。 [来源1] [来源2] [来源3] 视觉化替代与设计建议 有人建议用纯视觉手段替代真实阻力来表达文件大小，以避免引入物理摩擦。具体方案是保持图标前视面积不变，但在视觉上向后延展成有深度的形状：小文本像薄纸，10MB 像厚纸板，2GB 视频像有深度的盒子。评论里明确提出这种深度感应应采用对数缩放（logarithmic），以更符合人类感知而非线性映射。该方法保留了可感知的“重量”提示同时避免实际拖动难度。 [来源1] 先例、实现技术与可行性（触觉/力反馈） 有从业者回忆了触觉交互的历史与硬件先例，比如 Immersion（触觉技术公司）与 Logitech 的 Wingman Force Feedback Mouse（90 年代的力反馈鼠标），后者能在 X/Y 平面产生力效应。触觉交互常用的原语包括 enclosures（包围区）、spring-damper（弹簧-阻尼）和振动，可以把文件映射为不同的粘滞性或 spring K 来表现“重量”。实现层面可以通过操作系统的无障碍接口（Active Accessibility）读取桌面元素并生成触觉效果，或在键盘上用 Hall effect 传感器推断击键速度，Android 上也可用触点半径模拟压力；但需要注意平台支持差异（例如 Apple 已弃用压力屏）。演示是基于 Z-axis 的压力输入，真实硬件能做更复杂的 2D/3D 力反馈效果。 [来源1] [来源2] [来源3] [来源4] [来源5] 概念潜力与实际场景 许多评论把这个实验当作有趣的思想实验并认为值得继续探索，尤其在游戏等需要细腻控制的场景中有明显价值。实际应用设想包括备份或磁盘整理时用“重量”来判断文件或文件夹是否能装下、在磁盘间“抛接”文件以感知是否合适，以及把触觉作为监测网络流量或内存带宽等系统指标的旁路反馈。也有人提出把它与压力感应键盘结合，依据击键力度改变字体大小或触发特殊模式，但同时不少人仍偏好直接看到字节数等数值表示作为精确反馈。 [来源1] [来源2] [来源3] 📚 术语解释 Haptic feedback（触觉反馈）: 通过力、振动或阻尼等触觉信号向用户传达界面状态或事件的技术；可将文件大小或属性映射为‘重量’、阻力或振动提示。 Force Touch / Pressure sensitivity（Force Touch/压力感应）: 设备检测触控或按压力度（或触点半径）并将其映射为交互输入的机制；演示中用于把按压力度当作“承受重量”的输入。 Hall effect（霍尔效应 / Hall sensor）: 利用磁场测量位置或速度的传感器技术，可用于键盘检测键程/速度以推断按压力度或击键强度，适合实现压力感知的硬件手段。 Active Accessibility（Active Accessibility / 无障碍 API）: 操作系统提供的无障碍接口（例如 Windows 的 Active Accessibility），可以读取 UI 元素与事件，用来驱动触觉或其他辅助输出。 Spring-damper（弹簧-阻尼模型）: 力反馈和物理模拟常用的建模原语，用弹簧常数(K)和阻尼描述回复力与粘滞性，可用于模拟物体的弹性或黏滞‘重量’感。 类别： Product | Hardware | Web | Opinion | file size | pressure sensitivity | Force Touch | UX | shiveesh.com | pressureinteraction.netlify.app","published_date":"2025-12-31T06:16:14.805Z","authors":"","source":"News Hacker | 极客洞察","details":{"content_html":"<p><strong>原标题：</strong>《What If Heavy Files Felt Heavy?》</p><p><strong>评分:</strong> 24 | <strong>作者:</strong> shiveeshfotedar</p><blockquote>💭 既然文件会有重量，是不是要算运费和保险？</blockquote><hr><h2>🎯 讨论背景</h2><p>讨论源于一个交互实验“如果文件有重量会怎样？”，演示地址为 pressureinteraction.netlify.app。作者用压力感应/触觉反馈或视觉手法把文件大小映射为“重量”或阻力，触发了关于可用性、可访问性与技术实现的讨论。评论回顾了触觉交互的先例（如 Immersion，一家触觉技术公司；Logitech 的 Wingman Force Feedback Mouse，一款 90 年代力反馈鼠标），并提出通过 Active Accessibility（操作系统无障碍 API）、Hall effect 传感器或 Android 触点半径等手段实现压力输入的可行路径。讨论还涉及实际场景（游戏、备份/磁盘整理、系统指标监测）与替代设计（视觉深度或数值显示），同时指出平台支持与直觉映射的局限。</p><hr><h2>📌 讨论焦点</h2><h3>可用性与用户体验担忧</h3><p>很多评论认为把文件“变重”违反良好的界面设计原则：让大文件变得难以移动会增加不必要的认知与操作负担。有人指出鼠标无法真正施力（it just clicks），所以用力感作为交互会很快令人厌烦。Force Touch 的压力方向和用户对重量的直觉不一致（更像浮力），演示中在施加足够向下压力后重物与轻物的拖动没有差异，这削弱了概念的直观性。另有观点强调“重是相对的”：在视频工作流中多数文件都很大，而小文本文件可能更重要，单以大小来表达重要性会产生误导。</p><p><a href=\"https://news.ycombinator.com/item?id=46441526\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441615\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441228\" target=\"_blank\">[来源3]</a></p><h3>视觉化替代与设计建议</h3><p>有人建议用纯视觉手段替代真实阻力来表达文件大小，以避免引入物理摩擦。具体方案是保持图标前视面积不变，但在视觉上向后延展成有深度的形状：小文本像薄纸，10MB 像厚纸板，2GB 视频像有深度的盒子。评论里明确提出这种深度感应应采用对数缩放（logarithmic），以更符合人类感知而非线性映射。该方法保留了可感知的“重量”提示同时避免实际拖动难度。</p><p><a href=\"https://news.ycombinator.com/item?id=46441526\" target=\"_blank\">[来源1]</a></p><h3>先例、实现技术与可行性（触觉/力反馈）</h3><p>有从业者回忆了触觉交互的历史与硬件先例，比如 Immersion（触觉技术公司）与 Logitech 的 Wingman Force Feedback Mouse（90 年代的力反馈鼠标），后者能在 X/Y 平面产生力效应。触觉交互常用的原语包括 enclosures（包围区）、spring-damper（弹簧-阻尼）和振动，可以把文件映射为不同的粘滞性或 spring K 来表现“重量”。实现层面可以通过操作系统的无障碍接口（Active Accessibility）读取桌面元素并生成触觉效果，或在键盘上用 Hall effect 传感器推断击键速度，Android 上也可用触点半径模拟压力；但需要注意平台支持差异（例如 Apple 已弃用压力屏）。演示是基于 Z-axis 的压力输入，真实硬件能做更复杂的 2D/3D 力反馈效果。</p><p><a href=\"https://news.ycombinator.com/item?id=46441299\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441530\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441210\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441512\" target=\"_blank\">[来源4]</a> <a href=\"https://news.ycombinator.com/item?id=46441169\" target=\"_blank\">[来源5]</a></p><h3>概念潜力与实际场景</h3><p>许多评论把这个实验当作有趣的思想实验并认为值得继续探索，尤其在游戏等需要细腻控制的场景中有明显价值。实际应用设想包括备份或磁盘整理时用“重量”来判断文件或文件夹是否能装下、在磁盘间“抛接”文件以感知是否合适，以及把触觉作为监测网络流量或内存带宽等系统指标的旁路反馈。也有人提出把它与压力感应键盘结合，依据击键力度改变字体大小或触发特殊模式，但同时不少人仍偏好直接看到字节数等数值表示作为精确反馈。</p><p><a href=\"https://news.ycombinator.com/item?id=46441496\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441350\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441164\" target=\"_blank\">[来源3]</a></p><hr><h2>📚 术语解释</h2><p><strong>Haptic feedback（触觉反馈）:</strong> 通过力、振动或阻尼等触觉信号向用户传达界面状态或事件的技术；可将文件大小或属性映射为‘重量’、阻力或振动提示。</p><p><strong>Force Touch / Pressure sensitivity（Force Touch/压力感应）:</strong> 设备检测触控或按压力度（或触点半径）并将其映射为交互输入的机制；演示中用于把按压力度当作“承受重量”的输入。</p><p><strong>Hall effect（霍尔效应 / Hall sensor）:</strong> 利用磁场测量位置或速度的传感器技术，可用于键盘检测键程/速度以推断按压力度或击键强度，适合实现压力感知的硬件手段。</p><p><strong>Active Accessibility（Active Accessibility / 无障碍 API）:</strong> 操作系统提供的无障碍接口（例如 Windows 的 Active Accessibility），可以读取 UI 元素与事件，用来驱动触觉或其他辅助输出。</p><p><strong>Spring-damper（弹簧-阻尼模型）:</strong> 力反馈和物理模拟常用的建模原语，用弹簧常数(K)和阻尼描述回复力与粘滞性，可用于模拟物体的弹性或黏滞‘重量’感。</p><hr><p><strong>类别：</strong>Product | Hardware | Web | Opinion | file size | pressure sensitivity | Force Touch | UX | shiveesh.com | pressureinteraction.netlify.app</p>"}},{"id":"229075542105192448","type":"news","url":"https://www.aibase.com/zh/news/24164","title":"快手副总裁周国睿即将离职，前路成谜！加入 Meta 或 TikTok？","description":"12 月 30 日，有消息传出，快手科技副总裁、基础大模型及推荐模型负责人周国睿即将离职。这一消息来自多个独立信源，令人关注的是，周国睿可能会选择加入 Meta（脸书母公司）或 TikTok（抖音国际版）。据了解，目前他在公司内部的状态显示为休假，并且他的电子邮件签名已变更为 “Log Out”，似乎暗示着他即将踏上新的职业旅程。 周国睿拥有丰富的技术背景，他硕士毕业于北京邮电大学的模式识别实验室。在加入快手之前，他在阿里巴巴工作，曾担任阿里妈妈事业部的 高级 算法专家，负责精准定向广告的排序相关业务。在 2021 年，周国睿加盟快手，之后迅速晋升为推荐算法副总裁以及基础大模型和推荐模型的负责人。在他的领导下，快手推出了创新性的生成式端到端架构 “OneRec”，成功重构了推荐链路。这一成果让快手在核心业务场景中实现了 “更大模型，成本更低” 的突破，极大降低了系统成本，提升了推荐系统的智能化和效率。 值得一提的是，快手的技术团队在过去两年内经历了多次人事变动。早在几个月前，快手的另一位技术副总裁张迪选择离职，并短暂加入 B 站，后又返回阿里巴巴。此外，快手国际化电商算法负责人王犇和其他几位副总裁级别的算法专家也相继离职。这一系列的变动让人们开始关注快手的技术人才流失情况。 周国睿的离职可能会对快手的技术发展和推荐系统优化产生影响，而他接下来的去向也备受瞩目。无论是选择 Meta 还是 TikTok，都将成为业界关注的焦点。","published_date":"2025-12-31T06:13:27.073Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>12 月 30 日，有消息传出，快手科技副总裁、基础大模型及推荐模型负责人周国睿即将离职。这一消息来自多个独立信源，令人关注的是，周国睿可能会选择加入 Meta（脸书母公司）或 TikTok（抖音国际版）。据了解，目前他在公司内部的状态显示为休假，并且他的电子邮件签名已变更为 “Log Out”，似乎暗示着他即将踏上新的职业旅程。</p><p>周国睿拥有丰富的技术背景，他硕士毕业于北京邮电大学的模式识别实验室。在加入快手之前，他在阿里巴巴工作，曾担任阿里妈妈事业部的<span>高级</span>算法专家，负责精准定向广告的排序相关业务。在 2021 年，周国睿加盟快手，之后迅速晋升为推荐算法副总裁以及基础大模型和推荐模型的负责人。在他的领导下，快手推出了创新性的生成式端到端架构 “OneRec”，成功重构了推荐链路。这一成果让快手在核心业务场景中实现了 “更大模型，成本更低” 的突破，极大降低了系统成本，提升了推荐系统的智能化和效率。</p><p>值得一提的是，快手的技术团队在过去两年内经历了多次人事变动。早在几个月前，快手的另一位技术副总裁张迪选择离职，并短暂加入 B 站，后又返回阿里巴巴。此外，快手国际化电商算法负责人王犇和其他几位副总裁级别的算法专家也相继离职。这一系列的变动让人们开始关注快手的技术人才流失情况。</p><p>周国睿的离职可能会对快手的技术发展和推荐系统优化产生影响，而他接下来的去向也备受瞩目。无论是选择 Meta 还是 TikTok，都将成为业界关注的焦点。</p>"}},{"id":"229075542105192449","type":"news","url":"https://www.aibase.com/zh/news/24163","title":"智能眼镜、手环也能享以旧换新补贴!2026年“两新”政策新增AI产品支持","description":"2026年“两新”政策（大规模设备更新和消费品以旧换新）迎来重要升级。据央视新闻消息，国家在原有汽车、家电、数码产品补贴基础上，** 首次 将智能眼镜、智能家居产品(含适老化家居)纳入“以旧换新”补贴范围**，标志着智能化终端正加速融入普惠性消费支持体系。 [图片: 眼镜，智能眼镜 https://pic.chinaz.com/picmap/202508151057298545_0.jpg] 根据 最新 政策细则，**个人消费者购买四类数码与智能产品——手机、平板、智能手表（含手环）、智能眼镜**，且单件销售价格不超过6000元，即可按**产品售价的15%获得财政补贴**，每类产品限补1件，**单件 最高 补贴500元**。此举显著降低了AR眼镜、AI健康手环等前沿智能设备的购买门槛。 此外，智能家居产品（如智能门锁、语音控制照明、适老化跌倒监测系统等）也被纳入支持范畴。具体补贴品类和标准由各地结合实际情况自主制定，赋予地方更大灵活性以响应本地老龄化、数字化等差异化需求。 国家信息中心经济预测部宏观经济研究室副主任邹蕴涵指出，此次政策调整的核心逻辑是“**产品向新**”——通过补贴引导，推动人工智能、物联网等新技术产品从“尝鲜”走向“常用”。“像AR智能眼镜这类过去被视为小众的设备，现在也能享受以旧换新补贴，说明国家正系统性推动高品质智能产品走进千家万户的日常生活。” 分析认为，这一政策不仅将刺激消费、释放内需潜力，更将加速AI终端在健康监测、远程协作、银发经济等场景的规模化落地。对产业链而言，补贴有望带动国产智能硬件、操作系统和边缘AI芯片的协同创新，进一步夯实“智能+”生态底座。","published_date":"2025-12-31T06:11:13.151Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p><span style=\"text-indent: 2em;\">2026年“两新”政策（大规模设备更新和消费品以旧换新）迎来重要升级。据央视新闻消息，国家在原有汽车、家电、数码产品补贴基础上，**<span>首次</span>将智能眼镜、智能家居产品(含适老化家居)纳入“以旧换新”补贴范围**，标志着智能化终端正加速融入普惠性消费支持体系。</span></p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202508151057298545_0.jpg\" title=\"眼镜，智能眼镜 (图片来源：AI合成)\" alt=\"眼镜，智能眼镜\"></p><p>根据<span>最新</span>政策细则，**个人消费者购买四类数码与智能产品——手机、平板、智能手表（含手环）、智能眼镜**，且单件销售价格不超过6000元，即可按**产品售价的15%获得财政补贴**，每类产品限补1件，**单件<span>最高</span>补贴500元**。此举显著降低了AR眼镜、AI健康手环等前沿智能设备的购买门槛。</p><p>此外，智能家居产品（如智能门锁、语音控制照明、适老化跌倒监测系统等）也被纳入支持范畴。具体补贴品类和标准由各地结合实际情况自主制定，赋予地方更大灵活性以响应本地老龄化、数字化等差异化需求。</p><p>国家信息中心经济预测部宏观经济研究室副主任邹蕴涵指出，此次政策调整的核心逻辑是“**产品向新**”——通过补贴引导，推动人工智能、物联网等新技术产品从“尝鲜”走向“常用”。“像AR智能眼镜这类过去被视为小众的设备，现在也能享受以旧换新补贴，说明国家正系统性推动高品质智能产品走进千家万户的日常生活。”</p><p>分析认为，这一政策不仅将刺激消费、释放内需潜力，更将加速AI终端在健康监测、远程协作、银发经济等场景的规模化落地。对产业链而言，补贴有望带动国产智能硬件、操作系统和边缘AI芯片的协同创新，进一步夯实“智能+”生态底座。</p>"}},{"id":"229075542105192450","type":"news","url":"https://www.aibase.com/zh/news/24162","title":"OpenAI 员工年薪翻天！人均股票薪酬高达 150 万美元，创科技行业新纪录！","description":"在科技行业竞争日益激烈的背景下，OpenAI 的薪酬数据让人瞩目。 最新 财务报告显示，这家领先的人工智能公司向约 4000 名员工支付的股票薪酬人均高达 150 万美元，创下了科技初创公司历史的新高。这个数字是过去 25 年里其他 18 家主要科技公司在上市前一年员工薪酬的 34 倍，实在让人惊叹。 根据分析，OpenAI 预计在 2030 年前每年将为员工发放约 30 亿美元的股票薪酬。此外，OpenAI 还取消了员工获得股票的归属期政策，过去需要工作满六个月才能获股权的规定已不复存在。这一改变可能会进一步推高员工的薪酬水平，吸引更多 顶尖 人才加入这家创新企业。 对于薪酬占收入的比例，分析表明，到 2025 年，OpenAI 的员工薪酬将占公司收入的 46%。这一比例仅次于电动车制造商 Rivian，高于 Palantir、谷歌和 Facebook 等知名企业，显示出 OpenAI 在薪酬激励方面的雄心壮志。 毫无疑问，这样的薪酬政策不仅能够吸引人才，还有助于留住现有员工。OpenAI 的做法或将成为其他科技公司的借鉴，推动整个行业在薪酬结构上进行重新审视。 随着人工智能的迅猛发展，OpenAI 作为行业的先锋，不仅在技术创新上走在前列，也在薪酬激励上树立了新标杆。这一切都表明，未来的竞争不仅仅是技术的较量，更是人才和薪酬的博弈。","published_date":"2025-12-31T06:09:23.789Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>在科技行业竞争日益激烈的背景下，OpenAI 的薪酬数据让人瞩目。<span>最新</span>财务报告显示，这家领先的人工智能公司向约 4000 名员工支付的股票薪酬人均高达 150 万美元，创下了科技初创公司历史的新高。这个数字是过去 25 年里其他 18 家主要科技公司在上市前一年员工薪酬的 34 倍，实在让人惊叹。</p><p>根据分析，OpenAI 预计在 2030 年前每年将为员工发放约 30 亿美元的股票薪酬。此外，OpenAI 还取消了员工获得股票的归属期政策，过去需要工作满六个月才能获股权的规定已不复存在。这一改变可能会进一步推高员工的薪酬水平，吸引更多<span>顶尖</span>人才加入这家创新企业。</p><p>对于薪酬占收入的比例，分析表明，到 2025 年，OpenAI 的员工薪酬将占公司收入的 46%。这一比例仅次于电动车制造商 Rivian，高于 Palantir、谷歌和 Facebook 等知名企业，显示出 OpenAI 在薪酬激励方面的雄心壮志。</p><p>毫无疑问，这样的薪酬政策不仅能够吸引人才，还有助于留住现有员工。OpenAI 的做法或将成为其他科技公司的借鉴，推动整个行业在薪酬结构上进行重新审视。</p><p>随着人工智能的迅猛发展，OpenAI 作为行业的先锋，不仅在技术创新上走在前列，也在薪酬激励上树立了新标杆。这一切都表明，未来的竞争不仅仅是技术的较量，更是人才和薪酬的博弈。</p><p><br></p>"}},{"id":"229075542105192451","type":"news","url":"https://www.aibase.com/zh/news/24161","title":"​谷歌 Nano Banana AI 工具引发 1.5 亿用户隐私担忧","description":"近日，谷歌的 Nano Banana AI 工具引发了新的隐私问题，关注点集中在全球15亿用户的照片分析与存储上。根据《福布斯》的一项报道，谷歌在其照片存储服务 Google Photos 中被指控可能在未经用户同意的情况下，利用这些照片为其强大的 AI 系统提供数据。这一指控并非来自监管机构或内部告发者，而是来自于专注隐私的科技公司 Proton，这家公司在云存储领域与谷歌直接竞争。 这一争议的时机引人注目，因为这一指控出现在谷歌的新 AI 图像工具 Nano Banana 受到广泛关注之后，后者因生成逼真图像而受到批评，许多人认为现实与虚构的界限正在迅速模糊。Proton 在社交媒体平台 X 上发布的帖子迅速传播，称 “谷歌 AI 之所以在生成图像方面表现优异，原因在于它们正在扫描每位安卓用户的 Google Photos 相册，但谷歌不会承认这一点，也无法证明。” 对此，谷歌坚决否认了这一指控。在与《福布斯》分享的一份声明中，谷歌表示:“我们不使用您的个人数据来训练任何生成式 AI 模型，包括其他 Gemini 模型和产品。如果您选择与其他谷歌或第三方服务共享照片或视频，您的数据将根据那些服务的政策进行处理。” 尽管谷歌否认了 AI 训练的说法，但它也承认 Google Photos 并不是一个端到端加密的服务。谷歌使用自动系统和专业团队扫描存储在平台上的图像，以检测儿童色情内容，谷歌称这一做法是出于安全与合规的考虑。 此次争议突显了云服务面临的更大问题。AI 工具正日益融入日常平台，而这些平台通常由复杂的隐私政策所管理，许多用户从未阅读这些政策。当这样的指控出现时，即使没有证据，也会迅速动摇用户的信任。正如《福布斯》的 Zak Doffman 所言，用户应明白:除非使用端到端加密，否则云平台并不完全私密，存储在网上的照片可能以某种形式被分析，即使公司表示不会用于 AI 训练。 划重点: - 📸 谷歌 Nano Banana AI 工具引发隐私担忧，15亿用户照片可能被利用。 - 🔒 谷歌否认使用用户数据训练 AI，但承认 Google Photos 不具备端到端加密。 - ⚠️ 云服务隐私问题凸显，用户需警惕存储照片的安全性。","published_date":"2025-12-31T06:04:32.350Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>近日，谷歌的 Nano Banana AI 工具引发了新的隐私问题，关注点集中在全球15亿用户的照片分析与存储上。根据《福布斯》的一项报道，谷歌在其照片存储服务 Google Photos 中被指控可能在未经用户同意的情况下，利用这些照片为其强大的 AI 系统提供数据。这一指控并非来自监管机构或内部告发者，而是来自于专注隐私的科技公司 Proton，这家公司在云存储领域与谷歌直接竞争。</p><p>这一争议的时机引人注目，因为这一指控出现在谷歌的新 AI 图像工具 Nano Banana 受到广泛关注之后，后者因生成逼真图像而受到批评，许多人认为现实与虚构的界限正在迅速模糊。Proton 在社交媒体平台 X 上发布的帖子迅速传播，称 “谷歌 AI 之所以在生成图像方面表现优异，原因在于它们正在扫描每位安卓用户的 Google Photos 相册，但谷歌不会承认这一点，也无法证明。”</p><p>对此，谷歌坚决否认了这一指控。在与《福布斯》分享的一份声明中，谷歌表示:“我们不使用您的个人数据来训练任何生成式 AI 模型，包括其他 Gemini 模型和产品。如果您选择与其他谷歌或第三方服务共享照片或视频，您的数据将根据那些服务的政策进行处理。” 尽管谷歌否认了 AI 训练的说法，但它也承认 Google Photos 并不是一个端到端加密的服务。谷歌使用自动系统和专业团队扫描存储在平台上的图像，以检测儿童色情内容，谷歌称这一做法是出于安全与合规的考虑。</p><p>此次争议突显了云服务面临的更大问题。AI 工具正日益融入日常平台，而这些平台通常由复杂的隐私政策所管理，许多用户从未阅读这些政策。当这样的指控出现时，即使没有证据，也会迅速动摇用户的信任。正如《福布斯》的 Zak Doffman 所言，用户应明白:除非使用端到端加密，否则云平台并不完全私密，存储在网上的照片可能以某种形式被分析，即使公司表示不会用于 AI 训练。</p><blockquote><p>划重点:</p><p>- 📸 谷歌 Nano Banana AI 工具引发隐私担忧，15亿用户照片可能被利用。</p><p>- 🔒 谷歌否认使用用户数据训练 AI，但承认 Google Photos 不具备端到端加密。</p><p>- ⚠️ 云服务隐私问题凸显，用户需警惕存储照片的安全性。</p></blockquote>"}},{"id":"229075542105192452","type":"news","url":"https://www.aibase.com/zh/news/24160","title":"2026 年企业 AI 投资将集中减少供应商，投资者展望新趋势","description":"近年来，企业在人工智能（AI）工具的试点和测试中不断探索，以确定 最佳 的应用策略。如今，投资者们认为，这一实验阶段即将结束，预计到2026年，企业的 AI 预算将显著增加，但将更加集中于少数有效的供应商。 多位企业专注的风险投资者表示，2026年将是企业开始整合投资、选择优胜者的一年。Databricks Ventures 的副总裁安德鲁・弗格森（Andrew Ferguson）指出，目前企业在单一应用场景中测试多种工具，而随着 AI 技术的实际应用证明其价值，企业将削减实验预算，理顺重叠的工具，从而将节省下来的资金投入到那些真正有效的 AI 技术中。 与此观点一致，Asymmetric Capital Partners 的管理合伙人罗伯・比德曼（Rob Biederman）表示，企业不仅会集中各自的支出，整个企业 AI 市场也将趋向于仅有少数几家供应商获得预算。比德曼预言，能够显著提供成果的特定 AI 产品预算将增加，而其他不太有效的产品预算将大幅下降。 Norwest Venture Partners 的合伙人斯科特・比丘克（Scott Beechuk）补充道，企业将更多地投入到确保 AI 使用安全性的工具上。他指出，随着这些能力的成熟，企业在从试点项目转向大规模部署时将更加自信，预算也将随之增加。 此外，Snowflake Ventures 的董事哈沙・卡普雷（Harsha Kapre）认为，2026年企业的 AI 投资将集中在三个主要领域:强化数据基础、模型后训练优化和工具整合。他提到，首席投资官们正在积极减少软件即服务(SaaS)的分散，朝着统一和智能化系统转型，以降低整合成本并实现可测量的投资回报。 随着企业逐渐向集中化和高效化发展，这将对初创企业产生影响。市场上那些拥有难以复制产品或独特数据的公司仍有可能持续增长，而那些与大型企业供应商（如 AWS 或 Salesforce）提供相似产品的初创公司，可能会面临试点项目和融资减少的挑战。 划重点: 🌟 企业将在2026年显著增加 AI 预算，但会集中在少数有效供应商上。 💼 投资者预期，成功的 AI 产品将获得更高的资金支持，而其他产品预算将大幅减少。 🔍 企业将在 AI 投资中关注数据基础建设和安全性，以实现高效运营。","published_date":"2025-12-31T06:01:05.553Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p>近年来，企业在人工智能（AI）工具的试点和测试中不断探索，以确定<span>最佳</span>的应用策略。如今，投资者们认为，这一实验阶段即将结束，预计到2026年，企业的 AI 预算将显著增加，但将更加集中于少数有效的供应商。</p><p>多位企业专注的风险投资者表示，2026年将是企业开始整合投资、选择优胜者的一年。Databricks Ventures 的副总裁安德鲁・弗格森（Andrew Ferguson）指出，目前企业在单一应用场景中测试多种工具，而随着 AI 技术的实际应用证明其价值，企业将削减实验预算，理顺重叠的工具，从而将节省下来的资金投入到那些真正有效的 AI 技术中。</p><p>与此观点一致，Asymmetric Capital Partners 的管理合伙人罗伯・比德曼（Rob Biederman）表示，企业不仅会集中各自的支出，整个企业 AI 市场也将趋向于仅有少数几家供应商获得预算。比德曼预言，能够显著提供成果的特定 AI 产品预算将增加，而其他不太有效的产品预算将大幅下降。</p><p>Norwest Venture Partners 的合伙人斯科特・比丘克（Scott Beechuk）补充道，企业将更多地投入到确保 AI 使用安全性的工具上。他指出，随着这些能力的成熟，企业在从试点项目转向大规模部署时将更加自信，预算也将随之增加。</p><p>此外，Snowflake Ventures 的董事哈沙・卡普雷（Harsha Kapre）认为，2026年企业的 AI 投资将集中在三个主要领域:强化数据基础、模型后训练优化和工具整合。他提到，首席投资官们正在积极减少软件即服务(SaaS)的分散，朝着统一和智能化系统转型，以降低整合成本并实现可测量的投资回报。</p><p>随着企业逐渐向集中化和高效化发展，这将对初创企业产生影响。市场上那些拥有难以复制产品或独特数据的公司仍有可能持续增长，而那些与大型企业供应商（如 AWS 或 Salesforce）提供相似产品的初创公司，可能会面临试点项目和融资减少的挑战。</p><blockquote><p>划重点:</p><p>🌟 企业将在2026年显著增加 AI 预算，但会集中在少数有效供应商上。  </p><p>💼 投资者预期，成功的 AI 产品将获得更高的资金支持，而其他产品预算将大幅减少。  </p><p>🔍 企业将在 AI 投资中关注数据基础建设和安全性，以实现高效运营。</p></blockquote>"}},{"id":"229069957911259137","type":"news","url":"https://newshacker.me/story?id=46441068","title":"🙄 Google Opal：无代码 AI 小应用，绑定 Google Drive 引发权限与存活疑虑","description":"原标题： 《Google Opal》 评分: 38 | 作者: gmays 💭 把我 Drive 的数据拿去训练，你们安心吗？ 🎯 讨论背景 Google Opal 是 Google 推出的一个面向非工程师的“无代码”AI 小应用构建器，几个月前已有 Hacker News 的早期讨论。帖子评论集中在两大问题：一是 Opal 要求访问用户的 Google Drive 并把输出保存为 Drive 文件，这触发了对权限范围、数据是否会被用于训练以及缺乏更细粒度隔离的担忧；二是 Google 将支持与早期邀请流量引导到 Discord（一个第三方聊天/社区平台），延续了 Bard（Google 的早期聊天式大模型）、Gemini（Google 的大模型品牌）和 NotebookLM（Google 的笔记/研究型 LLM 产品）等产品的做法。评论情绪以怀疑与讽刺为主，用户对供应商锁定和产品被中止的历史格外敏感。 📌 讨论焦点 产品寿命与被砍忧虑 不少评论对 Google 新服务的长期可用性持怀疑态度，把新发布的产品视为可能被砍掉的项目。有人用“platform roulette”来形容在 Google 平台上长期投入的风险，认为成功率接近零。这种悲观情绪来自过去 Google 频繁中止或重组产品线的历史，使用户在投入时间或数据时格外谨慎。 [来源1] [来源2] [来源3] 隐私与 Google Drive 权限担忧 多个评论者在体验 Opal 时中止操作，原因是它要求访问整个 Google Drive，且权限范围可能很广（读/写或元数据）。有人解释 Opal 把 Drive 当作后端、将输出保存为 Drive 文件以便持久化和在 Docs 中打开，这让用户担心是否无意中授予应用访问全部个人文件的权限。还有人担心这类权限可能允许把 Drive 数据纳入训练集或触发新的隐私条款，尽管也有评论指出 Drive 本身已由 Google 托管，但真正的问题是权限粒度和数据使用政策的不确定性。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] Google 使用 Discord 作为支持与邀请渠道的意外 多名评论对 Google 把官方支持与反馈引导到 Discord 感到意外，并列举了历史先例。Bard（Google 的早期聊天模型）、Gemini（Google 的大模型品牌）和 NotebookLM（Google 的笔记/研究型 LLM 产品）在早期测试阶段都曾使用 invite-only 的 Discord 社区分发邀请或收集反馈。有人提到某些邀请甚至要求把 Discord 帐号与 Google 绑定才能入群，表明 Google 在早期社区运营上倚重第三方平台而非自家 Chat 服务。 [来源1] [来源2] [来源3] [来源4] [来源5] 产品定位与锁定风险（无代码/后端依赖） Opal 被描述为“AI mini app”或无代码构建器，但评论者质疑它能否产出生产级应用还是仅限演示或小工具。无代码性质让用户担心一旦使用就会被平台锁定，Google 可能掌控托管、定价与未来访问权限，存在“被劫持”的风险。另有评论指出 Opal 将输出保存在 Google Drive，这既方便共享又带来依赖性；少数人认为这类产品可能对像 Vercel（前端部署平台）之类服务构成竞争，但大多数关注点仍是数据可导出性与供应商锁定。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 Opal（Google Opal）: Google 的新产品，定位为无代码/低代码的 AI “mini app” 构建器；评论中指出其将用户输出保存到 Google Drive，并因此需申请 Drive 权限。 Google Drive（Google 的云端存储服务）: 在本讨论中被 Opal 当作后端存储，应用可能申请较宽的权限范围（读取、写入或元数据访问），输出以 Drive 文件形式持久化并可在 Google Docs 中打开。 NotebookLM（Google 的笔记/研究型 LLM 产品）: Google 的面向笔记整理与知识管理的产品，曾在早期采用 invite-only 的 Discord 社区作为测试与支持通道，评论将其作为 Google 社区做法的例子。 Discord（一个聊天/社区平台）: 第三方社区与即时通讯平台；评论指出 Google 将 Discord 用作 Opal 及其他大模型产品的早期支持、反馈和邀请渠道，有时要求将 Discord 帐号与 Google 账户关联。 类别： AI | Security | Product | Release | Opal | Google | Google Drive | Drive permissions | privacy | training data | Discord | NotebookLM","published_date":"2025-12-31T05:50:47.529Z","authors":"","source":"News Hacker | 极客洞察","details":{"content_html":"<p><strong>原标题：</strong>《Google Opal》</p><p><strong>评分:</strong> 38 | <strong>作者:</strong> gmays</p><blockquote>💭 把我 Drive 的数据拿去训练，你们安心吗？</blockquote><hr><h2>🎯 讨论背景</h2><p>Google Opal 是 Google 推出的一个面向非工程师的“无代码”AI 小应用构建器，几个月前已有 Hacker News 的早期讨论。帖子评论集中在两大问题：一是 Opal 要求访问用户的 Google Drive 并把输出保存为 Drive 文件，这触发了对权限范围、数据是否会被用于训练以及缺乏更细粒度隔离的担忧；二是 Google 将支持与早期邀请流量引导到 Discord（一个第三方聊天/社区平台），延续了 Bard（Google 的早期聊天式大模型）、Gemini（Google 的大模型品牌）和 NotebookLM（Google 的笔记/研究型 LLM 产品）等产品的做法。评论情绪以怀疑与讽刺为主，用户对供应商锁定和产品被中止的历史格外敏感。</p><hr><h2>📌 讨论焦点</h2><h3>产品寿命与被砍忧虑</h3><p>不少评论对 Google 新服务的长期可用性持怀疑态度，把新发布的产品视为可能被砍掉的项目。有人用“platform roulette”来形容在 Google 平台上长期投入的风险，认为成功率接近零。这种悲观情绪来自过去 Google 频繁中止或重组产品线的历史，使用户在投入时间或数据时格外谨慎。</p><p><a href=\"https://news.ycombinator.com/item?id=46441534\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441663\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441539\" target=\"_blank\">[来源3]</a></p><h3>隐私与 Google Drive 权限担忧</h3><p>多个评论者在体验 Opal 时中止操作，原因是它要求访问整个 Google Drive，且权限范围可能很广（读/写或元数据）。有人解释 Opal 把 Drive 当作后端、将输出保存为 Drive 文件以便持久化和在 Docs 中打开，这让用户担心是否无意中授予应用访问全部个人文件的权限。还有人担心这类权限可能允许把 Drive 数据纳入训练集或触发新的隐私条款，尽管也有评论指出 Drive 本身已由 Google 托管，但真正的问题是权限粒度和数据使用政策的不确定性。</p><p><a href=\"https://news.ycombinator.com/item?id=46441493\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441655\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441678\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441696\" target=\"_blank\">[来源4]</a> <a href=\"https://news.ycombinator.com/item?id=46441514\" target=\"_blank\">[来源5]</a> <a href=\"https://news.ycombinator.com/item?id=46441648\" target=\"_blank\">[来源6]</a></p><h3>Google 使用 Discord 作为支持与邀请渠道的意外</h3><p>多名评论对 Google 把官方支持与反馈引导到 Discord 感到意外，并列举了历史先例。Bard（Google 的早期聊天模型）、Gemini（Google 的大模型品牌）和 NotebookLM（Google 的笔记/研究型 LLM 产品）在早期测试阶段都曾使用 invite-only 的 Discord 社区分发邀请或收集反馈。有人提到某些邀请甚至要求把 Discord 帐号与 Google 绑定才能入群，表明 Google 在早期社区运营上倚重第三方平台而非自家 Chat 服务。</p><p><a href=\"https://news.ycombinator.com/item?id=46441633\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441653\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441689\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441645\" target=\"_blank\">[来源4]</a> <a href=\"https://news.ycombinator.com/item?id=46441672\" target=\"_blank\">[来源5]</a></p><h3>产品定位与锁定风险（无代码/后端依赖）</h3><p>Opal 被描述为“AI mini app”或无代码构建器，但评论者质疑它能否产出生产级应用还是仅限演示或小工具。无代码性质让用户担心一旦使用就会被平台锁定，Google 可能掌控托管、定价与未来访问权限，存在“被劫持”的风险。另有评论指出 Opal 将输出保存在 Google Drive，这既方便共享又带来依赖性；少数人认为这类产品可能对像 Vercel（前端部署平台）之类服务构成竞争，但大多数关注点仍是数据可导出性与供应商锁定。</p><p><a href=\"https://news.ycombinator.com/item?id=46441572\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441513\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441655\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441310\" target=\"_blank\">[来源4]</a></p><hr><h2>📚 术语解释</h2><p><strong>Opal（Google Opal）:</strong> Google 的新产品，定位为无代码/低代码的 AI “mini app” 构建器；评论中指出其将用户输出保存到 Google Drive，并因此需申请 Drive 权限。</p><p><strong>Google Drive（Google 的云端存储服务）:</strong> 在本讨论中被 Opal 当作后端存储，应用可能申请较宽的权限范围（读取、写入或元数据访问），输出以 Drive 文件形式持久化并可在 Google Docs 中打开。</p><p><strong>NotebookLM（Google 的笔记/研究型 LLM 产品）:</strong> Google 的面向笔记整理与知识管理的产品，曾在早期采用 invite-only 的 Discord 社区作为测试与支持通道，评论将其作为 Google 社区做法的例子。</p><p><strong>Discord（一个聊天/社区平台）:</strong> 第三方社区与即时通讯平台；评论指出 Google 将 Discord 用作 Opal 及其他大模型产品的早期支持、反馈和邀请渠道，有时要求将 Discord 帐号与 Google 账户关联。</p><hr><p><strong>类别：</strong>AI | Security | Product | Release | Opal | Google | Google Drive | Drive permissions | privacy | training data | Discord | NotebookLM</p>"}},{"id":"229075542105192453","type":"news","url":"https://www.aibase.com/zh/news/24159","title":"京东正式上线自营租赁业务，百万级人形机器人触手可及","description":"12月31日，京东与宇树科技（Unitree）合作的全球首家线下门店在京东MALL(北京双井店)隆重开业。这不仅标志着 顶尖 具身智能产品正式由线上走向全渠道零售，更见证了机器人走进大众生活的关键一步。 [图片: 机器人 AI 人工智能 (1) https://pic.chinaz.com/picmap/202304201630359794_4.jpg] “只租不卖”新模式:降低体验门槛 在开业活动现场，京东机器人业务具身智能负责人透露，京东已正式推出自营机器人租赁服务。用户现在可以以更低廉的价格、更灵活的周期（如日租或长租）体验包括四足机器狗、人形机器人在内的前沿技术。此举旨在解决人形机器人单价高、大众上手难的痛点，让具身智能技术真正服务于普通消费者。 场景化体验:机器人进入千家万户 作为京东的线下 超级 体验中心，京东MALL已在全国开设27家门店，单店面积达3万至8万平方米。据负责人介绍，京东正持续布局线下应用场景，消费者可以在店内的真实环境下，沉浸式体验机器人在家居辅助、教育陪护、康养护理、文化娱乐等多元场景下的实际应用。 强强联手:加速商业化落地 作为国内机器人领域的“独角兽”，宇树科技的G1人形机器人及Go2机器狗等明星产品均在首店亮相。依托京东强大的物流保障、售后保障及金融租赁体系，双方的合作将加速具身智能产品在C端市场的渗透，推动行业从“实验室研发”向“家庭应用”的商业化拐点迈进。","published_date":"2025-12-31T05:45:53.500Z","authors":"AI Base","source":"AI新闻资讯 - AI Base","details":{"content_html":"<p><span style=\"text-indent: 2em;\">12月31日，京东与宇树科技（Unitree）合作的全球首家线下门店在京东MALL(北京双井店)隆重开业。这不仅标志着<span>顶尖</span>具身智能产品正式由线上走向全渠道零售，更见证了机器人走进大众生活的关键一步。</span></p><p><span style=\"text-indent: 2em;\"></span></p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202304201630359794_4.jpg\" title=\"机器人 AI 人工智能 (1) (图片来源：AI合成)\" alt=\"机器人 AI 人工智能 (1)\"></p><p><span style=\"text-indent: 2em;\"></span><br></p><p><strong>“只租不卖”新模式:降低体验门槛</strong></p><p>在开业活动现场，京东机器人业务具身智能负责人透露，京东已正式推出自营机器人租赁服务。用户现在可以以更低廉的价格、更灵活的周期（如日租或长租）体验包括四足机器狗、人形机器人在内的前沿技术。此举旨在解决人形机器人单价高、大众上手难的痛点，让具身智能技术真正服务于普通消费者。</p><p><strong>场景化体验:机器人进入千家万户</strong></p><p>作为京东的线下<span>超级</span>体验中心，京东MALL已在全国开设27家门店，单店面积达3万至8万平方米。据负责人介绍，京东正持续布局线下应用场景，消费者可以在店内的真实环境下，沉浸式体验机器人在家居辅助、教育陪护、康养护理、文化娱乐等多元场景下的实际应用。</p><p><strong>强强联手:加速商业化落地</strong></p><p>作为国内机器人领域的“独角兽”，宇树科技的G1人形机器人及Go2机器狗等明星产品均在首店亮相。依托京东强大的物流保障、售后保障及金融租赁体系，双方的合作将加速具身智能产品在C端市场的渗透，推动行业从“实验室研发”向“家庭应用”的商业化拐点迈进。</p>"}},{"id":"229069957911259141","type":"news","url":"https://newshacker.me/story?id=46440833","title":"🤦 LLVM 政策：不接受非程序员靠 AI 提交代码，提交者必须负责","description":"原标题： 《We don't need more contributors who aren't programmers to contribute code》 评分: 94 | 作者: pertymcpert 💭 把代码责任全部推给 LLM，是想躺着晋升吗？ 🎯 讨论背景 讨论源于 LLVM（一个主流开源编译器基础设施）针对 AI 工具与贡献者行为的政策，核心在于限制不会编程的人依赖 LLM/代码助手直接提交代码以及禁止无人复核的自动审查评论。评论基于维护者长期遭遇的现实：AI 快速降低了生成代码的门槛但 reviewer 数量与质量控制机制未同步扩张，导致大量低质量 PR 与沟通负担。争论集中在如何在保留 AI 辅助价值的同时，确保人类最终把关、保护项目质量，以及如何用更友好的驳回措辞与必要的培训来减少摩擦。理解这些讨论需要知道 LLM、Cursor 等代码助理的工作方式及开源项目对可维护性与审核成本的敏感性。 📌 讨论焦点 责任与归属：提交者必须对代码负责 评论普遍支持一条基线原则：提交者必须为自己提交的代码负责，不能把责任推给 AI 或以“AI 做的”为借口。多条评论提到有人在 PR 中写“Cursor wrote that”或“an LLM did it”，但一旦改动出现在你的 pull request，责任就在你，且会计入绩效评估。几个工作场景的例子说明公司通常既不强制使用也不禁止 AI，但会明确要求人能够解释和验证 AI 的产出。评论认为将 AI 视为工具而非作者，是维护代码质量和团队文化的最低标准。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] [来源8] [来源9] 维护负担与“slop”激增 许多评论指出 AI 使得会写代码的人数突然暴增，但 reviewer 数量并未增加甚至因裁员减少，导致大量低质量提交（评论中称为“slop”）涌入。有人专门提到这对 LLVM 这样核心开源项目尤其危险，维护者需要花更多时间在审查、修复和驳回不理解的变更上，从而提高总体维护成本。也有实例描述原开发者用 AI 提交了严重有缺陷的改动并拒绝改正，表明问题不仅是数量，还有质量与态度。基于这些观察，评论里有人支持通过政策限制无理解的 AI 产出以保护项目稳定性。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 自动化审查代理与人类在环（human‑in‑the‑loop）争论 政策里禁止“自动化审查工具在无人复核时自动发表评论”引发了争议：一方认为像 Gemini、Cursor 的审查代理能发现真实问题并带来价值，另一方担心自动评论会削弱人类审查时的知识传递与讨论。支持禁止自动化直接发表意见的观点强调 LLM 本质上是一个 plausibility engine，不能做为流程最后判定，且应让人类主导审查以促进交流与教学。评论建议的折中是把 AI 作为辅助工具而非替代，让人类发起并最终负责审查流程，因此有人把这条政策概括为“human in the loop”。 [来源1] [来源2] [来源3] [来源4] 对驳回模板语气与对外沟通的批评 尽管支持控制 AI 产出的思路，但有评论抨击政策中用于驳回外部贡献者的默认回复文本过于行话化并带有贬低意味。建议在第一层级使用更通俗、礼貌且可操作的回复，明确告诉贡献者下一步如何改进，而将更强硬或带有专业术语的措辞留到升级处理时。评论认为更友好的首轮沟通能减少误解、降低重复往返并改善社区互动，从而间接减轻维护者负担。维护者应平衡质量控制与对外界的可接纳性，避免不必要的社区阻隔。 [来源1] [来源2] 能力差距与培训：AI 放大 Dunning‑Kruger 效应 部分评论指出 AI 会放大 Dunning‑Kruger 效应，使非程序员或技术功底薄弱的人在缺乏基本理解的情况下自信地提交代码，从而增加故障风险。有人认为传统面向技术人员的培训无法直接覆盖这批借助 AI 的“新贡献者”，因此要么设计专门培训路径，要么对其贡献施加更严格的门槛。评论还提醒并非只有非程序员会犯错，程序员在过度依赖 LLM 时也会出现“无思考”的错误，这就要求团队在流程中加强验证与教学，而非单靠工具输出。 [来源1] [来源2] [来源3] 📚 术语解释 LLVM: LLVM（一个开源的编译器与工具链基础设施项目），广泛用于编译器、静态分析和语言工具，是本次政策针对的核心开源项目背景。 LLM: LLM（Large Language Model，大型语言模型），基于大规模语料生成自然语言或代码的模型，评论中讨论其作为代码生成/审查来源的局限性。 Cursor: Cursor（一个面向开发者的 AI 代码助手/编辑器插件），评论中被举例为生成代码并被人以此为借口的实际工具。 自动化审查代理（automated review tools）: 自动化审查代理：在 PR 上自动发表评论或建议的 AI 系统，能发现问题但可能在无人类监督下阻断知识传播或作出误导性判断。 人类在环（human‑in‑the‑loop）: 人类在环（human‑in‑the‑loop）：一种流程设计原则，要求人工介入最终决策或审查，AI 仅作为辅助工具，不能单独做最后判定。 类别： AI | Programming | Policy | Spec | LLVM | AI | human-in-the-loop | policy | RFC | LLM | Cursor","published_date":"2025-12-31T05:21:55.249Z","authors":"","source":"News Hacker | 极客洞察","details":{"content_html":"<p><strong>原标题：</strong>《We don't need more contributors who aren't programmers to contribute code》</p><p><strong>评分:</strong> 94 | <strong>作者:</strong> pertymcpert</p><blockquote>💭 把代码责任全部推给 LLM，是想躺着晋升吗？</blockquote><hr><h2>🎯 讨论背景</h2><p>讨论源于 LLVM（一个主流开源编译器基础设施）针对 AI 工具与贡献者行为的政策，核心在于限制不会编程的人依赖 LLM/代码助手直接提交代码以及禁止无人复核的自动审查评论。评论基于维护者长期遭遇的现实：AI 快速降低了生成代码的门槛但 reviewer 数量与质量控制机制未同步扩张，导致大量低质量 PR 与沟通负担。争论集中在如何在保留 AI 辅助价值的同时，确保人类最终把关、保护项目质量，以及如何用更友好的驳回措辞与必要的培训来减少摩擦。理解这些讨论需要知道 LLM、Cursor 等代码助理的工作方式及开源项目对可维护性与审核成本的敏感性。</p><hr><h2>📌 讨论焦点</h2><h3>责任与归属：提交者必须对代码负责</h3><p>评论普遍支持一条基线原则：提交者必须为自己提交的代码负责，不能把责任推给 AI 或以“AI 做的”为借口。多条评论提到有人在 PR 中写“Cursor wrote that”或“an LLM did it”，但一旦改动出现在你的 pull request，责任就在你，且会计入绩效评估。几个工作场景的例子说明公司通常既不强制使用也不禁止 AI，但会明确要求人能够解释和验证 AI 的产出。评论认为将 AI 视为工具而非作者，是维护代码质量和团队文化的最低标准。</p><p><a href=\"https://news.ycombinator.com/item?id=46441461\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441518\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441538\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441356\" target=\"_blank\">[来源4]</a> <a href=\"https://news.ycombinator.com/item?id=46441463\" target=\"_blank\">[来源5]</a> <a href=\"https://news.ycombinator.com/item?id=46441504\" target=\"_blank\">[来源6]</a> <a href=\"https://news.ycombinator.com/item?id=46441420\" target=\"_blank\">[来源7]</a> <a href=\"https://news.ycombinator.com/item?id=46441416\" target=\"_blank\">[来源8]</a> <a href=\"https://news.ycombinator.com/item?id=46441540\" target=\"_blank\">[来源9]</a></p><h3>维护负担与“slop”激增</h3><p>许多评论指出 AI 使得会写代码的人数突然暴增，但 reviewer 数量并未增加甚至因裁员减少，导致大量低质量提交（评论中称为“slop”）涌入。有人专门提到这对 LLVM 这样核心开源项目尤其危险，维护者需要花更多时间在审查、修复和驳回不理解的变更上，从而提高总体维护成本。也有实例描述原开发者用 AI 提交了严重有缺陷的改动并拒绝改正，表明问题不仅是数量，还有质量与态度。基于这些观察，评论里有人支持通过政策限制无理解的 AI 产出以保护项目稳定性。</p><p><a href=\"https://news.ycombinator.com/item?id=46440994\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441075\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441460\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441466\" target=\"_blank\">[来源4]</a> <a href=\"https://news.ycombinator.com/item?id=46441502\" target=\"_blank\">[来源5]</a> <a href=\"https://news.ycombinator.com/item?id=46441409\" target=\"_blank\">[来源6]</a></p><h3>自动化审查代理与人类在环（human‑in‑the‑loop）争论</h3><p>政策里禁止“自动化审查工具在无人复核时自动发表评论”引发了争议：一方认为像 Gemini、Cursor 的审查代理能发现真实问题并带来价值，另一方担心自动评论会削弱人类审查时的知识传递与讨论。支持禁止自动化直接发表意见的观点强调 LLM 本质上是一个 plausibility engine，不能做为流程最后判定，且应让人类主导审查以促进交流与教学。评论建议的折中是把 AI 作为辅助工具而非替代，让人类发起并最终负责审查流程，因此有人把这条政策概括为“human in the loop”。</p><p><a href=\"https://news.ycombinator.com/item?id=46441412\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441546\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441494\" target=\"_blank\">[来源3]</a> <a href=\"https://news.ycombinator.com/item?id=46441531\" target=\"_blank\">[来源4]</a></p><h3>对驳回模板语气与对外沟通的批评</h3><p>尽管支持控制 AI 产出的思路，但有评论抨击政策中用于驳回外部贡献者的默认回复文本过于行话化并带有贬低意味。建议在第一层级使用更通俗、礼貌且可操作的回复，明确告诉贡献者下一步如何改进，而将更强硬或带有专业术语的措辞留到升级处理时。评论认为更友好的首轮沟通能减少误解、降低重复往返并改善社区互动，从而间接减轻维护者负担。维护者应平衡质量控制与对外界的可接纳性，避免不必要的社区阻隔。</p><p><a href=\"https://news.ycombinator.com/item?id=46441466\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441409\" target=\"_blank\">[来源2]</a></p><h3>能力差距与培训：AI 放大 Dunning‑Kruger 效应</h3><p>部分评论指出 AI 会放大 Dunning‑Kruger 效应，使非程序员或技术功底薄弱的人在缺乏基本理解的情况下自信地提交代码，从而增加故障风险。有人认为传统面向技术人员的培训无法直接覆盖这批借助 AI 的“新贡献者”，因此要么设计专门培训路径，要么对其贡献施加更严格的门槛。评论还提醒并非只有非程序员会犯错，程序员在过度依赖 LLM 时也会出现“无思考”的错误，这就要求团队在流程中加强验证与教学，而非单靠工具输出。</p><p><a href=\"https://news.ycombinator.com/item?id=46441502\" target=\"_blank\">[来源1]</a> <a href=\"https://news.ycombinator.com/item?id=46441500\" target=\"_blank\">[来源2]</a> <a href=\"https://news.ycombinator.com/item?id=46441540\" target=\"_blank\">[来源3]</a></p><hr><h2>📚 术语解释</h2><p><strong>LLVM:</strong> LLVM（一个开源的编译器与工具链基础设施项目），广泛用于编译器、静态分析和语言工具，是本次政策针对的核心开源项目背景。</p><p><strong>LLM:</strong> LLM（Large Language Model，大型语言模型），基于大规模语料生成自然语言或代码的模型，评论中讨论其作为代码生成/审查来源的局限性。</p><p><strong>Cursor:</strong> Cursor（一个面向开发者的 AI 代码助手/编辑器插件），评论中被举例为生成代码并被人以此为借口的实际工具。</p><p><strong>自动化审查代理（automated review tools）:</strong> 自动化审查代理：在 PR 上自动发表评论或建议的 AI 系统，能发现问题但可能在无人类监督下阻断知识传播或作出误导性判断。</p><p><strong>人类在环（human‑in‑the‑loop）:</strong> 人类在环（human‑in‑the‑loop）：一种流程设计原则，要求人工介入最终决策或审查，AI 仅作为辅助工具，不能单独做最后判定。</p><hr><p><strong>类别：</strong>AI | Programming | Policy | Spec | LLVM | AI | human-in-the-loop | policy | RFC | LLM | Cursor</p>"}},{"id":"229067870511015936","type":"news","url":"https://www.jiqizhixin.com/articles/2025-12-31-5","title":"视远 · 正心明智——「AI 中国」机器之心2025年度评选正式揭晓","description":"[图片: 图片 https://image.jiqizhixin.com/uploads/editor/372907fd-2b19-4d58-842e-65673e69045d/640.png] 2025 年的日历已经翻到最后一页。 这一年里，大模型的演进速度被不断推高：新的模型架构、训练范式与推理策略轮番登场，技术边界一次次被向前推移。 放眼海外，GPT-5、Gemini 3 等新一代模型相继亮相，在理解、生成与推理等核心能力上持续抬升上限，通用智能的轮廓愈发清晰。 回到国内，2025 年的 AI 场面同样热闹。国产大模型一边在核心能力上不断拉近与国际头部模型的差距，甚至在个别方向上实现反超，另一边也在开源、工程化和应用适配上明显提速。 然而，在技术浪潮起伏中，我们更需要清醒识别真正具备长远价值的 AI 力量。因为决定行业走向的，从来不是某一次参数翻倍、某一项榜单刷新，而是哪些能力能够在真实世界中持续发挥作用 —— 它们是否真正重塑了生产方式，并在时间的检验中沉淀为基础能力。 正是基于这样的判断与追问，我们尝试把目光从短期热度中抽离，去辨认那些真正值得被记录的技术进展与创新路径。 带着这些思考与期待，机器之心精心策划了 2025 年度榜单，记录中国人工智能奋进的这一年，勾勒技术创新的璀璨未来。 今日，「AI 中国」机器之心 2025 年度评选正式揭晓： 最强技术实力企业/机构 TOP 10 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/f0f76124-6dca-4227-80bc-9c5c7fb636b9/640.png] 人工智能领军企业 TOP 20 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/99207199-8921-491d-857e-a4b4aab8e143/640.png] 最佳大模型 TOP 20 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/dae6faf7-5bae-469a-bfd9-26abf9c23c02/640.png] 最佳大模型产品 TOP 20 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/9a0df25c-1f70-4cf7-b82d-a128721702dd/640.png] 具身智能领军企业 TOP 20 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/2e90595e-dd2d-4428-b14e-73ae6504dba3/640.png] ScienceAI 领军企业/机构 TOP 10 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/9c019211-7f58-4fdd-8abe-be7a41bba7ac/640.png] ]]>","published_date":"2025-12-31T05:19:44.813Z","authors":"机器之心","source":"机器之心 - 机器之心","details":{"content_html":"<img src=\"https://image.jiqizhixin.com/uploads/editor/372907fd-2b19-4d58-842e-65673e69045d/640.png\" alt=\"图片\" style=\"width: 700%;\"><p>2025 年的日历已经翻到最后一页。</p><p>这一年里，大模型的演进速度被不断推高：新的模型架构、训练范式与推理策略轮番登场，技术边界一次次被向前推移。</p><p>放眼海外，GPT-5、Gemini 3 等新一代模型相继亮相，在理解、生成与推理等核心能力上持续抬升上限，通用智能的轮廓愈发清晰。</p><p>回到国内，2025 年的 AI 场面同样热闹。国产大模型一边在核心能力上不断拉近与国际头部模型的差距，甚至在个别方向上实现反超，另一边也在开源、工程化和应用适配上明显提速。</p><p>然而，在技术浪潮起伏中，我们更需要清醒识别真正具备长远价值的 AI 力量。因为决定行业走向的，从来不是某一次参数翻倍、某一项榜单刷新，而是哪些能力能够在真实世界中持续发挥作用 —— 它们是否真正重塑了生产方式，并在时间的检验中沉淀为基础能力。</p><p>正是基于这样的判断与追问，我们尝试把目光从短期热度中抽离，去辨认那些真正值得被记录的技术进展与创新路径。</p><p>带着这些思考与期待，机器之心精心策划了 2025 年度榜单，记录中国人工智能奋进的这一年，勾勒技术创新的璀璨未来。</p><p>今日，「AI 中国」机器之心 2025 年度评选正式揭晓：</p><p><span><strong>最强技术实力企业/机构 TOP 10</strong></span></p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/f0f76124-6dca-4227-80bc-9c5c7fb636b9/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p><span><strong>人工智能领军企业 TOP 20</strong></span></p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/99207199-8921-491d-857e-a4b4aab8e143/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p><span><strong>最佳大模型 TOP 20</strong></span></p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/dae6faf7-5bae-469a-bfd9-26abf9c23c02/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p><span><strong>最佳大模型产品 TOP 20</strong></span></p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/9a0df25c-1f70-4cf7-b82d-a128721702dd/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p><span><strong>具身智能领军企业 TOP 20</strong></span></p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/2e90595e-dd2d-4428-b14e-73ae6504dba3/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><section><span><strong>ScienceAI 领军企业/机构 TOP 10</strong></span></section><section><img src=\"https://image.jiqizhixin.com/uploads/editor/9c019211-7f58-4fdd-8abe-be7a41bba7ac/640.png\" alt=\"图片\" style=\"width: 50%;\"></section>]]>"}},{"id":"229067870511015937","type":"news","url":"https://www.jiqizhixin.com/articles/2025-12-31-4","title":"NUS尤洋教授深度探讨智能增长的瓶颈：或许我们将这样实现AGI？","description":"2026 年即将到来，AI 的发展也已经进入了一个新的阶段：我们已经取得了惊人成就，却同时面临进一步增长的瓶颈。 新加坡国立大学（NUS）的尤洋教授近期发表了一篇深度分析：《 智能增长的瓶颈 》。 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/f6bd305d-ff9e-4e9a-81e0-3e72b54679ca/640.png] 原文链接：https://zhuanlan.zhihu.com/p/1989100535295538013 在这篇分析文章中，尤洋教授从技术本质出发，直指智能增长的核心矛盾，为我们揭示了 AGI（通用人工智能）的可能路径。 观点速览 ✅ 智能增长的本质不是架构变革，而是算力如何转化为智能 ：AI 的核心智能来自于预训练及其 Loss 结构（例如 GPT 的 Next-Token Prediction）。这些机制更像是把算力转化为智能的方法，而非智能本身。 ✅ 现有智能增长遇到瓶颈的根源 ：当前范式（Transformer + 超大算力）在面对进一步增长时， 难以充分消化不断增长的算力资源，这导致了所谓 “预训练红利递减”。 ✅ 算力并不是无限扩展就能解决问题 ：即使算力指数级增长，如果现有算法无法有效利用这些计算资源，智能提升仍将受限。 ✅ 未来方向不在于工程优化，而是底层范式突破 ：文章探讨了更高精度计算、更高阶优化器、更灵活的 Loss 设计、超大规模训练策略等潜在突破点。 ✅ AI 未来仍然乐观 ：智能增长瓶颈虽强，但仍有可能通过更好的算力利用方式被克服。预训练可能才刚刚开始，大模型智能仍有巨大的发展空间。 AGI 的未来将如何发展？让我们拭目以待。 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/c8963d7f-778f-42e2-90d6-ef48a9999f72/640.png] 尤洋教授，《智能增长的瓶颈》作者 以下为其分享原文： 智能增长的瓶颈 2026 年已至。在 ChatGPT 诞生三年多后的今天，关于我们的智能水平是否令人满意，以及未来是否还能强劲增长，笔者想分享一些个人的看法。如有谬误，恳请大家指正。 为了能深入探讨智能的本质，本文将不涉及产品易用性、成本等商业化或落地问题，因为这些本质上与智能突破本身无关。 1. 智能的现状 什么是智能？其实目前并没有一个明确的定义。 从最近图灵奖得主 Yann LeCun 和诺贝尔奖得主 Demis Hassabis 关于 AGI 的争论中，我感受到即便是世界上最顶尖的 专家 也无法准确定义智能。 个人感觉，AGI 很难定义，其标准也会随着时代的变化而变化。我依然记得十几年前，普通人对人脸识别技术感到不可思议。如果把今天的 ChatGPT 拿到 2006 年，相信那时候的很多人会毫不怀疑地认为我们已经实现了 AGI。 我觉得智能的核心是 预测 和 创作 。 我认为如果达到以下这种状态，那么就离 AGI 不远了： 如果你选择接受哪个工作 Offer，完全听从 AI 的意见。 如果你买足球彩票预测世界杯冠军，完全听从 AI 的意见。 如果你有健康问题，会完全采用 AI 制定的方案去治疗。 你分辨不清楚一部奥斯卡最佳电影是否是由 AI 生成的。 石油公司的勘探团队用 AI 替代了所有数值算法。 AI 能指导初级高铁工程师在 5 分钟内排除高铁的疑难故障。 AI 能研制出一款专杀癌细胞且不破坏好细胞的药物。 AI 能通过某区域的地下结构数据，精准预测地震的时间。 等等…… 今天，我们显然还没实现这些。未来能否实现，取决于我们能否克服智能发展的瓶颈。 2. 智能发展的瓶颈 今天，我们经常听到一些关于智能发展遇到瓶颈，或者预训练红利已尽的观点。何为瓶颈？我们先探讨一下智能从何而来。 过去 10 年，AI 大模型的技术本质，是把电力能源通过计算过程转化为可复用的智能。技术的好坏取决于这个转化效率的高低。类似的表述，我也听月之暗面的朋友提及过。 今天模型的智能本身，最主要还是来自预训练（往往是自监督方法），仅有少量来自微调或强化学习。 为什么？先算一笔浅显的经济账：因为预训练消耗的算力最多，消耗的能源也最多。 当然，预训练、微调、强化学习本质上都是在计算梯度以更新参数。如果有合适的海量数据和 Loss 函数，未来在预训练阶段采用 SFT（监督微调）或特殊的强化学习方法也有可能。 从智能增长的角度，我们甚至不用刻意区分预训练、SFT 和强化学习。它们的区别主要在于更新参数的次数与规模。 从计算本质上看：预训练、微调、强化学习（比如 GRPO）都是在计算梯度的类似物，并用它来更新参数。 那么，能源从何而来呢？这就是 GPU 或算力。英伟达在这点上做了最大的贡献。虽然英伟达有很多先进的技术，比如更强的 Tensor Cores、Transformer Engine、互联技术（NVLink / 网络化 NVLink）、软件栈等，但我先试图用一句话说清楚英伟达过去几年在技术上做的最重要的事情，即其 GPU 设计的核心思路。 简而言之，英伟达过去几年最重要的路线是： 在同样的物理空间里堆更多 HBM（高带宽内存）。 HBM 虽然带宽很高，但依然是计算核心之外的内存（Off-chip from logic die），与计算核心存在不可忽略的物理距离。为了掩盖内存访问延迟，GPU 只能依赖超大的 Batch Size（批处理量）和大规模并行来处理数据。英伟达 GPU 本质上就是一台并行计算机。 因此，英伟达对算法层和软件层的要求非常明确：必须提供足够大的 Batch Size 或并行度。 面对英伟达的要求，很多研究团队都提出了自己的方案。比如 RNN、Transformer、卷积序列模型（CNN for Sequence）等等。甚至有人尝试用 SVM 来处理大规模序列数据。 那为什么 Transformer 率先脱颖而出？因为 Transformer 也是一台并行计算机。 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/24e3ce8a-5297-4d2a-83ba-a7d43f9cb147/640.png] 原初的 Transformer 架构 这里我引用一下 Ilya Sutskever 的一句话：“Transformers: parallel computers in disguise”，直白的意思是：Transformer 本质上是一个被神经网络外壳包裹起来的并行计算机。这也是 Transformer 最先能够显现智能的核心原因，因为 它的并行计算特性完美匹配了 GPU 的并行计算单元 。 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/54926c94-fc79-4fc8-bb77-1679e570b877/640.png] 同时，OpenAI 完美地实现了 Next-Token Prediction 这个 Loss 函数，它给了 AI 大模型近乎无限的训练数据。理论上 BERT 的 Loss 函数（完形填空和 Next Sentence Prediction）也可以提供近乎无限的数据，但在实践中，Next-Token Prediction 的效果明显更好。 我推测，这个 Loss 函数最小化了人类的干预 —— 它不是人为设计的，而是大自然在进化过程中赋予人脑的逻辑。并且，Next-Token Prediction 其实是 预测未来 ，而 BERT 的完形填空其实是把过去的信息和现在的信息串联起来。这就好比让一个足球专家根据历史数据和当天的比赛结果去解释合理性，几乎所有专家都能做到；但是，如果让专家去预测每一场比赛的精准比分，他们会经常出错。这再次说明了， 预测 (Prediction) 是智能的核心能力体现，难度远高于解释 (Explanation) 。 其实我挺佩服 OpenAI 团队能够坚持下来的勇气。2018 年时，BERT 在媒体上的影响力几乎完全碾压了 GPT，且当时 OpenAI 的 AI 研发团队体量跟 Google 比起来微不足道。很佩服他们没有放弃 Next-Token Prediction，也没有转向类 BERT 的训练方式。真理往往需要时间去检验。 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/1350a0e1-c403-4655-9406-c6e2c6926123/640.png] BERT 对比 GPT 同时，以 Transformer 为核心的方案收获了 “一箭双雕” 的双重优势： 模型的每层参数量越多，并行度就越高 (Tensor Parallelism) 。 所以，只要通信代价不显著增加，能同时利用的算力就越多。这点需要点赞行业领导者的先见之明。几年前，我看到 CNN 时代有研究人员试图把模型往深度发展，比如设想 1000 层的神经网络。其实非常深（层数非常多）的神经网络是不利于有效利用算力的，因为流水线并行提供的并行度上限不高。 Transformer 的不同 Token 可以同时计算 。 序列长度越长，并行度就越高，只要通讯代价不显著增加，能同时利用的算力就越多。Sequence Parallelism 与 Data Parallelism 互补，进一步提供了更多的并行度。 就这样，我们见证了 GPT-1、BERT、GPT-2、GPT-3、ChatGPT、Gemini 一步一步把智能提升到了今天的高度。 到这里，大家大概也清楚为什么 AI 模型的智能增长会遇到瓶颈了 —— 因为 我们现在的范式无法充分消化持续增长的算力 。 假定一次模型训练和微调消耗的浮点数计算次数（即程序员面试中的计算复杂度的具体值）从 10 ⁿ 变成 10ⁿ⁺³ 时，我们是否获得了一个显著更好的模型？ 其实，很多时候我们把 “效率优化技术” 和 “智能提升技术” 混淆了。比如，明天我提出一个新的架构，实验发现达到跟 GPT-5 类似的效果，只需要 20% 的参数量或计算量。这其实更多是落地或商业化问题；智能的终极问题是：使用同样的浮点数计算次数（而非 Token 量），能否获得一个更好的模型。 浮点数计算次数，才是算力最基本、最本质的计量单位。 3. 未来的方法探讨 首先从硬件层来看，我们 需要持续产生更大的绝对算力 ，这不一定局限于单位芯片上的算力提升。 [图片: 图片 https://image.jiqizhixin.com/uploads/editor/8026f37c-8700-4096-8342-5e6dc2027b49/640.png] 前沿规模机器学习模型训练所用计算量的趋势，图源：Epoch AI 即便单位芯片上的算力没有大幅度提升，我们通过集群的方式也能构建更大的绝对算力。这里需要平衡的是：聚集芯片带来的性能增长，要高于 “芯片或服务器之间通信增长带来的负担”。 所以，具体的硬指标就是：增长或至少维持住 “计算开销/通信开销” 这个比值。这是整个 AI 基础设施层最核心的技术目标。要想实现这个目标，我们需要扩展性更好的并行计算技术，无论是软件还是硬件。 在 更上层 的探索中，我们需要让 AI 模型在单位时间内 “吃下” 更多能源，并真正将其转化为智能。个人感觉大概有以下几点方向： 更高精度的计算能力。 今天，从 FP16 到 FP32，甚至 FP64，模型智能并未出现明显跃升。这本身就是一个瓶颈。理论上，更高精度应当带来更可靠的计算结果，这一点在传统科学计算中早已得到验证。这个观点可能与主流机器学习共识并不一致，而且真正发生可能需要很长时间，但从本质上看，智能仍然需要更精准的计算。这与过拟合并无直接关系，过拟合的根源在于数据规模不足或参数与数据不匹配。 更高阶的优化器。 Google 的朋友告诉我，他们有时候已经不用类 Adam 优化器，而是用更高阶的优化器在训练模型。高阶优化器理论上能在学习过程中给模型更好的指导，算出更好的梯度，这是模型智能提升的本质。当然，高阶优化器的全面替代可能需要很长的时间。 扩展性更好的模型架构或 Loss 函数。 我们仍然需要一种扩展性更好的整合和利用算力的方式。这点我们需要注意：优化效率不一定能提升智能。比如 Mamba 出来的时候，宣传重点是吞吐量的提升，用更小的模型获得同水平的智能。但是，本文关注的是：在最健全的 AI 基础设施上，用最大的可接受成本，能否训出更好的模型，获得更高的智能。比如，今天 Google 告诉你：预算 300 亿美元，半年内给我训出一个更好的模型，不考虑省钱问题，花 10 亿和花 100 亿没区别。在这个场景下，你最终是否会用 Mamba 这样的架构？你是否需要设计更好的 Loss 函数？ 更多的 Epoch 和更好的超参数。 迫于成本压力，我们今天其实并没有对 AI 模型进行深度优化，甚至没有深度搜索超参数。这其实也是我之所以对 AI 模型的智能继续增长有信心的原因。我这里的意思不是直接训练更多的 Epoch。明知无效却生硬地跑更多 Epoch 其实是方法不对（比如参数量和数据量不匹配）。但是，根本上，更多的 Epoch 代表更多的浮点数、更多的能源。我们需要找到方法去 “吃下” 更多能源，并转化出更高智能。 有些技术对大规模落地 AI 非常重要，比如低精度训练、剪枝、量化、蒸馏、PD 分离等推理优化技术。但是，在一个 “算力转智能” 极端有效的情况下，这些技术跟 提升智能上限 无关。笔者对这些技术的贡献者非常尊重，它们在实际落地中至关重要，只是与本文探讨的主题无关。 智能增长归根到底还是算力利用问题。假定算力无限大，比如一个集群的算力达到今天的万亿倍，可能我们会发现更简单的模型结构比 Transformer 和 Next-Token Prediction 的扩展性更好。从 SVM 到 CNN、LSTM、BERT、GPT、MoE：我们始终在寻找能更高效利用算力且具备更好扩展性的方法。这个过程中， 核心原因是问题的规模在不断扩大 。 我们在 AI 时代到来之前便已实现天气预报，然而至今仍未能攻克地震预报，尽管两者本质上都是针对地球数据的研究。究其原因，地下结构涉及比大气更加错综复杂、且变量规模呈指数级庞大的动态多模态数据。这种传统计算模式难以驾驭的高维复杂性，恰恰是未来 AI 技术大有可为的机遇所在。 所以，我有信心我们未来会不断找到更高效的算力使用方式。虽然过程中可能会有很多困难和低潮，但大趋势不可阻挡。 最后，借用 Richard Sutton 教授的一句话收尾： 人工智能 70 年的研究留给我们最大的经验教训是，依托计算能力的通用方法才是最终的赢家，且具备压倒性的优势。 ]]>","published_date":"2025-12-31T05:16:21.905Z","authors":"机器之心","source":"机器之心 - 机器之心","details":{"content_html":"2026 年即将到来，AI 的发展也已经进入了一个新的阶段：我们已经取得了惊人成就，却同时面临进一步增长的瓶颈。<p>新加坡国立大学（NUS）的尤洋教授近期发表了一篇深度分析：《<strong>智能增长的瓶颈</strong>》。</p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/f6bd305d-ff9e-4e9a-81e0-3e72b54679ca/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p>原文链接：https://zhuanlan.zhihu.com/p/1989100535295538013</p><p>在这篇分析文章中，尤洋教授从技术本质出发，直指智能增长的核心矛盾，为我们揭示了 AGI（通用人工智能）的可能路径。</p><p><strong>观点速览</strong></p><p>✅<strong> 智能增长的本质不是架构变革，而是算力如何转化为智能</strong>：AI 的核心智能来自于预训练及其 Loss 结构（例如 GPT 的 Next-Token Prediction）。这些机制更像是把算力转化为智能的方法，而非智能本身。</p><p><strong>✅ 现有智能增长遇到瓶颈的根源</strong>：当前范式（Transformer + 超大算力）在面对进一步增长时， 难以充分消化不断增长的算力资源，这导致了所谓 “预训练红利递减”。</p><p><strong>✅ 算力并不是无限扩展就能解决问题</strong>：即使算力指数级增长，如果现有算法无法有效利用这些计算资源，智能提升仍将受限。</p><p><strong>✅ 未来方向不在于工程优化，而是底层范式突破</strong>：文章探讨了更高精度计算、更高阶优化器、更灵活的 Loss 设计、超大规模训练策略等潜在突破点。</p><p><strong>✅ AI 未来仍然乐观</strong>：智能增长瓶颈虽强，但仍有可能通过更好的算力利用方式被克服。预训练可能才刚刚开始，大模型智能仍有巨大的发展空间。</p><p>AGI 的未来将如何发展？让我们拭目以待。</p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/c8963d7f-778f-42e2-90d6-ef48a9999f72/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p><sup>                          尤洋教授，《智能增长的瓶颈》作者</sup></p><p>以下为其分享原文：</p><p><strong>智能增长的瓶颈</strong></p><p>2026 年已至。在 ChatGPT 诞生三年多后的今天，关于我们的智能水平是否令人满意，以及未来是否还能强劲增长，笔者想分享一些个人的看法。如有谬误，恳请大家指正。</p><p>为了能深入探讨智能的本质，本文将不涉及产品易用性、成本等商业化或落地问题，因为这些本质上与智能突破本身无关。</p><p><strong>1. 智能的现状</strong></p><p>什么是智能？其实目前并没有一个明确的定义。</p><p>从最近图灵奖得主 Yann LeCun 和诺贝尔奖得主 Demis Hassabis 关于 AGI 的争论中，我感受到即便是世界上最顶尖的<strong>专家</strong>也无法准确定义智能。</p><p>个人感觉，AGI 很难定义，其标准也会随着时代的变化而变化。我依然记得十几年前，普通人对人脸识别技术感到不可思议。如果把今天的 ChatGPT 拿到 2006 年，相信那时候的很多人会毫不怀疑地认为我们已经实现了 AGI。</p><p>我觉得智能的核心是<strong>预测</strong>和<strong>创作</strong>。</p><p>我认为如果达到以下这种状态，那么就离 AGI 不远了：</p><ul><li><p>如果你选择接受哪个工作 Offer，完全听从 AI 的意见。</p></li><li><p>如果你买足球彩票预测世界杯冠军，完全听从 AI 的意见。</p></li><li><p>如果你有健康问题，会完全采用 AI 制定的方案去治疗。</p></li><li><p>你分辨不清楚一部奥斯卡最佳电影是否是由 AI 生成的。</p></li><li><p>石油公司的勘探团队用 AI 替代了所有数值算法。</p></li><li><p>AI 能指导初级高铁工程师在 5 分钟内排除高铁的疑难故障。</p></li><li><p>AI 能研制出一款专杀癌细胞且不破坏好细胞的药物。</p></li><li><p>AI 能通过某区域的地下结构数据，精准预测地震的时间。</p></li><li><p>等等……</p></li></ul><p>今天，我们显然还没实现这些。未来能否实现，取决于我们能否克服智能发展的瓶颈。</p><p><strong>2. 智能发展的瓶颈</strong></p><p>今天，我们经常听到一些关于智能发展遇到瓶颈，或者预训练红利已尽的观点。何为瓶颈？我们先探讨一下智能从何而来。</p><p>过去 10 年，AI 大模型的技术本质，是把电力能源通过计算过程转化为可复用的智能。技术的好坏取决于这个转化效率的高低。类似的表述，我也听月之暗面的朋友提及过。</p><p>今天模型的智能本身，最主要还是来自预训练（往往是自监督方法），仅有少量来自微调或强化学习。</p><p>为什么？先算一笔浅显的经济账：因为预训练消耗的算力最多，消耗的能源也最多。</p><p>当然，预训练、微调、强化学习本质上都是在计算梯度以更新参数。如果有合适的海量数据和 Loss 函数，未来在预训练阶段采用 SFT（监督微调）或特殊的强化学习方法也有可能。</p><p>从智能增长的角度，我们甚至不用刻意区分预训练、SFT 和强化学习。它们的区别主要在于更新参数的次数与规模。<strong>从计算本质上看：预训练、微调、强化学习（比如 GRPO）都是在计算梯度的类似物，并用它来更新参数。</strong></p><p>那么，能源从何而来呢？这就是 GPU 或算力。英伟达在这点上做了最大的贡献。虽然英伟达有很多先进的技术，比如更强的 Tensor Cores、Transformer Engine、互联技术（NVLink / 网络化 NVLink）、软件栈等，但我先试图用一句话说清楚英伟达过去几年在技术上做的最重要的事情，即其 GPU 设计的核心思路。</p><p>简而言之，英伟达过去几年最重要的路线是：<strong>在同样的物理空间里堆更多 HBM（高带宽内存）。</strong></p><p>HBM 虽然带宽很高，但依然是计算核心之外的内存（Off-chip from logic die），与计算核心存在不可忽略的物理距离。为了掩盖内存访问延迟，GPU 只能依赖超大的 Batch Size（批处理量）和大规模并行来处理数据。英伟达 GPU 本质上就是一台并行计算机。</p><p>因此，英伟达对算法层和软件层的要求非常明确：必须提供足够大的 Batch Size 或并行度。</p><p>面对英伟达的要求，很多研究团队都提出了自己的方案。比如 RNN、Transformer、卷积序列模型（CNN for Sequence）等等。甚至有人尝试用 SVM 来处理大规模序列数据。</p><p>那为什么 Transformer 率先脱颖而出？因为 Transformer 也是一台并行计算机。</p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/24e3ce8a-5297-4d2a-83ba-a7d43f9cb147/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p><sup>                          原初的 Transformer 架构</sup></p><p>这里我引用一下 Ilya Sutskever 的一句话：“Transformers: parallel computers in disguise”，直白的意思是：Transformer 本质上是一个被神经网络外壳包裹起来的并行计算机。这也是 Transformer 最先能够显现智能的核心原因，因为<strong>它的并行计算特性完美匹配了 GPU 的并行计算单元</strong>。</p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/54926c94-fc79-4fc8-bb77-1679e570b877/640.png\" alt=\"图片\" style=\"width: 50%;\"></section><p>同时，OpenAI 完美地实现了 <strong>Next-Token Prediction</strong> 这个 Loss 函数，它给了 AI 大模型近乎无限的训练数据。理论上 BERT 的 Loss 函数（完形填空和 Next Sentence Prediction）也可以提供近乎无限的数据，但在实践中，Next-Token Prediction 的效果明显更好。</p><p>我推测，这个 Loss 函数最小化了人类的干预 —— 它不是人为设计的，而是大自然在进化过程中赋予人脑的逻辑。并且，Next-Token Prediction 其实是<strong>预测未来</strong>，而 BERT 的完形填空其实是把过去的信息和现在的信息串联起来。这就好比让一个足球专家根据历史数据和当天的比赛结果去解释合理性，几乎所有专家都能做到；但是，如果让专家去预测每一场比赛的精准比分，他们会经常出错。这再次说明了，<strong>预测 (Prediction) 是智能的核心能力体现，难度远高于解释 (Explanation)</strong>。</p><p>其实我挺佩服 OpenAI 团队能够坚持下来的勇气。2018 年时，BERT 在媒体上的影响力几乎完全碾压了 GPT，且当时 OpenAI 的 AI 研发团队体量跟 Google 比起来微不足道。很佩服他们没有放弃 Next-Token Prediction，也没有转向类 BERT 的训练方式。真理往往需要时间去检验。</p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/1350a0e1-c403-4655-9406-c6e2c6926123/640.png\" alt=\"图片\" style=\"width: 700%;\"></section><p><sup>      BERT 对比 GPT</sup></p><p>同时，以 Transformer 为核心的方案收获了 “一箭双雕” 的双重优势：</p><ol><li><p><strong>模型的每层参数量越多，并行度就越高 (Tensor Parallelism)</strong>。 所以，只要通信代价不显著增加，能同时利用的算力就越多。这点需要点赞行业领导者的先见之明。几年前，我看到 CNN 时代有研究人员试图把模型往深度发展，比如设想 1000 层的神经网络。其实非常深（层数非常多）的神经网络是不利于有效利用算力的，因为流水线并行提供的并行度上限不高。</p></li><li><p><strong>Transformer 的不同 Token 可以同时计算</strong>。 序列长度越长，并行度就越高，只要通讯代价不显著增加，能同时利用的算力就越多。Sequence Parallelism 与 Data Parallelism 互补，进一步提供了更多的并行度。</p></li></ol><p>就这样，我们见证了 GPT-1、BERT、GPT-2、GPT-3、ChatGPT、Gemini 一步一步把智能提升到了今天的高度。</p><p>到这里，大家大概也清楚为什么 AI 模型的智能增长会遇到瓶颈了 —— 因为<strong>我们现在的范式无法充分消化持续增长的算力</strong>。</p><p>假定一次模型训练和微调消耗的浮点数计算次数（即程序员面试中的计算复杂度的具体值）从 10<span>ⁿ</span> 变成 10ⁿ⁺³ 时，我们是否获得了一个显著更好的模型？</p><p>其实，很多时候我们把 “效率优化技术” 和 “智能提升技术” 混淆了。比如，明天我提出一个新的架构，实验发现达到跟 GPT-5 类似的效果，只需要 20% 的参数量或计算量。这其实更多是落地或商业化问题；智能的终极问题是：使用同样的浮点数计算次数（而非 Token 量），能否获得一个更好的模型。<strong>浮点数计算次数，才是算力最基本、最本质的计量单位。</strong></p><p><strong>3. 未来的方法探讨</strong></p><p>首先从硬件层来看，我们<strong>需要持续产生更大的绝对算力</strong>，这不一定局限于单位芯片上的算力提升。</p><section><img src=\"https://image.jiqizhixin.com/uploads/editor/8026f37c-8700-4096-8342-5e6dc2027b49/640.png\" alt=\"图片\" style=\"width: 700%;\"></section><p><sup>      前沿规模机器学习模型训练所用计算量的趋势，图源：Epoch AI</sup></p><p>即便单位芯片上的算力没有大幅度提升，我们通过集群的方式也能构建更大的绝对算力。这里需要平衡的是：聚集芯片带来的性能增长，要高于 “芯片或服务器之间通信增长带来的负担”。</p><p>所以，具体的硬指标就是：增长或至少维持住 “计算开销/通信开销” 这个比值。这是整个 AI 基础设施层最核心的技术目标。要想实现这个目标，我们需要扩展性更好的并行计算技术，无论是软件还是硬件。</p><p>在<strong>更上层</strong>的探索中，我们需要让 AI 模型在单位时间内 “吃下” 更多能源，并真正将其转化为智能。个人感觉大概有以下几点方向：</p><ol><li><p><strong>更高精度的计算能力。</strong> 今天，从 FP16 到 FP32，甚至 FP64，模型智能并未出现明显跃升。这本身就是一个瓶颈。理论上，更高精度应当带来更可靠的计算结果，这一点在传统科学计算中早已得到验证。这个观点可能与主流机器学习共识并不一致，而且真正发生可能需要很长时间，但从本质上看，智能仍然需要更精准的计算。这与过拟合并无直接关系，过拟合的根源在于数据规模不足或参数与数据不匹配。</p></li><li><p><strong>更高阶的优化器。</strong> Google 的朋友告诉我，他们有时候已经不用类 Adam 优化器，而是用更高阶的优化器在训练模型。高阶优化器理论上能在学习过程中给模型更好的指导，算出更好的梯度，这是模型智能提升的本质。当然，高阶优化器的全面替代可能需要很长的时间。</p></li><li><p><strong>扩展性更好的模型架构或 Loss 函数。 </strong>我们仍然需要一种扩展性更好的整合和利用算力的方式。这点我们需要注意：优化效率不一定能提升智能。比如 Mamba 出来的时候，宣传重点是吞吐量的提升，用更小的模型获得同水平的智能。但是，本文关注的是：在最健全的 AI 基础设施上，用最大的可接受成本，能否训出更好的模型，获得更高的智能。比如，今天 Google 告诉你：预算 300 亿美元，半年内给我训出一个更好的模型，不考虑省钱问题，花 10 亿和花 100 亿没区别。在这个场景下，你最终是否会用 Mamba 这样的架构？你是否需要设计更好的 Loss 函数？</p></li><li><p><strong>更多的 Epoch 和更好的超参数。 </strong>迫于成本压力，我们今天其实并没有对 AI 模型进行深度优化，甚至没有深度搜索超参数。这其实也是我之所以对 AI 模型的智能继续增长有信心的原因。我这里的意思不是直接训练更多的 Epoch。明知无效却生硬地跑更多 Epoch 其实是方法不对（比如参数量和数据量不匹配）。但是，根本上，更多的 Epoch 代表更多的浮点数、更多的能源。我们需要找到方法去 “吃下” 更多能源，并转化出更高智能。</p></li></ol><p>有些技术对大规模落地 AI 非常重要，比如低精度训练、剪枝、量化、蒸馏、PD 分离等推理优化技术。但是，在一个 “算力转智能” 极端有效的情况下，这些技术跟<strong>提升智能上限</strong>无关。笔者对这些技术的贡献者非常尊重，它们在实际落地中至关重要，只是与本文探讨的主题无关。</p><p>智能增长归根到底还是算力利用问题。假定算力无限大，比如一个集群的算力达到今天的万亿倍，可能我们会发现更简单的模型结构比 Transformer 和 Next-Token Prediction 的扩展性更好。从 SVM 到 CNN、LSTM、BERT、GPT、MoE：我们始终在寻找能更高效利用算力且具备更好扩展性的方法。这个过程中，<strong>核心原因是问题的规模在不断扩大</strong>。</p><p>我们在 AI 时代到来之前便已实现天气预报，然而至今仍未能攻克地震预报，尽管两者本质上都是针对地球数据的研究。究其原因，地下结构涉及比大气更加错综复杂、且变量规模呈指数级庞大的动态多模态数据。这种传统计算模式难以驾驭的高维复杂性，恰恰是未来 AI 技术大有可为的机遇所在。</p><p>所以，我有信心我们未来会不断找到更高效的算力使用方式。虽然过程中可能会有很多困难和低潮，但大趋势不可阻挡。</p><p>最后，借用 Richard Sutton 教授的一句话收尾：<strong>人工智能 70 年的研究留给我们最大的经验教训是，依托计算能力的通用方法才是最终的赢家，且具备压倒性的优势。</strong></p>]]>"}}]