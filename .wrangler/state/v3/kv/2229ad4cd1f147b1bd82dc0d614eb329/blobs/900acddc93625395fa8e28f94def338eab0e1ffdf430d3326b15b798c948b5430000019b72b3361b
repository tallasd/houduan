[{"id":"229046946093049856","type":"socialMedia","url":"https://m.okjike.com/originalPosts/69549ed8f9f724324f33530b","title":"年末总结特别多，纯模型进展的我觉得看这一篇就够了 https://substack.com/inbox/post/182789318 没梯子或者英文不好的， 看notebooklm整理的ppt就行 这里： htt...","description":"年末总结特别多，纯模型进展的我觉得看这一篇就够了 https://substack.com/inbox/post/182789318 没梯子或者英文不好的， 看notebooklm整理的ppt就行 这里： https://ai.feishu.cn/wiki/ZOPJwddiRiOMebk85QjcaU0cnhg?from=from_copylink [图片: https://cdnv2.ruguoapp.com/Fjhppq1qA7dNSqtVQiTUarN1kPS6v3.png] [图片: https://cdnv2.ruguoapp.com/FqNSzSxj68uO8kKacugXojippPp1v3.png]","published_date":"2025-12-31T03:56:08.724Z","authors":"rosicky311_明浩","source":"AI探索站 - 即刻圈子 - rosicky311_明浩","details":{"content_html":"年末总结特别多，纯模型进展的我觉得看这一篇就够了<br>https://substack.com/inbox/post/182789318<br>没梯子或者英文不好的，<br>看notebooklm整理的ppt就行<br>这里：<br>https://ai.feishu.cn/wiki/ZOPJwddiRiOMebk85QjcaU0cnhg?from=from_copylink<br><img src=\"https://cdnv2.ruguoapp.com/Fjhppq1qA7dNSqtVQiTUarN1kPS6v3.png\"><br><img src=\"https://cdnv2.ruguoapp.com/FqNSzSxj68uO8kKacugXojippPp1v3.png\">"}},{"id":"229044756439869440","type":"socialMedia","url":"https://x.com/ezshine/status/2006200845931839890","title":"Gemini太逗了，让我假装老法师，终于理解金牌讲师的保护色了。","description":"Gemini太逗了，让我假装老法师，终于理解金牌讲师的保护色了。 [图片: https://pbs.twimg.com/media/G9d1CF2aAAAieX7?format=jpg&#x26;name=orig]","published_date":"2025-12-31T03:08:49.041Z","authors":"大帅老猿","source":"twitter-大帅老猿","details":{"content_html":"Gemini太逗了，让我假装老法师，终于理解金牌讲师的保护色了。<br><img width=\"946\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9d1CF2aAAAieX7?format=jpg&#x26;name=orig\">"}},{"id":"229019868916328448","type":"socialMedia","url":"https://x.com/kevinweil/status/2006187462729847107","title":"Congrats to the @OpenAI research team—GPT 5.2 is an incredible model!","description":"Congrats to the @OpenAI research team—GPT 5.2 is an incredible model! Sebastien Bubeck: Nice way to end the year, see you in 2026 for more! (Also good to remember that 6 months ago the models were at 4% on Frontier Math Tier 4...) [图片: https://pbs.twimg.com/media/G9dbDVkaYAIT-f9?format=jpg&#x26;name=orig]","published_date":"2025-12-31T02:15:38.364Z","authors":"Kevin Weil 🇺🇸","source":"twitter-Kevin Weil 🇺🇸","details":{"content_html":"Congrats to the @OpenAI research team—GPT 5.2 is an incredible model!<div><br><br>Sebastien Bubeck: Nice way to end the year, see you in 2026 for more! <br><br>(Also good to remember that 6 months ago the models were at 4% on Frontier Math Tier 4...)<br><br><img width=\"1080\" height=\"847\" style=\"\" src=\"https://pbs.twimg.com/media/G9dbDVkaYAIT-f9?format=jpg&#x26;name=orig\"></div>"}},{"id":"229016512015955968","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1q00zul/apple_needs_to_deliver_an_aicharged_siri_so_good/","title":"Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade","description":"[图片: Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade https://external-preview.redd.it/5xYig1WI5dSa9Bw0hjO_VZFIcNoTnL-dQdxjEWh0as8.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=2dadab3ead02b470de3adae2c0f4c80f01347841] submitted by /u/ControlCAD [link] [comments]","published_date":"2025-12-31T02:15:13.791Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1q00zul/apple_needs_to_deliver_an_aicharged_siri_so_good/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/5xYig1WI5dSa9Bw0hjO_VZFIcNoTnL-dQdxjEWh0as8.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=2dadab3ead02b470de3adae2c0f4c80f01347841\" alt=\"Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade\" title=\"Apple needs to deliver an AI-charged Siri so good it gets older iPhone users to upgrade\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/ControlCAD\" target=\"_blank\"> /u/ControlCAD </a> <br> <span><a href=\"https://www.cnbc.com/2025/12/30/apple-intelligence-ai-siri-iphone.html\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1q00zul/apple_needs_to_deliver_an_aicharged_siri_so_good/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"229026580041713664","type":"socialMedia","url":"https://x.com/shao__meng/status/2006179679288582432","title":"2026 年 AI 发展八点预测，和 2025 年预测回顾（仅一个失误），来自 @ashugarg 2025年预测回顾：大部分准确或部分实现 正确（🟢）： · 推理模型（如 OpenAI o...","description":"2026 年 AI 发展八点预测，和 2025 年预测回顾（仅一个失误），来自 @ashugarg 2025年预测回顾：大部分准确或部分实现 正确（🟢）： · 推理模型（如 OpenAI o1/o3）和复合 AI 系统（多模型+工具协作）主导了 2025 年。 · AI 重塑软件经济，向“服务即软件”（AI 直接交付结果而非卖许可证）转型，成为 B2B 投资主流。 · OpenAI 主导地位削弱，Gemini、Claude 和开源模型分流市场份额，企业采用多模型策略。 · NVIDIA 芯片垄断面临挑战（Cerebras、AMD、Google TPU 等崛起）。 · 无人驾驶出租车（如 Waymo）赢得公众信任，在旧金山等地普及。 提前预测（⏳）： · AI 初创公司尚未完全取代传统巨头（Google 等强势反击）。 · AI 界面超越纯聊天框（进展较慢，但作者坚持 2026 年会加速）。 · 搜索引擎“10 个蓝链接”模式衰退（AI 概述已覆盖 20 亿用户，点击率下降），但真正颠覆在于智能体式商务。 错误（❌）： · Meta Llama 未成为“AI 的 Linux”（开源模型繁荣，但未形成单一标准主导）。 2026 年 8 大预测 2026 年是 AI 从试点向大规模生产落地的关键年，重点在企业应用、安全、竞争和消费者习惯变化。 1. 企业 AI 进入生产阶段：过去两年企业 AI 停留在试点，2026 年将实现可靠部署。初创公司通过嵌入工程师、定制小模型和本地部署解决边缘案例，SaaS 巨头（如Salesforce、ServiceNow）推动类别合法化。 2. 决策痕迹成为新数据护城河：AI 智能体执行工作流时，会记录完整决策过程（输入、规则、例外等），形成“上下文图”。这将成为企业独有资产，帮助持续优化智能体，初创公司在执行路径上有优势。 3. AI 安全问题成为焦点：智能体持有敏感业务逻辑，风险增大。2026 年 AI 安全将成为董事会级指标，出现至少一起高调事件，推动零信任框架和行为监控。 4. SaaS 巨头反击：Salesforce、ServiceNow 等加强本土 AI 功能，限制 API 访问、增加摩擦以保护数据和收入。初创公司需警惕对巨头依赖的风险。 5. 智能体吞噬电商：消费者习惯用 AI 描述需求购物，Visa、Mastercard 等已铺设智能体支付协议。2026 年智能体将主导低风险高频消费，颠覆聚合器（如 Expedia），强化 Amazon/Walmart 优势，挑战 Google 广告模式。 6. Gemini 超越 ChatGPT：2025 年后半年 Gemini 用户增长 30%（ChatGPT 仅 6%），MAU 达数亿。Google 的分发优势（Search、Android）将帮助 Gemini（及 Grok）抢占消费者份额，形成三四强格局。 7. AI 实验室上市：Anthropic 和/或 OpenAI 可能 2026 年 IPO。Anthropic 收入快速增长（2025年超70亿，2026目标260亿），OpenAI 达200亿规模，但巨额亏损和资本需求推动上市（估值可能达万亿）。 8. Cursor 式界面成默认：聊天框 UI 已到极限，2026年 AI 将嵌入工作流（如 Cursor 在代码中的直接编辑）。类似“某某领域的 Cursor ”将普及于法律、金融、营销等领域，AI 主动提议而非被动等待。 3个持续趋势（不止2026年） · 缩放定律乘数效应：预训练+后训练优化+推理时计算，三者结合带来复合提升。 · 验证是瓶颈：AI 在可验证领域（如编码、数学）进步快，主观任务仍需人类监督。 · 定价向结果导向转变：从按使用付费转向按任务/结果付费，企业要求明确 ROI。 [图片: https://pbs.twimg.com/media/G9dhxHAaYAQnhgC?format=jpg&#x26;name=orig] ashu garg: http://x.com/i/article/2006074423854702592","published_date":"2025-12-31T01:44:43.629Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"2026 年 AI 发展八点预测，和 2025 年预测回顾（仅一个失误），来自 @ashugarg <br><br>2025年预测回顾：大部分准确或部分实现<br>正确（🟢）：<br>· 推理模型（如 OpenAI o1/o3）和复合 AI 系统（多模型+工具协作）主导了 2025 年。<br>· AI 重塑软件经济，向“服务即软件”（AI 直接交付结果而非卖许可证）转型，成为 B2B 投资主流。<br>· OpenAI 主导地位削弱，Gemini、Claude 和开源模型分流市场份额，企业采用多模型策略。<br>· NVIDIA 芯片垄断面临挑战（Cerebras、AMD、Google TPU 等崛起）。<br>· 无人驾驶出租车（如 Waymo）赢得公众信任，在旧金山等地普及。<br>提前预测（⏳）：<br>· AI 初创公司尚未完全取代传统巨头（Google 等强势反击）。<br>· AI 界面超越纯聊天框（进展较慢，但作者坚持 2026 年会加速）。<br>· 搜索引擎“10 个蓝链接”模式衰退（AI 概述已覆盖 20 亿用户，点击率下降），但真正颠覆在于智能体式商务。<br>错误（❌）：<br>· Meta Llama 未成为“AI 的 Linux”（开源模型繁荣，但未形成单一标准主导）。<br><br>2026 年 8 大预测<br>2026 年是 AI 从试点向大规模生产落地的关键年，重点在企业应用、安全、竞争和消费者习惯变化。<br><br>1. 企业 AI 进入生产阶段：过去两年企业 AI 停留在试点，2026 年将实现可靠部署。初创公司通过嵌入工程师、定制小模型和本地部署解决边缘案例，SaaS 巨头（如Salesforce、ServiceNow）推动类别合法化。<br><br>2. 决策痕迹成为新数据护城河：AI 智能体执行工作流时，会记录完整决策过程（输入、规则、例外等），形成“上下文图”。这将成为企业独有资产，帮助持续优化智能体，初创公司在执行路径上有优势。<br><br>3. AI 安全问题成为焦点：智能体持有敏感业务逻辑，风险增大。2026 年 AI 安全将成为董事会级指标，出现至少一起高调事件，推动零信任框架和行为监控。<br><br>4. SaaS 巨头反击：Salesforce、ServiceNow 等加强本土 AI 功能，限制 API 访问、增加摩擦以保护数据和收入。初创公司需警惕对巨头依赖的风险。<br><br>5. 智能体吞噬电商：消费者习惯用 AI 描述需求购物，Visa、Mastercard 等已铺设智能体支付协议。2026 年智能体将主导低风险高频消费，颠覆聚合器（如 Expedia），强化 Amazon/Walmart 优势，挑战 Google 广告模式。<br><br>6. Gemini 超越 ChatGPT：2025 年后半年 Gemini 用户增长 30%（ChatGPT 仅 6%），MAU 达数亿。Google 的分发优势（Search、Android）将帮助 Gemini（及 Grok）抢占消费者份额，形成三四强格局。<br><br>7. AI 实验室上市：Anthropic 和/或 OpenAI 可能 2026 年 IPO。Anthropic 收入快速增长（2025年超70亿，2026目标260亿），OpenAI 达200亿规模，但巨额亏损和资本需求推动上市（估值可能达万亿）。<br><br>8. Cursor 式界面成默认：聊天框 UI 已到极限，2026年 AI 将嵌入工作流（如 Cursor 在代码中的直接编辑）。类似“某某领域的 Cursor ”将普及于法律、金融、营销等领域，AI 主动提议而非被动等待。<br><br>3个持续趋势（不止2026年）<br>· 缩放定律乘数效应：预训练+后训练优化+推理时计算，三者结合带来复合提升。<br>· 验证是瓶颈：AI 在可验证领域（如编码、数学）进步快，主观任务仍需人类监督。<br>· 定价向结果导向转变：从按使用付费转向按任务/结果付费，企业要求明确 ROI。<br><img width=\"1643\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9dhxHAaYAQnhgC?format=jpg&#x26;name=orig\"><div><br><br>ashu garg: http://x.com/i/article/2006074423854702592<br></div>"}},{"id":"229026580041713665","type":"socialMedia","url":"https://x.com/shao__meng/status/2006176156274581618","title":"2025 年 LLM 现状：进展、问题与预测，来自 @rasbt 分享，开始前再安利一次作者的书籍和开源资源 Build a Large Language Model (From Scratch) https://github....","description":"2025 年 LLM 现状：进展、问题与预测，来自 @rasbt 分享，开始前再安利一次作者的书籍和开源资源 Build a Large Language Model (From Scratch) https://github.com/rasbt/LLMs-from-scratch Build A Reasoning Model (From Scratch) https://github.com/rasbt/reasoning-from-scratch 1. 2025年：推理模型、RLVR 与 GRPO 之年 2025年最大的亮点是推理模型的爆发。这些模型通过生成中间推理步骤（如链式思考）显著提升复杂任务准确率。关键创新是 RLVR，结合 GRPO 算法，由 DeepSeek R1 模型在年初引入。 · RLVR 允许使用客观正确的奖励信号进行大规模后训练，而无需昂贵的人工标注。 · 这大幅降低了训练成本，并使开放权重模型迅速赶上专有模型。 · 随后，各大实验室纷纷推出推理变体，RLVR 成为后训练主流方法，取代了以往的 RLHF 和 PPO。 2. GRPO：年度研究宠儿 GRPO 算法在 2025 年被广泛改进和采用（如 Olmo 3、DeepSeek V3.2），通过过滤不良更新、调整KL散度和采样策略，提升训练稳定性和性能。它标志着强化学习在 LLM 领域的成熟应用。 3. LLM 架构：分叉之路？ · 主导架构仍是 Decoder-only Transformer + MoE，辅以效率优化（如分组查询注意力、多头潜注意力）。 · 新兴趋势：混合高效架构（如 Qwen3-Next的Gated DeltaNets、Kimi Linear、NVIDIA Nemotron 3 的 Mamba-2 层），实现序列长度线性扩展。 · 文本扩散模型（如 Google Gemini Diffusion）作为低延迟替代方案出现，但尚未主导前沿性能。 4. 推理时扩展与工具使用之年 · 推理时扩展（如自一致性、自精炼）成为提升复杂任务性能的重要手段，许多模型已在数学竞赛中达到金牌水平。 · 工具使用（调用搜索、计算器等外部工具）减少幻觉，成为代理系统标准。但开源生态在工具集成和安全性上仍落后于专有模型。 5. 年度热词：Benchmaxxing 基准测试过度优化问题突出：模型在公开基准上得分很高，但实际应用表现平平。原因包括训练数据污染和基准饱和。作者建议视基准为“阈值指标”，而非绝对能力衡量，并强调实际任务测试的重要性。 6. AI 在编码、写作与研究中的应用 · 编码：擅长处理重复性任务（如调试、代码清理），但专家知识仍不可替代。 · 写作/研究：帮助纠错、查找参考，但过度依赖可能导致技能退化和工作空洞化。 作者强调“先自己努力，再用 LLM 辅助”的原则，以保持学习和创造满足感。 7. 私域数据：新竞争优势 随着通用 scaling 定律趋于饱和，私有数据成为差异化关键。行业企业（如生物科技公司）倾向自建专有 LLM，利用开放基础模型（如 DeepSeek V3.2）进行领域适配。 8. 从零构建 LLM 与推理模型 作者分享个人工作：畅销书「Build a Large Language Model (From Scratch)」及续作「Build a Reasoning Model (From Scratch)」，涵盖推理时扩展、RLVR/GRPO 等最新技术。 9. 2025 年惊喜与 2026 年预测 2025 年主要惊喜（作者未预料到如此迅速发生）： · 多个推理模型已在重大数学竞赛中达到金牌水平（如 OpenAI 未命名模型、Gemini Deep Think、DeepSeekMath-V2）。 · Llama 系列（包括 Llama 4）在开源社区大幅失宠，Qwen 凭借下载量和衍生模型数量成为新霸主。 · Mistral AI 的旗舰 Mistral 3 采用 DeepSeek V3 架构。 · 开源前沿模型竞争激烈，新选手涌现（如 Kimi、GLM、MiniMax）。 · 高效混合架构被领先实验室优先采用。 · OpenAI 意外发布开放权重模型 gpt-oss。 · MCP 协议迅速成为代理系统中工具/数据访问的标准。 对 2026 年的预测： · 将出现行业级、低延迟消费级扩散模型（如 Gemini Diffusion 领先）。 · 开源社区逐步集成本地工具使用和更强智能体能力。 · RLVR 扩展至数学/编码以外领域（如化学、生物）。 · 传统 RAG 渐退，长上下文小模型将成为文档查询主流。 · 性能提升更多来自工具优化和推理时扩展，而非单纯核心模型训练；基准进步将聚焦减少无用推理步骤。 原文地址： https://magazine.sebastianraschka.com/p/state-of-llms-2025 [图片: https://pbs.twimg.com/media/G9dekfPWwAEgLDk?format=jpg&#x26;name=orig] Sebastian Raschka: http://x.com/i/article/2006014147733995520","published_date":"2025-12-31T01:30:43.774Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"2025 年 LLM 现状：进展、问题与预测，来自 @rasbt 分享，开始前再安利一次作者的书籍和开源资源<br><br>Build a Large Language Model (From Scratch)<br>https://github.com/rasbt/LLMs-from-scratch<br>Build A Reasoning Model (From Scratch)<br>https://github.com/rasbt/reasoning-from-scratch<br><br>1. 2025年：推理模型、RLVR 与 GRPO 之年<br>2025年最大的亮点是推理模型的爆发。这些模型通过生成中间推理步骤（如链式思考）显著提升复杂任务准确率。关键创新是 RLVR，结合 GRPO 算法，由 DeepSeek R1 模型在年初引入。<br>· RLVR 允许使用客观正确的奖励信号进行大规模后训练，而无需昂贵的人工标注。<br>· 这大幅降低了训练成本，并使开放权重模型迅速赶上专有模型。<br>· 随后，各大实验室纷纷推出推理变体，RLVR 成为后训练主流方法，取代了以往的 RLHF 和 PPO。<br><br>2. GRPO：年度研究宠儿<br>GRPO 算法在 2025 年被广泛改进和采用（如 Olmo 3、DeepSeek V3.2），通过过滤不良更新、调整KL散度和采样策略，提升训练稳定性和性能。它标志着强化学习在 LLM 领域的成熟应用。<br><br>3. LLM 架构：分叉之路？<br>· 主导架构仍是 Decoder-only Transformer + MoE，辅以效率优化（如分组查询注意力、多头潜注意力）。<br>· 新兴趋势：混合高效架构（如 Qwen3-Next的Gated DeltaNets、Kimi Linear、NVIDIA Nemotron 3 的 Mamba-2 层），实现序列长度线性扩展。<br>· 文本扩散模型（如 Google Gemini Diffusion）作为低延迟替代方案出现，但尚未主导前沿性能。<br><br>4. 推理时扩展与工具使用之年<br>· 推理时扩展（如自一致性、自精炼）成为提升复杂任务性能的重要手段，许多模型已在数学竞赛中达到金牌水平。<br>· 工具使用（调用搜索、计算器等外部工具）减少幻觉，成为代理系统标准。但开源生态在工具集成和安全性上仍落后于专有模型。<br><br>5. 年度热词：Benchmaxxing<br>基准测试过度优化问题突出：模型在公开基准上得分很高，但实际应用表现平平。原因包括训练数据污染和基准饱和。作者建议视基准为“阈值指标”，而非绝对能力衡量，并强调实际任务测试的重要性。<br><br>6. AI 在编码、写作与研究中的应用<br>· 编码：擅长处理重复性任务（如调试、代码清理），但专家知识仍不可替代。<br>· 写作/研究：帮助纠错、查找参考，但过度依赖可能导致技能退化和工作空洞化。 作者强调“先自己努力，再用 LLM 辅助”的原则，以保持学习和创造满足感。<br><br>7. 私域数据：新竞争优势<br>随着通用 scaling 定律趋于饱和，私有数据成为差异化关键。行业企业（如生物科技公司）倾向自建专有 LLM，利用开放基础模型（如 DeepSeek V3.2）进行领域适配。<br><br>8. 从零构建 LLM 与推理模型<br>作者分享个人工作：畅销书「Build a Large Language Model (From Scratch)」及续作「Build a Reasoning Model (From Scratch)」，涵盖推理时扩展、RLVR/GRPO 等最新技术。<br><br>9. 2025 年惊喜与 2026 年预测<br>2025 年主要惊喜（作者未预料到如此迅速发生）：<br>· 多个推理模型已在重大数学竞赛中达到金牌水平（如 OpenAI 未命名模型、Gemini Deep Think、DeepSeekMath-V2）。<br>· Llama 系列（包括 Llama 4）在开源社区大幅失宠，Qwen 凭借下载量和衍生模型数量成为新霸主。<br>· Mistral AI 的旗舰 Mistral 3 采用 DeepSeek V3 架构。<br>· 开源前沿模型竞争激烈，新选手涌现（如 Kimi、GLM、MiniMax）。<br>· 高效混合架构被领先实验室优先采用。<br>· OpenAI 意外发布开放权重模型 gpt-oss。<br>· MCP 协议迅速成为代理系统中工具/数据访问的标准。<br><br>对 2026 年的预测：<br>· 将出现行业级、低延迟消费级扩散模型（如 Gemini Diffusion 领先）。<br>· 开源社区逐步集成本地工具使用和更强智能体能力。<br>· RLVR 扩展至数学/编码以外领域（如化学、生物）。<br>· 传统 RAG 渐退，长上下文小模型将成为文档查询主流。<br>· 性能提升更多来自工具优化和推理时扩展，而非单纯核心模型训练；基准进步将聚焦减少无用推理步骤。<br><br>原文地址：<br>https://magazine.sebastianraschka.com/p/state-of-llms-2025<br><img width=\"2046\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9dekfPWwAEgLDk?format=jpg&#x26;name=orig\"><div><br><br>Sebastian Raschka: http://x.com/i/article/2006014147733995520<br></div>"}},{"id":"229026580041713666","type":"socialMedia","url":"https://x.com/shao__meng/status/2006171403528122454","title":"三个增强 Claude Code 实用性的开源工具，来自 @Yampeleg 分享推荐，感谢 ❤️ 1. WhatsApp bridge for Claude Code @steipete · 功能：允许用户通过 WhatsApp ...","description":"三个增强 Claude Code 实用性的开源工具，来自 @Yampeleg 分享推荐，感谢 ❤️ 1. WhatsApp bridge for Claude Code @steipete · 功能：允许用户通过 WhatsApp 直接与 Claude Code 互动，实现更便捷的移动端对话。 · 开源地址：https://github.com/steipete/clawdis 2. dev-browser @sawyerhood · 功能：提供可靠的浏览器自动化控制能力（作者尝试过多个同类工具，此为最稳定可靠的一个）。 · 开源地址：https://github.com/SawyerHood/dev-browser 3. Continuous-Claude-v2 @parcadei · 功能：一套相互协作的代码相关工具集，特别强调会话连续性（保持上下文）、上下文钩子以及 token 高效的工作流，帮助长时间编程任务更顺畅，“令人惊叹的工具集合”。 · 开源地址：https://github.com/parcadei/Continuous-Claude-v2 [图片: https://pbs.twimg.com/media/G9daHOxaYAAYt85?format=jpg&#x26;name=orig] Yam Peleg: Tools I actually use myself got Claude Code: 1. WhatsApp bridge for Claude Code: • warelay by @steipete • https://github.com/steipete/warelay 2. The best browser control plugin: (i tried them all, this is the most reliable) • dev-browser by @sawyerhood • https://github.com/SawyerHood/dev-browser 3.","published_date":"2025-12-31T01:11:50.387Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"三个增强 Claude Code 实用性的开源工具，来自 @Yampeleg 分享推荐，感谢 ❤️<br><br>1. WhatsApp bridge for Claude Code @steipete<br>· 功能：允许用户通过 WhatsApp 直接与 Claude Code 互动，实现更便捷的移动端对话。<br>· 开源地址：https://github.com/steipete/clawdis<br><br>2. dev-browser @sawyerhood<br>· 功能：提供可靠的浏览器自动化控制能力（作者尝试过多个同类工具，此为最稳定可靠的一个）。<br>· 开源地址：https://github.com/SawyerHood/dev-browser<br><br>3. Continuous-Claude-v2 @parcadei<br>· 功能：一套相互协作的代码相关工具集，特别强调会话连续性（保持上下文）、上下文钩子以及 token 高效的工作流，帮助长时间编程任务更顺畅，“令人惊叹的工具集合”。<br>· 开源地址：https://github.com/parcadei/Continuous-Claude-v2<br><img width=\"1668\" height=\"1276\" style=\"\" src=\"https://pbs.twimg.com/media/G9daHOxaYAAYt85?format=jpg&#x26;name=orig\"><div><br><br>Yam Peleg: Tools I actually use myself got Claude Code:<br><br>1. WhatsApp bridge for Claude Code:<br><br>• warelay by @steipete<br>• https://github.com/steipete/warelay<br><br>2. The best browser control plugin:<br>(i tried them all, this is the most reliable)<br><br>• dev-browser by @sawyerhood<br>• https://github.com/SawyerHood/dev-browser<br><br>3.<br></div>"}},{"id":"229026580041713667","type":"socialMedia","url":"https://x.com/shao__meng/status/2006169366916915531","title":"Context Graph 实战示例：从 CRM 到 CRCG @ishan_chhabra 这篇文章是对「AI’s trillion-dollar opportunity: Context graphs」提出「Context Graph」的进一步阐...","description":"Context Graph 实战示例：从 CRM 到 CRCG @ishan_chhabra 这篇文章是对「AI’s trillion-dollar opportunity: Context graphs」提出「Context Graph」的进一步阐释和实用化说明。 核心观点是：传统的 CRM 系统是“记录系统”，只存储静态数据和最终状态；而新兴的 Agentic AI 需要一种全新的“上下文图”，它不仅是记录数据，更是记录决策过程、推理逻辑和动态上下文，从而变成“推理系统”。 为什么“Context Graph”容易被误解？ · “Graph”一词容易让人联想到图数据库或知识图谱，但作者强调：Context Graphs 与这些技术无关。 · 它本质上是两种思路的结合： 1. 上下文工程：为 AI 模型提供精确、相关的任务信息，避免幻觉或遗忘。 2. 决策图：AI Agent 在执行任务时动态构建的图结构，记录它收集了哪些上下文、为什么做出某个决策。 文章用一个销售场景的实用例子来说明差异 作者以销售团队的 POC 失败问题为例，对比三种方法： 1. 传统 CRM 方式： · 在 CRM 中新增字段（如 POC 开始/结束日期、成功标准）。 · 销售人员填写，但“成功标准”往往简陋（如“需要邮件集成”）。 · 结果：领导无法深入了解真正的成功定义、关键人物或与组织目标的匹配。 2. 朴素 AI 方式： · 用 AI 自动从会议录音中提取总结，填充或更新 CRM 字段。 · 问题：多次更新会导致上下文丢失，只剩最终状态，没有决策痕迹（为什么这个标准被优先？）。 3. Context Graph 方式（推荐的新架构）： · 以销售一家新一代 CRM 给客户 “Dunder Mifflin” 为例，涉及两场会议： · 第一场：与普通员工 Jim 聊天，他抱怨“每周花5小时找线索”和“CRM 更新太慢”。 · 第二场：与经理 Michael 聊天，他强调“为 IPO 准备，需要将预测准确率从73%提升到90%”。 · 系统不只是简单记录痛点，而是动态构建图结构： · 先有基础节点：自家产品的核心能力（擅长预测和管道可见性，不擅长线索生成）。 · 与 Jim 的痛点匹配：线索生成不匹配（标记为无法解决）；CRM 更新匹配，并拉取类似客户案例。 · 与 Michael 的痛点匹配：预测准确率高度匹配，创建“成功指标”节点（从73%到90%），并因 Michael 是决策者而优先级更高。 · 结果：询问“成功定义是什么？”时，Context Graph 能给出层次化、带理由的答案： · 首要：决策者 Michael 的预测需求，与公司 IPO 目标对齐，且匹配产品核心能力。 · 次要：员工 Jim 的 CRM 更新需求（影响力较低）。 · 不相关：Jim 的线索生成需求（产品不支持）。 为什么这很重要？未来的潜力 · 传统 CRM 只存储“什么”（最终事实），Context Graph 存储“为什么”（决策痕迹、来源权重、优先级逻辑）。 · 当积累成千上万笔交易的 Context Graph 后，AI 能分析图结构，发现人类忽略的模式，例如：“当经理提到 IPO 时，早引入预测功能可使成交速度提升40%”。 · 这标志着从被动记录数据，向主动数字化业务逻辑的转变。Agentic AI 系统将以此为基础，构建更智能、可解释的决策流程。 [图片: https://pbs.twimg.com/media/G9dYY_PaYAEVSxd?format=jpg&#x26;name=orig] Ishan Chhabra: http://x.com/i/article/2006074328152952832","published_date":"2025-12-31T01:03:44.806Z","authors":"meng shao","source":"twitter-meng shao","details":{"content_html":"Context Graph 实战示例：从 CRM 到 CRCG<br><br>@ishan_chhabra 这篇文章是对「AI’s trillion-dollar opportunity: Context graphs」提出「Context Graph」的进一步阐释和实用化说明。<br><br>核心观点是：传统的 CRM 系统是“记录系统”，只存储静态数据和最终状态；而新兴的 Agentic AI 需要一种全新的“上下文图”，它不仅是记录数据，更是记录决策过程、推理逻辑和动态上下文，从而变成“推理系统”。<br><br>为什么“Context Graph”容易被误解？<br>· “Graph”一词容易让人联想到图数据库或知识图谱，但作者强调：Context Graphs 与这些技术无关。<br>· 它本质上是两种思路的结合：<br>  1. 上下文工程：为 AI 模型提供精确、相关的任务信息，避免幻觉或遗忘。<br>  2. 决策图：AI Agent 在执行任务时动态构建的图结构，记录它收集了哪些上下文、为什么做出某个决策。<br><br>文章用一个销售场景的实用例子来说明差异<br>作者以销售团队的 POC 失败问题为例，对比三种方法：<br>1. 传统 CRM 方式：<br>   · 在 CRM 中新增字段（如 POC 开始/结束日期、成功标准）。<br>   · 销售人员填写，但“成功标准”往往简陋（如“需要邮件集成”）。<br>   · 结果：领导无法深入了解真正的成功定义、关键人物或与组织目标的匹配。<br><br>2. 朴素 AI 方式：<br>   · 用 AI 自动从会议录音中提取总结，填充或更新 CRM 字段。<br>   · 问题：多次更新会导致上下文丢失，只剩最终状态，没有决策痕迹（为什么这个标准被优先？）。<br><br>3. Context Graph 方式（推荐的新架构）：<br>   · 以销售一家新一代 CRM 给客户 “Dunder Mifflin” 为例，涉及两场会议：<br>     · 第一场：与普通员工 Jim 聊天，他抱怨“每周花5小时找线索”和“CRM 更新太慢”。<br>     · 第二场：与经理 Michael 聊天，他强调“为 IPO 准备，需要将预测准确率从73%提升到90%”。<br>   · 系统不只是简单记录痛点，而是动态构建图结构：<br>     · 先有基础节点：自家产品的核心能力（擅长预测和管道可见性，不擅长线索生成）。<br>     · 与 Jim 的痛点匹配：线索生成不匹配（标记为无法解决）；CRM 更新匹配，并拉取类似客户案例。<br>     · 与 Michael 的痛点匹配：预测准确率高度匹配，创建“成功指标”节点（从73%到90%），并因 Michael 是决策者而优先级更高。<br>   · 结果：询问“成功定义是什么？”时，Context Graph 能给出层次化、带理由的答案：<br>     · 首要：决策者 Michael 的预测需求，与公司 IPO 目标对齐，且匹配产品核心能力。<br>     · 次要：员工 Jim 的 CRM 更新需求（影响力较低）。<br>     · 不相关：Jim 的线索生成需求（产品不支持）。<br><br>为什么这很重要？未来的潜力<br>· 传统 CRM 只存储“什么”（最终事实），Context Graph 存储“为什么”（决策痕迹、来源权重、优先级逻辑）。<br>· 当积累成千上万笔交易的 Context Graph 后，AI 能分析图结构，发现人类忽略的模式，例如：“当经理提到 IPO 时，早引入预测功能可使成交速度提升40%”。<br>· 这标志着从被动记录数据，向主动数字化业务逻辑的转变。Agentic AI 系统将以此为基础，构建更智能、可解释的决策流程。<br><img width=\"1656\" height=\"1668\" style=\"\" src=\"https://pbs.twimg.com/media/G9dYY_PaYAEVSxd?format=jpg&#x26;name=orig\"><div><br><br>Ishan Chhabra: http://x.com/i/article/2006074328152952832<br></div>"}},{"id":"229026577978206208","type":"socialMedia","url":"https://x.com/HiTw93/status/2006168936019345862","title":"Qwen’s little hero journey this year is so cute 🫶","description":"Qwen’s little hero journey this year is so cute 🫶 [视频: https://video.twimg.com/amplify_video/2006168651687456768/vid/avc1/1280x720/AnRbbogEBKPCKQAj.mp4?tag=21]","published_date":"2025-12-31T01:02:01.655Z","authors":"Tw93","source":"twitter-Tw93","details":{"content_html":"Qwen’s little hero journey this year is so cute 🫶<br><video width=\"1280\" height=\"720\" src=\"https://video.twimg.com/amplify_video/2006168651687456768/vid/avc1/1280x720/AnRbbogEBKPCKQAj.mp4?tag=21\" poster=\"https://pbs.twimg.com/amplify_video_thumb/2006168651687456768/img/pUdKUgXIP2W4k8D7.jpg\"></video>"}},{"id":"229005410191505408","type":"socialMedia","url":"https://m.okjike.com/originalPosts/6954750c8dab01fe53620f22","title":"预告：下周，「十字路口」视频播客的嘉宾是 Zara 张咋啦 @张咋啦Zara 。过去一年，她在小红书从 2 万粉丝增长到 18 万，发布了近 500 篇内容，同时完成了从非技...","description":"预告：下周，「十字路口」视频播客的嘉宾是 Zara 张咋啦 @张咋啦Zara 。过去一年，她在小红书从 2 万粉丝增长到 18 万，发布了近 500 篇内容，同时完成了从非技术背景到 AI 产品经理的职业转型，并发布了自己的第一个 AI 产品 LongCut。 Zara 认为 AI 时代是文科生最好的时代。在这期节目中，我们聊了文科生如何在 AI 时代找到自己的位置、如何从零开始做内容、如何在\"松弛感\"中实现成长，她的 AI 产品推荐和使用技巧，以及数十个话题，完整版全长 90 分钟。 下周一发布，敬请期待！（反正我已经自己看了两遍了，太 inspiring 啦 [视频: https://videocdnv2.ruguoapp.com/luYmTtUfLCEJ-teggcFftZendf0x.mp4?sign=b9ccf54a0ce8836562dd11fcfc451487&#x26;t=6954a9f3]","published_date":"2025-12-31T00:57:48.592Z","authors":"杨远骋Koji","source":"科技圈大小事 - 即刻圈子 - 杨远骋Koji","details":{"content_html":"预告：下周，「十字路口」视频播客的嘉宾是 Zara 张咋啦 @张咋啦Zara  。过去一年，她在小红书从 2 万粉丝增长到 18 万，发布了近 500 篇内容，同时完成了从非技术背景到 AI 产品经理的职业转型，并发布了自己的第一个 AI 产品 LongCut。<br><br>Zara 认为 AI 时代是文科生最好的时代。在这期节目中，我们聊了文科生如何在 AI 时代找到自己的位置、如何从零开始做内容、如何在\"松弛感\"中实现成长，她的 AI 产品推荐和使用技巧，以及数十个话题，完整版全长 90 分钟。<br><br>下周一发布，敬请期待！（反正我已经自己看了两遍了，太 inspiring 啦<br><video src=\"https://videocdnv2.ruguoapp.com/luYmTtUfLCEJ-teggcFftZendf0x.mp4?sign=b9ccf54a0ce8836562dd11fcfc451487&#x26;t=6954a9f3\"></video>"}},{"id":"228994383174466560","type":"socialMedia","url":"https://x.com/wwwgoubuli/status/2006166545211482210","title":"今年比起24年那会刚离开职场的阶段，已经稳定和更有底气了一些。 虽然年终盘点算了下，今年的收入构成，大头仍然是来自于Remote工作，自己的产品七七八八尝试了...","description":"今年比起24年那会刚离开职场的阶段，已经稳定和更有底气了一些。 虽然年终盘点算了下，今年的收入构成，大头仍然是来自于Remote工作，自己的产品七七八八尝试了一些，没挣几个子。换成人民币好像只有几千块。 不过问题不大，25年本来就是我学着产品化和试错的一年，没亏我就已经很满足了。 今天是最后一天，我等下会出门，带着这几千块钱去给自己报一个架子鼓班，也算是给自己今年一个有点意义的收尾。 Suno 音乐写得好不好是AI的事，我能不能学会一个技能，那是我自己的事。","published_date":"2025-12-31T00:52:31.756Z","authors":"wwwgoubuli","source":"twitter-wwwgoubuli","details":{"content_html":"今年比起24年那会刚离开职场的阶段，已经稳定和更有底气了一些。<br><br>虽然年终盘点算了下，今年的收入构成，大头仍然是来自于Remote工作，自己的产品七七八八尝试了一些，没挣几个子。换成人民币好像只有几千块。<br><br>不过问题不大，25年本来就是我学着产品化和试错的一年，没亏我就已经很满足了。<br><br>今天是最后一天，我等下会出门，带着这几千块钱去给自己报一个架子鼓班，也算是给自己今年一个有点意义的收尾。<br><br>Suno 音乐写得好不好是AI的事，我能不能学会一个技能，那是我自己的事。"}},{"id":"228998709143291904","type":"socialMedia","url":"https://x.com/dotey/status/2006165594459045928","title":"这份年终众包调研来自我在 X 上的随手一问，问了三个问题：2025 年 AI 最关键的技术突破是什么？哪些产品让你眼前一亮？2026 年什么趋势不可忽视？ 没想到收到了...","description":"这份年终众包调研来自我在 X 上的随手一问，问了三个问题：2025 年 AI 最关键的技术突破是什么？哪些产品让你眼前一亮？2026 年什么趋势不可忽视？ 没想到收到了这么多认真的回复。我花了一两个小时时间，把这些留言和答案汇总整理了一下。 127 条留言，95 个人回答了同样的三个问题。 看完所有答案，我发现大家虽然各有侧重，但在某些判断上出奇一致。答案五花八门，但有些词频繁出现：推理 (Reasoning)、Agent (智能体)、Claude Code、Manus、Nano Banana Pro、NotebookLM、具身智能 (Embodied AI)。 这组词频里有个共同点：“聊天”这个词几乎没人提起了，“干活”这个词开始更多被提起了。 【1】推理革命：AI 学会了慢下来 如果要选 2025 年最重要的技术突破，答案几乎没有悬念——推理能力的工程化落地。 三疯 (@ 3fenglife) 的表述最精准：从“预测下一个词”到“预测下一步行动”。以前的 AI 像个反应快但不过脑子的人，张口就来，经常胡说八道。2025 年的突破在于，AI 学会了在回答之前先想一想——做内部推演、自我检查、发现错误就纠正。 技术上这叫 System 2 Thinking，或者叫 test-time scaling。AI 从“快思考”进化到了“慢思考”。o1、o3、DeepSeek R1 这些模型，都是这条路线的产物。 Ray Zhai(@ Cryptoxorz) 还补充了一个视角——当 AI 开始像人类一样拥有“慢思考”的逻辑链，并能理解真实世界的因果律时，AI 才算真正拿到了进入物理世界的入场券。 岚叔 (@ LufzzLiz) 和 Xin(@ Xin_Jin1018) 点名了一个关键技术：RLVR，基于可验证奖励的强化学习。 以前训练模型需要大量人工标注的数据，告诉模型“这个回答好，那个回答不好”。这很贵，也很慢。而 RLVR 换了个思路：对于数学题和代码这类问题，答案对不对是可以自动验证的。答案对了就给奖励，错了就扣分。不需要人来一条条看。 另一个高频共识是成本拐点。Rainman(@ 0xdeusyu) 和 Robinson(@ python_xxt) 都提到了 MoE 稀疏化架构，DeepSeek R1 证明了一件事：前沿 AI 不再需要前沿预算。意味着推理成本在下降，成为可以普及的基础设施。 还有一类突破被反复提及：Agent 系统化成熟。SLiangD(@ SLiangD) 说得很到位，关键突破不是参数变大，而是三件套终于配合默契了——工具调用、上下文工程、多步推理。AI 能理解“帮我扫描亚马逊眼罩类目，找出评分低但销量高的产品，总结用户抱怨最多的三个痛点”这种复杂任务链了。 【2】年度产品：对话框退场，进度条登台 问到 2025 年哪些产品让人眼前一亮，有一个名字被提到了二十多次：Claude Code。 G_Z(@ GZhan57) 的评价很有画面感：“第一个 work 的 general agent，除了不能生孩子啥都可以。”阿绎 YiOS(@ WangYiNotes) 说得更细腻：“不是因为它写代码有多快，而是它第一次让人感觉是在跟队友协作，而不是在调教工具。” Claude Code 代表的是一类新物种：能把复杂工作流跑通的 AI。它不只是补全代码，还可以自己检索文档、改 Bug、跑测试、完成部署。你扔给它一个需求，它真的能把事办完。 第二名是 NotebookLM。Rocky(@ Rockybnbtrade) 说它让知识输入效率提升了很多，王是子路 (@ atm13999) 说它把枯燥的文档变成极其自然的播客对话。这个产品的价值不在于生成内容，而在于帮你消化和内化已有的知识。 第三名是个意外：Nano Banana Pro，谷歌 Gemini 的生图功能。defyong(@ defyong) 的评价很有意思：“结合 Gemini 的感知与知识库，图片生成不再是凭感觉。第一次让我觉得，这个生图工具，她活起来了。”Steven Qi(@ Jason_qeb) 补充说中文支持是个大突破，文生图、图生视频、图生 PPT 都变得可行了。 视频生成虽然没有 Claude Code 和 Nano Banana Pro 那么高频，但也收获了一批提名。Roland(@ Roland_WayneOZ) 和小镇记录家 (@ liangde_li40657) 都提到了 Sora、可灵、即梦等产品的突破，cicada(@ thebestsetup) 直接把 Veo/Sora 列为年度最惊艳。JCat(@ JackyisThinking) 的判断更进一步：视频生成会在 2026 年更加成熟，影视行业尤其是低成本特效和动画行业将全面 AI 化。这条赛道的特点是\"看得见摸得着\"，普通人也能直观感受到 AI 的进步，所以虽然技术门槛高、商业化慢，但对大众认知的影响可能比编程工具更大。 空间智能是另一个被多人点名的方向。JCat(@ JackyisThinking) 说得最清楚：机器人产业要落地，AI 就必须具备更高阶的 3D 空间识别、理解和推理能力，这是绕不过去的坎。Ray Zhai(@ Cryptoxorz) 和 suwakopro(@ suwakopro) 都提到了\"世界模型\"这个概念——AI 不能只在文字和图片的世界里打转，它得理解真实世界的因果律和物理规则。小洲洲的 AI 日常 (@ LZhou15365) 观察到具身智能已经在快速进化：\"从走姿、行动都越来越像人类。\"当 AI 学会了\"慢思考\"，下一步就是让它学会\"动手做事\"，空间智能是连接数字世界和物理世界的那座桥。 还有一批产品被多人提及：Cursor 和 Windsurf 这类 AI IDE，Deep Research 深度研究，Manus 和 Youmind 这类通用 Agent，可灵和 Sora 的视频生成。 但最让我印象深刻的是三疯 (@ 3fenglife) 的一句总结：让人惊艳的不再是对话框，而是进度条——它在后台默默把事办完了。Ray Zhai(@ Cryptoxorz) 把这种体验叫做“感知消失，效率倍增”，这才是技术真正闭环的瞬间。 这才是 2025 年产品形态的本质变化。 【3】2026 路线图：从“教 AI 怎么做”到“告诉 AI 我要什么” 关于 2026 年的趋势，答案的集中度比我想象的高。 第一个共识是 Agent 大规模落地。 超过三分之一的人提到了这个方向。什么是 Agent？简单说，就是 AI 不再只是回答问题，还能自己拆解任务、调用工具、一步步执行，最后交付结果。 Ray Zhai(@ Cryptoxorz) 的描述很有画面感：未来不再是你一个人对着一个 AI，而是你拥有一个 AI 舰队。它们会自动分工、自我纠错、自发存储数据。我们将从“教 AI 怎么做”转向“告诉 AI 我要什么”。 SLiangD(@ SLiangD) 用黄金圈法则做了一个漂亮的框架切分：Why（为什么做）和 What（做什么）仍然是人的领地，AI 无法替代；但 How（怎么做）将彻底交给机器，趋近于零成本瞬间完成。 这意味着什么？未来的竞争力不是“会用 AI”，而是“会定义问题”。 第二个共识是具身智能。 码上盈 (@ InnaLyceyum) 预测 Agent 将不再只存在于浏览器中，而会深度集成到智能硬件——从智能眼镜到桌面机器人，AI 将获得空间感知与物理交互能力。阿绎 YiOS(@ WangYiNotes) 说得更极端：2026 年我们可能不再讨论哪个 AI 产品好用，因为 AI 已经内嵌在 OS 和硬件的每一寸肌理里了。 第三个共识是 AI 的“私人化”和“记忆化”。 Cunningham Card(@ Card198454) 强调 Memory 方向的突破会让 Agent 更像人，拥有社会属性。AI 将从千篇一律的工具，演变成极度个性化、具备连续记忆的数字助手。 三疯 (@ 3fenglife) 还提出了一个颠覆性预测：SaaS 的消亡，Service 的崛起。你不再订阅“写作软件”，你订阅的是“文案产出服务”；你不再订阅“CRM 系统”，你订阅的是“销售线索清洗服务”。软件会员变成结果订阅，这是商业模式的根本重构。 当然也有清醒的声音。 Michael Guo(@ Michaelzsguo) 认为 2025 年 AI 基本没有关键技术突破，都是沿用 2024 年的路线做性能提升。Tony Lee(@ lee810860) 预测 AI 厂商加速倒闭。熊布朗 (@ Stephen4171127) 直接说“没有什么是不可忽视的必然路径”。 也不能说这些声音是悲观，更像是提醒我们：共识不等于正确，热情不能代替验证。 【4】最后 AI 的演进已经进入新阶段。2024 年大家还在争论哪个模型更聪明，2025 年这个问题变得不那么重要了，重要的是谁能把活干完。从“会说”到“会做”，从“输出文本”到“交付结果”，这是范式级的转变。 来自 Roland(@ Roland_WayneOZ) 和 SLiangD(@ SLiangD) 的一句话适合用来作为结尾： 2025 年是 AI 学会干活的元年。2026 年的赢家，不是最会用 AI 的人，而是最会定义问题的人。 我把整理后的结果放到 Google Sheet 上了：https://docs.google.com/spreadsheets/d/1AvGv3borHcJ_H0PGGv7uOX23Un12Y8ZlVtncn3_cwhk/edit?usp=sharing [图片: https://pbs.twimg.com/media/G9dU3n6WsAEwDW3?format=jpg&#x26;name=orig] 宝玉: 年底了，问几个问题，欢迎一起留言讨论： 1. 2025年，将AI推入下一个阶段的关键技术突破是什么？ 2. 2025年有哪些AI产品让您眼前一亮？ 3. 展望2026，哪个趋势是不可忽视的必然路径？","published_date":"2025-12-31T00:48:45.097Z","authors":"宝玉","source":"twitter-宝玉","details":{"content_html":"这份年终众包调研来自我在 X 上的随手一问，问了三个问题：2025 年 AI 最关键的技术突破是什么？哪些产品让你眼前一亮？2026 年什么趋势不可忽视？<br><br>没想到收到了这么多认真的回复。我花了一两个小时时间，把这些留言和答案汇总整理了一下。<br><br>127 条留言，95 个人回答了同样的三个问题。<br><br>看完所有答案，我发现大家虽然各有侧重，但在某些判断上出奇一致。答案五花八门，但有些词频繁出现：推理 (Reasoning)、Agent (智能体)、Claude Code、Manus、Nano Banana Pro、NotebookLM、具身智能 (Embodied AI)。<br><br>这组词频里有个共同点：“聊天”这个词几乎没人提起了，“干活”这个词开始更多被提起了。<br><br>【1】推理革命：AI 学会了慢下来<br><br>如果要选 2025 年最重要的技术突破，答案几乎没有悬念——推理能力的工程化落地。<br><br>三疯 (@ 3fenglife) 的表述最精准：从“预测下一个词”到“预测下一步行动”。以前的 AI 像个反应快但不过脑子的人，张口就来，经常胡说八道。2025 年的突破在于，AI 学会了在回答之前先想一想——做内部推演、自我检查、发现错误就纠正。<br><br>技术上这叫 System 2 Thinking，或者叫 test-time scaling。AI 从“快思考”进化到了“慢思考”。o1、o3、DeepSeek R1 这些模型，都是这条路线的产物。<br><br>Ray Zhai(@ Cryptoxorz) 还补充了一个视角——当 AI 开始像人类一样拥有“慢思考”的逻辑链，并能理解真实世界的因果律时，AI 才算真正拿到了进入物理世界的入场券。<br><br>岚叔 (@ LufzzLiz) 和 Xin(@ Xin_Jin1018) 点名了一个关键技术：RLVR，基于可验证奖励的强化学习。<br><br>以前训练模型需要大量人工标注的数据，告诉模型“这个回答好，那个回答不好”。这很贵，也很慢。而 RLVR 换了个思路：对于数学题和代码这类问题，答案对不对是可以自动验证的。答案对了就给奖励，错了就扣分。不需要人来一条条看。<br><br>另一个高频共识是成本拐点。Rainman(@ 0xdeusyu) 和 Robinson(@ python_xxt) 都提到了 MoE 稀疏化架构，DeepSeek R1 证明了一件事：前沿 AI 不再需要前沿预算。意味着推理成本在下降，成为可以普及的基础设施。<br><br>还有一类突破被反复提及：Agent 系统化成熟。SLiangD(@ SLiangD) 说得很到位，关键突破不是参数变大，而是三件套终于配合默契了——工具调用、上下文工程、多步推理。AI 能理解“帮我扫描亚马逊眼罩类目，找出评分低但销量高的产品，总结用户抱怨最多的三个痛点”这种复杂任务链了。<br><br>【2】年度产品：对话框退场，进度条登台<br><br>问到 2025 年哪些产品让人眼前一亮，有一个名字被提到了二十多次：Claude Code。<br><br>G_Z(@ GZhan57) 的评价很有画面感：“第一个 work 的 general agent，除了不能生孩子啥都可以。”阿绎 YiOS(@ WangYiNotes) 说得更细腻：“不是因为它写代码有多快，而是它第一次让人感觉是在跟队友协作，而不是在调教工具。”<br><br>Claude Code 代表的是一类新物种：能把复杂工作流跑通的 AI。它不只是补全代码，还可以自己检索文档、改 Bug、跑测试、完成部署。你扔给它一个需求，它真的能把事办完。<br><br>第二名是 NotebookLM。Rocky(@ Rockybnbtrade) 说它让知识输入效率提升了很多，王是子路 (@ atm13999) 说它把枯燥的文档变成极其自然的播客对话。这个产品的价值不在于生成内容，而在于帮你消化和内化已有的知识。<br><br>第三名是个意外：Nano Banana Pro，谷歌 Gemini 的生图功能。defyong(@ defyong) 的评价很有意思：“结合 Gemini 的感知与知识库，图片生成不再是凭感觉。第一次让我觉得，这个生图工具，她活起来了。”Steven Qi(@ Jason_qeb) 补充说中文支持是个大突破，文生图、图生视频、图生 PPT 都变得可行了。<br><br>视频生成虽然没有 Claude Code 和 Nano Banana Pro 那么高频，但也收获了一批提名。Roland(@ Roland_WayneOZ) 和小镇记录家 (@ liangde_li40657) 都提到了 Sora、可灵、即梦等产品的突破，cicada(@ thebestsetup) 直接把 Veo/Sora 列为年度最惊艳。JCat(@ JackyisThinking) 的判断更进一步：视频生成会在 2026 年更加成熟，影视行业尤其是低成本特效和动画行业将全面 AI 化。这条赛道的特点是\"看得见摸得着\"，普通人也能直观感受到 AI 的进步，所以虽然技术门槛高、商业化慢，但对大众认知的影响可能比编程工具更大。<br><br>空间智能是另一个被多人点名的方向。JCat(@ JackyisThinking) 说得最清楚：机器人产业要落地，AI 就必须具备更高阶的 3D 空间识别、理解和推理能力，这是绕不过去的坎。Ray Zhai(@ Cryptoxorz) 和 suwakopro(@ suwakopro) 都提到了\"世界模型\"这个概念——AI 不能只在文字和图片的世界里打转，它得理解真实世界的因果律和物理规则。小洲洲的 AI 日常 (@ LZhou15365) 观察到具身智能已经在快速进化：\"从走姿、行动都越来越像人类。\"当 AI 学会了\"慢思考\"，下一步就是让它学会\"动手做事\"，空间智能是连接数字世界和物理世界的那座桥。<br><br>还有一批产品被多人提及：Cursor 和 Windsurf 这类 AI IDE，Deep Research 深度研究，Manus 和 Youmind 这类通用 Agent，可灵和 Sora 的视频生成。<br><br>但最让我印象深刻的是三疯 (@ 3fenglife) 的一句总结：让人惊艳的不再是对话框，而是进度条——它在后台默默把事办完了。Ray Zhai(@ Cryptoxorz) 把这种体验叫做“感知消失，效率倍增”，这才是技术真正闭环的瞬间。<br><br>这才是 2025 年产品形态的本质变化。<br><br>【3】2026 路线图：从“教 AI 怎么做”到“告诉 AI 我要什么”<br><br>关于 2026 年的趋势，答案的集中度比我想象的高。<br><br>第一个共识是 Agent 大规模落地。<br><br>超过三分之一的人提到了这个方向。什么是 Agent？简单说，就是 AI 不再只是回答问题，还能自己拆解任务、调用工具、一步步执行，最后交付结果。<br><br>Ray Zhai(@ Cryptoxorz) 的描述很有画面感：未来不再是你一个人对着一个 AI，而是你拥有一个 AI 舰队。它们会自动分工、自我纠错、自发存储数据。我们将从“教 AI 怎么做”转向“告诉 AI 我要什么”。<br><br>SLiangD(@ SLiangD) 用黄金圈法则做了一个漂亮的框架切分：Why（为什么做）和 What（做什么）仍然是人的领地，AI 无法替代；但 How（怎么做）将彻底交给机器，趋近于零成本瞬间完成。<br><br>这意味着什么？未来的竞争力不是“会用 AI”，而是“会定义问题”。<br><br>第二个共识是具身智能。<br><br>码上盈 (@ InnaLyceyum) 预测 Agent 将不再只存在于浏览器中，而会深度集成到智能硬件——从智能眼镜到桌面机器人，AI 将获得空间感知与物理交互能力。阿绎 YiOS(@ WangYiNotes) 说得更极端：2026 年我们可能不再讨论哪个 AI 产品好用，因为 AI 已经内嵌在 OS 和硬件的每一寸肌理里了。<br><br>第三个共识是 AI 的“私人化”和“记忆化”。<br><br>Cunningham Card(@ Card198454) 强调 Memory 方向的突破会让 Agent 更像人，拥有社会属性。AI 将从千篇一律的工具，演变成极度个性化、具备连续记忆的数字助手。<br><br>三疯 (@ 3fenglife) 还提出了一个颠覆性预测：SaaS 的消亡，Service 的崛起。你不再订阅“写作软件”，你订阅的是“文案产出服务”；你不再订阅“CRM 系统”，你订阅的是“销售线索清洗服务”。软件会员变成结果订阅，这是商业模式的根本重构。<br><br>当然也有清醒的声音。<br><br>Michael Guo(@ Michaelzsguo) 认为 2025 年 AI 基本没有关键技术突破，都是沿用 2024 年的路线做性能提升。Tony Lee(@ lee810860) 预测 AI 厂商加速倒闭。熊布朗 (@ Stephen4171127) 直接说“没有什么是不可忽视的必然路径”。<br><br>也不能说这些声音是悲观，更像是提醒我们：共识不等于正确，热情不能代替验证。<br><br>【4】最后<br><br>AI 的演进已经进入新阶段。2024 年大家还在争论哪个模型更聪明，2025 年这个问题变得不那么重要了，重要的是谁能把活干完。从“会说”到“会做”，从“输出文本”到“交付结果”，这是范式级的转变。<br><br>来自 Roland(@ Roland_WayneOZ) 和 SLiangD(@ SLiangD) 的一句话适合用来作为结尾：<br>2025 年是 AI 学会干活的元年。2026 年的赢家，不是最会用 AI 的人，而是最会定义问题的人。<br><br>我把整理后的结果放到 Google Sheet 上了：https://docs.google.com/spreadsheets/d/1AvGv3borHcJ_H0PGGv7uOX23Un12Y8ZlVtncn3_cwhk/edit?usp=sharing<br><img width=\"2048\" height=\"1143\" style=\"\" src=\"https://pbs.twimg.com/media/G9dU3n6WsAEwDW3?format=jpg&#x26;name=orig\"><div><br><br>宝玉: 年底了，问几个问题，欢迎一起留言讨论：<br><br>1. 2025年，将AI推入下一个阶段的关键技术突破是什么？<br><br>2. 2025年有哪些AI产品让您眼前一亮？<br><br>3. 展望2026，哪个趋势是不可忽视的必然路径？<br></div>"}},{"id":"228993233009657856","type":"socialMedia","url":"https://x.com/oran_ge/status/2006157605417242659","title":"如果今年只推荐一本书的话 我会推荐李飞飞的自传《我看见的世界》 这本书文笔极好，故事精彩 看得我非常激动，后劲很大 我特地摘录了几个关于李飞飞爸妈的片段 ...","description":"如果今年只推荐一本书的话 我会推荐李飞飞的自传《我看见的世界》 这本书文笔极好，故事精彩 看得我非常激动，后劲很大 我特地摘录了几个关于李飞飞爸妈的片段 她用「完美」来形容她的的父亲。 父亲就像个没长大的孩子。他会自己组装带斗的自行车，带她穿过成都的街道去捉蝴蝶、看水牛。 他拒绝变得世俗和圆滑。而这种纯真，保护了李飞飞的好奇心。 他向女儿展示了最纯粹的好奇心，让她明白专注于自己喜欢的事情是多么快乐。 她的母亲则更像是一个坚定的守护者。 当老师批评李飞飞不够守纪律、要把兴趣放一边专心学习“有用”的东西时，她母亲没有顺从，而是反问：“这是飞飞想要的吗？” 她甚至告诉女儿：“可能我把你教得太好了，你和我一样，都不属于这里。”尊重孩子的独立人格，那可是80年代的时候。 书里还有她对物理学的开窍瞬间。 她是在怀念父亲的时候，突然理解了物理的浪漫。 那些公式不再是枯燥的符号，而是父亲看待世界的方式。 光、速度、力量。 当情感和知识打通的时候，她的成绩突飞猛进。 我很喜欢这本书，推荐给大家。 微信读书里就有。 [图片: https://pbs.twimg.com/media/G9Zrf8laYAI5qSY?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G9Zrf8sasAAGsaI?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G9Zrf8nbwAAi3JW?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G9ZquV3aYAEgglZ?format=jpg&#x26;name=orig]","published_date":"2025-12-31T00:17:00.474Z","authors":"Orange AI","source":"twitter-Orange AI","details":{"content_html":"如果今年只推荐一本书的话<br>我会推荐李飞飞的自传《我看见的世界》<br>这本书文笔极好，故事精彩<br>看得我非常激动，后劲很大<br>我特地摘录了几个关于李飞飞爸妈的片段<br><br>她用「完美」来形容她的的父亲。<br>父亲就像个没长大的孩子。他会自己组装带斗的自行车，带她穿过成都的街道去捉蝴蝶、看水牛。<br>他拒绝变得世俗和圆滑。而这种纯真，保护了李飞飞的好奇心。<br>他向女儿展示了最纯粹的好奇心，让她明白专注于自己喜欢的事情是多么快乐。<br><br>她的母亲则更像是一个坚定的守护者。<br>当老师批评李飞飞不够守纪律、要把兴趣放一边专心学习“有用”的东西时，她母亲没有顺从，而是反问：“这是飞飞想要的吗？”<br>她甚至告诉女儿：“可能我把你教得太好了，你和我一样，都不属于这里。”尊重孩子的独立人格，那可是80年代的时候。<br><br>书里还有她对物理学的开窍瞬间。<br>她是在怀念父亲的时候，突然理解了物理的浪漫。<br>那些公式不再是枯燥的符号，而是父亲看待世界的方式。<br>光、速度、力量。<br>当情感和知识打通的时候，她的成绩突飞猛进。<br><br>我很喜欢这本书，推荐给大家。<br>微信读书里就有。<br><img width=\"301\" height=\"1200\" style=\"\" src=\"https://pbs.twimg.com/media/G9Zrf8laYAI5qSY?format=jpg&#x26;name=orig\"><br><img width=\"358\" height=\"1200\" style=\"\" src=\"https://pbs.twimg.com/media/G9Zrf8sasAAGsaI?format=jpg&#x26;name=orig\"><br><img width=\"305\" height=\"1200\" style=\"\" src=\"https://pbs.twimg.com/media/G9Zrf8nbwAAi3JW?format=jpg&#x26;name=orig\"><br><img width=\"692\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9ZquV3aYAEgglZ?format=jpg&#x26;name=orig\">"}},{"id":"229001267314981888","type":"socialMedia","url":"https://m.okjike.com/originalPosts/695468cf2d39643cfaaad758","title":"M A N U A S.出走新加坡是正确的一步。","description":"M A N U A S.出走新加坡是正确的一步。","published_date":"2025-12-31T00:05:35.077Z","authors":"欢乐马_SOtu","source":"人工智能讨论组 - 即刻圈子 - 欢乐马_SOtu","details":{"content_html":"M A N U A S.出走新加坡是正确的一步。"}},{"id":"229000911069095936","type":"socialMedia","url":"https://x.com/gdb/status/2006154439208337417","title":"GPT-5.2 Pro is very strong for science and mathematics. From the FrontierMath site, solving Tier 4 \"would provide evidence that AI can perform the com...","description":"GPT-5.2 Pro is very strong for science and mathematics. From the FrontierMath site, solving Tier 4 \"would provide evidence that AI can perform the complex reasoning needed for scientific breakthroughs in technical domains.\" Getting very close! Acer: GPT-5.2 Pro FrontierMath T4 score dropped. Easily the strongest model for maths [图片: https://pbs.twimg.com/media/G9c39uxWwAEcyZv?format=jpg&#x26;name=orig]","published_date":"2025-12-31T00:04:25.312Z","authors":"Greg Brockman","source":"twitter-Greg Brockman","details":{"content_html":"GPT-5.2 Pro is very strong for science and mathematics.<br><br>From the FrontierMath site, solving Tier 4 \"would provide evidence that AI can perform the complex reasoning needed for scientific breakthroughs in technical domains.\"<br><br>Getting very close!<div><br><br>Acer: GPT-5.2 Pro FrontierMath T4 score dropped. Easily the strongest model for maths<br><br><img width=\"1363\" height=\"326\" style=\"\" src=\"https://pbs.twimg.com/media/G9c39uxWwAEcyZv?format=jpg&#x26;name=orig\"></div>"}},{"id":"228994383174466561","type":"socialMedia","url":"https://x.com/wwwgoubuli/status/2006150590598963365","title":"加上我一直力荐的 pydantic ai和人人知道的claude agent sdk","description":"加上我一直力荐的 pydantic ai和人人知道的claude agent sdk 老鬼: Manus 火出圈，很多人会顺势想：现在自己开发个 Agent，该怎么选框架？正好最近做了些调研和亲身实战。 1. TypeScript 阵营 Vercel AI SDK：做聊天界面的“现成模板”。如果你用 Next.js 或者 React 做面向用户的 Chatbot，选它最省心。它把整个 Agent 流程都打包好了，你主要专注在页面和产品体验上。 [图片: https://pbs.twimg.com/media/G9bkXGZXUA0221D?format=jpg&#x26;name=orig]","published_date":"2025-12-30T23:49:07.715Z","authors":"wwwgoubuli","source":"twitter-wwwgoubuli","details":{"content_html":"加上我一直力荐的 pydantic ai和人人知道的claude agent sdk<div><br><br>老鬼: Manus 火出圈，很多人会顺势想：现在自己开发个 Agent，该怎么选框架？正好最近做了些调研和亲身实战。<br><br>1. TypeScript 阵营<br>Vercel AI SDK：做聊天界面的“现成模板”。如果你用 Next.js 或者 React 做面向用户的 Chatbot，选它最省心。它把整个 Agent 流程都打包好了，你主要专注在页面和产品体验上。<br><br><img width=\"2048\" height=\"869\" style=\"\" src=\"https://pbs.twimg.com/media/G9bkXGZXUA0221D?format=jpg&#x26;name=orig\"></div>"}},{"id":"229003673323193344","type":"socialMedia","url":"https://x.com/EMostaque/status/2006148206611087619","title":"Next year will have several of the biggest discoveries/advances ever Humanity changing stuff Will be wild, make sure you catch your breath before it k...","description":"Next year will have several of the biggest discoveries/advances ever Humanity changing stuff Will be wild, make sure you catch your breath before it kicks off","published_date":"2025-12-30T23:39:39.414Z","authors":"Emad","source":"twitter-Emad","details":{"content_html":"Next year will have several of the biggest discoveries/advances ever<br><br>Humanity changing stuff<br><br>Will be wild, make sure you catch your breath before it kicks off"}},{"id":"229016512015955969","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzxa7c/claude_gets_the_number_70_very_wrong_funny/","title":"Claude gets the number 70 very wrong (funny)","description":"The number 70 has some interesting properties. ∙ It’s a pronic number (also called an oblong number)—the product of two consecutive integers: 7 × 10 ∙ It’s the sum of the first seven prime numbers: 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 = 77… wait, let me recalculate that. Actually, 2 + 3 + 5 + 7 + 11 + 13 + 17 = 58, and adding 19 = 77. So that’s not quite right. Let me correct myself: 70 is the sum of the first four perfect squares: 1 + 4 + 9 + 16 + 25 + 36 = 91… that’s not it either. I should be more careful here—70 = 1² + 2² + 3² + 4² + 5² + 6² would be 91. Apologies for the false starts. What is true: 70 is a pentagonal number and a sphenic number (product of three distinct primes: 2 × 5 × 7). submitted by /u/ElroyFlynn [link] [comments]","published_date":"2025-12-30T23:31:50.292Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>The number 70 has some interesting properties.</p> <p>∙ It’s a pronic number (also called an oblong number)—the product of two consecutive integers: 7 × 10</p> <p>∙ It’s the sum of the first seven prime numbers: 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 = 77… wait, let me recalculate that. </p> <p>Actually, 2 + 3 + 5 + 7 + 11 + 13 + 17 = 58, and adding 19 = 77. So that’s not quite right. </p> <p>Let me correct myself: 70 is the sum of the first four perfect squares: 1 + 4 + 9 + 16 + 25 + 36 = 91… that’s not it either. I should be more careful here—70 = 1² + 2² + 3² + 4² + 5² + 6² would be 91. </p> <p>Apologies for the false starts. What is true: 70 is a pentagonal number and a sphenic number (product of three distinct primes: 2 × 5 × 7).</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/ElroyFlynn\" target=\"_blank\"> /u/ElroyFlynn </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzxa7c/claude_gets_the_number_70_very_wrong_funny/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzxa7c/claude_gets_the_number_70_very_wrong_funny/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228990678791858176","type":"socialMedia","url":"https://x.com/HiTw93/status/2006144267455209866","title":"I mainly use Claude Code in my daily work and recently came across cc-wrapped, a small tool that generates a yearly summary of your Claude Code usage....","description":"I mainly use Claude Code in my daily work and recently came across cc-wrapped, a small tool that generates a yearly summary of your Claude Code usage. It’s built by adapting opencode-wrapped, and gives a nice overview of how you’ve been using Claude Code over the year. If you’re a Claude Code user as well, it’s worth a try. Run it with: npx cc-wrapped [图片: https://pbs.twimg.com/media/G9QoSr6bkAA5wxc?format=jpg&#x26;name=orig]","published_date":"2025-12-30T23:24:00.008Z","authors":"Tw93","source":"twitter-Tw93","details":{"content_html":"I mainly use Claude Code in my daily work and recently came across cc-wrapped, a small tool that generates a yearly summary of your Claude Code usage.<br><br>It’s built by adapting opencode-wrapped, and gives a nice overview of how you’ve been using Claude Code over the year. If you’re a Claude Code user as well, it’s worth a try.<br><br>Run it with: npx cc-wrapped<br><img width=\"1200\" height=\"1120\" style=\"\" src=\"https://pbs.twimg.com/media/G9QoSr6bkAA5wxc?format=jpg&#x26;name=orig\">"}},{"id":"229016512015955970","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzwvws/artificial_intelligence_myths_have_existed_for/","title":"'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot","description":"[图片: 'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot https://external-preview.redd.it/PRwd6xRRA_JNo9pxNCL8AmAlq2kHlDL4W-9n2GsuF4Q.png?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=a927f096729aadb2f6c80953398f448d0aef02db] submitted by /u/Fcking_Chuck [link] [comments]","published_date":"2025-12-30T23:15:00.867Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1pzwvws/artificial_intelligence_myths_have_existed_for/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/PRwd6xRRA_JNo9pxNCL8AmAlq2kHlDL4W-9n2GsuF4Q.png?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=a927f096729aadb2f6c80953398f448d0aef02db\" alt=\"'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot\" title=\"'Artificial intelligence' myths have existed for centuries – from the ancient Greeks to a pope’s chatbot\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/Fcking_Chuck\" target=\"_blank\"> /u/Fcking_Chuck </a> <br> <span><a href=\"https://www.livescience.com/archaeology/artificial-intelligence-myths-have-existed-for-centuries-from-the-ancient-greeks-to-a-popes-chatbot\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzwvws/artificial_intelligence_myths_have_existed_for/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"228980460781893632","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzw2z8/d_what_to_learn_next_to_secure_a_ml_role_after/","title":"[D] What to learn next to secure a ML role after graduation?","description":"Hi, I'm graduating from a UK bachelor degree soon and looking to secure a job relating to machine learning or AI. I have: - 12 month internship experience working on deep learning - Covered much of the basics and fundamental architectures in my course, i.e. differentiation, supervised, unsupervised and reinforcement learning. - Architectures like MLP, RNN, LSTM, Transformer, CNN, etc are all covered as well. - Also covered diffusion models. There is a real possibility I won't get into a graduate scheme before graduation, so I'm planning ahead to apply to non-graduate roles closer to my graduation. I was wondering what else I should learn to improve my skill and/or potential in securing those non-graduate ML roles? submitted by /u/PositiveInformal9512 [link] [comments]","published_date":"2025-12-30T22:42:05.368Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>Hi, I'm graduating from a UK bachelor degree soon and looking to secure a job relating to machine learning or AI.</p> <p>I have:<br> - 12 month internship experience working on deep learning<br> - Covered much of the basics and fundamental architectures in my course, i.e. differentiation, supervised, unsupervised and reinforcement learning.</p> <p>- Architectures like MLP, RNN, LSTM, Transformer, CNN, etc are all covered as well.</p> <p>- Also covered diffusion models.</p> <p>There is a real possibility I won't get into a graduate scheme before graduation, so I'm planning ahead to apply to non-graduate roles closer to my graduation.</p> <p>I was wondering what else I should learn to improve my skill and/or potential in securing those non-graduate ML roles?</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/PositiveInformal9512\" target=\"_blank\"> /u/PositiveInformal9512 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzw2z8/d_what_to_learn_next_to_secure_a_ml_role_after/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzw2z8/d_what_to_learn_next_to_secure_a_ml_role_after/\" target=\"_blank\">[comments]</a></span>"}},{"id":"229016512015955971","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzvzxm/need_good_ai_resources/","title":"Need Good AI Resources","description":"Hey everyone, I am currently putting together a list of AI/ML resources and tools that I find helpful: chatbots, video/image creators, music creators, coding helpers, etc. It’s here if you want to see what I’ve got so far: https://top-ai-sites.com I’m 100% sure I’ve missed a ton of good stuff, so I’d love your help. If you have go-to sites for research, learning or fun (not just random AI tool spam), please drop them in the comments. I’m planning to keep updating the list and to make this more of a helpful community index than just another link list. Thanks! submitted by /u/M3ltd0wn_ [link] [comments]","published_date":"2025-12-30T22:38:21.832Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Hey everyone,</p> <p>I am currently putting together a list of AI/ML resources and tools that I find helpful: chatbots, video/image creators, music creators, coding helpers, etc. It’s here if you want to see what I’ve got so far: <a href=\"https://top-ai-sites.com\" target=\"_blank\">https://top-ai-sites.com</a></p> <p>I’m 100% sure I’ve missed a ton of good stuff, so I’d love your help.</p> <p>If you have go-to sites for research, learning or fun (not just random AI tool spam), please drop them in the comments. </p> <p>I’m planning to keep updating the list and to make this more of a helpful community index than just another link list.</p> <p>Thanks!</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/M3ltd0wn_\" target=\"_blank\"> /u/M3ltd0wn_ </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzvzxm/need_good_ai_resources/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzvzxm/need_good_ai_resources/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893633","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzvr8b/d_aiml_self_hosted_software_that_can_be_run_on/","title":"[D] AI/ML self hosted software that can be run on off the shelf cameras and detects smoke or fire?","description":"Can be deployed on a raspberry pi or similar hardware setup using consumer level cameras. No clue why the current ones like wyze/ring don't have this feature. Would be a great in my opinion. Thanks. submitted by /u/SedimentaryLife [link] [comments]","published_date":"2025-12-30T22:27:55.328Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>Can be deployed on a raspberry pi or similar hardware setup using consumer level cameras. No clue why the current ones like wyze/ring don't have this feature. Would be a great in my opinion. Thanks.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/SedimentaryLife\" target=\"_blank\"> /u/SedimentaryLife </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzvr8b/d_aiml_self_hosted_software_that_can_be_run_on/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzvr8b/d_aiml_self_hosted_software_that_can_be_run_on/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893634","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzv7bh/p_edgevec_v070_browsernative_vector_database_with/","title":"[P] EdgeVec v0.7.0: Browser-Native Vector Database with 8.75x Faster Hamming Distance via SIMD","description":"I've been building **EdgeVec**, an open-source vector database that runs entirely in the browser via WebAssembly. With v0.7.0, we're shipping significant SIMD optimizations and celebrating our first community contribution. ### What is EdgeVec? EdgeVec is a lightweight vector search engine designed for: - **Browser-based RAG applications** - Run retrieval-augmented generation without server roundtrips - **Semantic search in web apps** - Build search experiences that understand meaning, not just keywords - **Offline-first AI tools** - Your embeddings and data never leave the user's device It works with embeddings from any provider: **OpenAI** (text-embedding-3-small/large), **Cohere** (embed-english-v3), **HuggingFace** (all-MiniLM, BGE, etc.), or your own fine-tuned models. ### v0.7.0 Highlights **1. 8.75x Faster Hamming Distance (Community Contribution)** Our first external contributor [@jsonMartin]( https://github.com/jsonMartin ) implemented WASM SIMD128 Hamming distance computation. For binary-quantized vectors: | Operation | Before | After | Speedup | |:----------|:-------|:------|:--------| | Hamming Distance | 87.5 ns | 10.0 ns | **8.75x** | This uses the `v128.popcnt` instruction available in modern browsers, making binary vector search extremely fast. **2. Binary Quantization: 32x Memory Reduction** Store 1536-dim embeddings (OpenAI large) in just 48 bytes instead of 6144 bytes: - **32x memory reduction** with typical **95%+ recall retention** - Makes million-vector indices practical in browser memory - Automatic projection + binarization pipeline **3. SIMD-Accelerated Euclidean Distance (3.2x faster)** Previous release added SIMD for Euclidean/cosine, this release extends SIMD coverage: ``` Euclidean Distance (1536-dim): Scalar: ~450 ns SIMD: ~140 ns (3.2x faster) ``` ### Technical Architecture ``` +-------------------------------------------------------------+ | Your Web Application | +-------------------------------------------------------------+ | EdgeVec (WASM) | | +-- Vector Storage (flat + binary-quantized) | | +-- SIMD Kernels (f32 ops, Hamming distance) | | +-- Cosine / Euclidean / Hamming similarity | | +-- Persistence (IndexedDB via idb-keyval) | +-------------------------------------------------------------+ | Browser Runtime | | +-- WebAssembly + SIMD128 (Chrome 91+, Firefox 89+) | +-------------------------------------------------------------+ ``` ### Code Example: RAG with OpenAI Embeddings ```javascript import init, { EdgeVec, EdgeVecConfig } from 'edgevec'; // Initialize WASM await init(); // Create index for OpenAI embeddings (1536D) const config = new EdgeVecConfig(1536); const db = new EdgeVec(config); db.enableBQ(); // Enable binary quantization for 32x compression // Index your documents for (const doc of documents) { const embedding = await openai.embeddings.create({ model: 'text-embedding-3-small', input: doc.text }); db.insertWithMetadata( new Float32Array(embedding.data[0].embedding), { id: doc.id , title: doc.title } ); } // Semantic search - runs locally, no API call const queryEmbedding = await openai.embeddings.create({ model: 'text-embedding-3-small', input: userQuery }); // BQ search with rescoring for 95%+ recall const results = db.searchBQRescored( new Float32Array(queryEmbedding.data[0].embedding), 5, // k 3 // rescore_factor ); // Use top-k results for RAG context ``` ### Why Browser-Native Matters for ML Applications **Privacy**: Embeddings contain semantic information about your data. Running locally means sensitive data never leaves the device. **Latency**: Eliminate network roundtrips. Search is sub-millisecond after embeddings are computed. **Offline capability**: Applications work without internet after initial embedding computation. **Cost**: No vector database hosting costs. Users' browsers provide the compute. ### Benchmarks (100k vectors, 768-dim) | Operation | Performance | |:----------|:------------| | Insert (binary quant) | 15,000 vec/sec | | Search k=10 (binary) | 1.2ms | | Memory per vector | 48 bytes (binary) vs 3072 bytes (f32) | ### Links - **GitHub**: https://github.com/matte1782/edgevec - **Live Demo**: https://matte1782.github.io/edgevec/demo/ - **npm**: https://www.npmjs.com/package/edgevec - **Docs**: https://github.com/matte1782/edgevec#readme ### What's Next - [ ] IVF indexing for sub-linear search on large indices - [ ] Product quantization (PQ) for more compression options - [ ] Streaming insert API for real-time applications Would love feedback from the ML community, especially on: - Embedding dimension / model combinations you'd want optimized - Use cases where browser-native search would be valuable - Performance comparisons you'd like to see **License**: MIT --- ## Post Metadata - **Flair**: [P] (Project) - **Crosspost to**: r/rust , r/webdev , r/LocalLLaMA submitted by /u/Complex_Ad_148 [link] [comments]","published_date":"2025-12-30T22:04:46.681Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>I've been building **EdgeVec**, an open-source vector database that runs entirely in the browser via WebAssembly. With v0.7.0, we're shipping significant SIMD optimizations and celebrating our first community contribution.</p> <p>### What is EdgeVec?</p> <p>EdgeVec is a lightweight vector search engine designed for:</p> <p>- **Browser-based RAG applications** - Run retrieval-augmented generation without server roundtrips</p> <p>- **Semantic search in web apps** - Build search experiences that understand meaning, not just keywords</p> <p>- **Offline-first AI tools** - Your embeddings and data never leave the user's device</p> <p>It works with embeddings from any provider: **OpenAI** (text-embedding-3-small/large), **Cohere** (embed-english-v3), **HuggingFace** (all-MiniLM, BGE, etc.), or your own fine-tuned models.</p> <p>### v0.7.0 Highlights</p> <p>**1. 8.75x Faster Hamming Distance (Community Contribution)**</p> <p>Our first external contributor [@jsonMartin](<a href=\"https://github.com/jsonMartin\" target=\"_blank\">https://github.com/jsonMartin</a>) implemented WASM SIMD128 Hamming distance computation. For binary-quantized vectors:</p> <p>| Operation | Before | After | Speedup |</p> <p>|:----------|:-------|:------|:--------|</p> <p>| Hamming Distance | 87.5 ns | 10.0 ns | **8.75x** |</p> <p>This uses the `v128.popcnt` instruction available in modern browsers, making binary vector search extremely fast.</p> <p>**2. Binary Quantization: 32x Memory Reduction**</p> <p>Store 1536-dim embeddings (OpenAI large) in just 48 bytes instead of 6144 bytes:</p> <p>- **32x memory reduction** with typical **95%+ recall retention**</p> <p>- Makes million-vector indices practical in browser memory</p> <p>- Automatic projection + binarization pipeline</p> <p>**3. SIMD-Accelerated Euclidean Distance (3.2x faster)**</p> <p>Previous release added SIMD for Euclidean/cosine, this release extends SIMD coverage:</p> <p>```</p> <p>Euclidean Distance (1536-dim):</p> <p>Scalar: ~450 ns</p> <p>SIMD: ~140 ns (3.2x faster)</p> <p>```</p> <p>### Technical Architecture</p> <p>```</p> <p>+-------------------------------------------------------------+</p> <p>| Your Web Application |</p> <p>+-------------------------------------------------------------+</p> <p>| EdgeVec (WASM) |</p> <p>| +-- Vector Storage (flat + binary-quantized) |</p> <p>| +-- SIMD Kernels (f32 ops, Hamming distance) |</p> <p>| +-- Cosine / Euclidean / Hamming similarity |</p> <p>| +-- Persistence (IndexedDB via idb-keyval) |</p> <p>+-------------------------------------------------------------+</p> <p>| Browser Runtime |</p> <p>| +-- WebAssembly + SIMD128 (Chrome 91+, Firefox 89+) |</p> <p>+-------------------------------------------------------------+</p> <p>```</p> <p>### Code Example: RAG with OpenAI Embeddings</p> <p>```javascript</p> <p>import init, { EdgeVec, EdgeVecConfig } from 'edgevec';</p> <p>// Initialize WASM</p> <p>await init();</p> <p>// Create index for OpenAI embeddings (1536D)</p> <p>const config = new EdgeVecConfig(1536);</p> <p>const db = new EdgeVec(config);</p> <p>db.enableBQ(); // Enable binary quantization for 32x compression</p> <p>// Index your documents</p> <p>for (const doc of documents) {</p> <p>const embedding = await openai.embeddings.create({</p> <p>model: 'text-embedding-3-small',</p> <p>input: doc.text</p> <p>});</p> <p>db.insertWithMetadata(</p> <p>new Float32Array(embedding.data[0].embedding),</p> <p>{ id: <a href=\"http://doc.id\" target=\"_blank\">doc.id</a>, title: doc.title }</p> <p>);</p> <p>}</p> <p>// Semantic search - runs locally, no API call</p> <p>const queryEmbedding = await openai.embeddings.create({</p> <p>model: 'text-embedding-3-small',</p> <p>input: userQuery</p> <p>});</p> <p>// BQ search with rescoring for 95%+ recall</p> <p>const results = db.searchBQRescored(</p> <p>new Float32Array(queryEmbedding.data[0].embedding),</p> <p>5, // k</p> <p>3 // rescore_factor</p> <p>);</p> <p>// Use top-k results for RAG context</p> <p>```</p> <p>### Why Browser-Native Matters for ML Applications</p> <ol> <li><p>**Privacy**: Embeddings contain semantic information about your data. Running locally means sensitive data never leaves the device.</p></li> <li><p>**Latency**: Eliminate network roundtrips. Search is sub-millisecond after embeddings are computed.</p></li> <li><p>**Offline capability**: Applications work without internet after initial embedding computation.</p></li> <li><p>**Cost**: No vector database hosting costs. Users' browsers provide the compute.</p></li> </ol> <p>### Benchmarks (100k vectors, 768-dim)</p> <p>| Operation | Performance |</p> <p>|:----------|:------------|</p> <p>| Insert (binary quant) | 15,000 vec/sec |</p> <p>| Search k=10 (binary) | 1.2ms |</p> <p>| Memory per vector | 48 bytes (binary) vs 3072 bytes (f32) |</p> <p>### Links</p> <p>- **GitHub**: <a href=\"https://github.com/matte1782/edgevec\" target=\"_blank\">https://github.com/matte1782/edgevec</a></p> <p>- **Live Demo**: <a href=\"https://matte1782.github.io/edgevec/demo/\" target=\"_blank\">https://matte1782.github.io/edgevec/demo/</a></p> <p>- **npm**: <a href=\"https://www.npmjs.com/package/edgevec\" target=\"_blank\">https://www.npmjs.com/package/edgevec</a></p> <p>- **Docs**: <a href=\"https://github.com/matte1782/edgevec#readme\" target=\"_blank\">https://github.com/matte1782/edgevec#readme</a></p> <p>### What's Next</p> <p>- [ ] IVF indexing for sub-linear search on large indices</p> <p>- [ ] Product quantization (PQ) for more compression options</p> <p>- [ ] Streaming insert API for real-time applications</p> <p>Would love feedback from the ML community, especially on:</p> <p>- Embedding dimension / model combinations you'd want optimized</p> <p>- Use cases where browser-native search would be valuable</p> <p>- Performance comparisons you'd like to see</p> <p>**License**: MIT</p> <p>---</p> <p>## Post Metadata</p> <p>- **Flair**: [P] (Project)</p> <p>- **Crosspost to**: <a href=\"/r/rust\" target=\"_blank\">r/rust</a>, <a href=\"/r/webdev\" target=\"_blank\">r/webdev</a>, <a href=\"/r/LocalLLaMA\" target=\"_blank\">r/LocalLLaMA</a></p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Complex_Ad_148\" target=\"_blank\"> /u/Complex_Ad_148 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzv7bh/p_edgevec_v070_browsernative_vector_database_with/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzv7bh/p_edgevec_v070_browsernative_vector_database_with/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228957449693493248","type":"socialMedia","url":"https://x.com/oran_ge/status/2006122179390238869","title":"在今年的最后一天，苹果审核终于通过了 从圣诞节等到今天 新版本卡审核卡了四天 今天终于审核通过了 以后手机也可以随手生图了 今年的最后一件事情也圆满了 感谢...","description":"在今年的最后一天，苹果审核终于通过了 从圣诞节等到今天 新版本卡审核卡了四天 今天终于审核通过了 以后手机也可以随手生图了 今年的最后一件事情也圆满了 感谢大家一年的支持 让我们一起辞旧迎新 [图片: https://pbs.twimg.com/media/G9ctfG9aEAAUKg-?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G9ctfG-aYAEWmEr?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G9ctfG-aYAIsHGE?format=jpg&#x26;name=orig]","published_date":"2025-12-30T21:56:14.725Z","authors":"Orange AI","source":"twitter-Orange AI","details":{"content_html":"在今年的最后一天，苹果审核终于通过了<br>从圣诞节等到今天<br>新版本卡审核卡了四天<br>今天终于审核通过了<br>以后手机也可以随手生图了<br>今年的最后一件事情也圆满了<br>感谢大家一年的支持<br>让我们一起辞旧迎新<br><img width=\"1073\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9ctfG9aEAAUKg-?format=jpg&#x26;name=orig\"><br><img width=\"1035\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9ctfG-aYAEWmEr?format=jpg&#x26;name=orig\"><br><img width=\"1089\" height=\"2048\" style=\"\" src=\"https://pbs.twimg.com/media/G9ctfG-aYAIsHGE?format=jpg&#x26;name=orig\">"}},{"id":"228969538600368128","type":"socialMedia","url":"https://x.com/raizamrtn/status/2006110397498314880","title":"Last week I demo'd Gemini Live to a bunch of non-tech people in my family. We used the video call option and I asked it to show me how to operate mult...","description":"Last week I demo'd Gemini Live to a bunch of non-tech people in my family. We used the video call option and I asked it to show me how to operate multiple electronics in my parents' house. Immediately, almost everyone had an example of when they would use something like this. It was instant product-market fit. It was a 15-second demo, tops. The funny part is that most people didn't know AI could do this, not to mention that it's pretty unintuitive to get to Gemini Live in the app. All of 2025 we kept saying we'd see new surfaces for AI that really showcase the strength of the models, but we still mostly rely on others to show us what's working well and that's what we know as \"AI.\" All these models have so much to offer - still buried under a chat UX!","published_date":"2025-12-30T21:09:25.180Z","authors":"Raiza Martin","source":"twitter-Raiza Martin","details":{"content_html":"Last week I demo'd Gemini Live to a bunch of non-tech people in my family. We used the video call option and I asked it to show me how to operate multiple electronics in my parents' house. <br><br>Immediately, almost everyone had an example of when they would use something like this. It was instant product-market fit.<br><br>It was a 15-second demo, tops.<br><br>The funny part is that most people didn't know AI could do this, not to mention that it's pretty unintuitive to get to Gemini Live in the app.<br><br>All of 2025 we kept saying we'd see new surfaces for AI that really showcase the strength of the models, but we still mostly rely on others to show us what's working well and that's what we know as \"AI.\"<br><br>All these models have so much to offer - still buried under a chat UX!"}},{"id":"228980460781893635","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pztniz/n_acl_2026_arr_jan_2026_no_rebuttal_period/","title":"[N] ACL 2026 (ARR Jan 2026), No Rebuttal period?","description":"I noticed that there is no rebuttal and discussion period in ARR Jan 2026 cycle. It seems like we will directly get reviews and the meta reviewer score and make a decision to commit to ACL 2026. From my past experience with ARR cycles reviewers have mostly not responded to the rebuttal let alone increase the score. submitted by /u/Healthy_Horse_2183 [link] [comments]","published_date":"2025-12-30T21:01:26.869Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>I noticed that there is no rebuttal and discussion period in ARR Jan 2026 cycle. It seems like we will directly get reviews and the meta reviewer score and make a decision to commit to ACL 2026. From my past experience with ARR cycles reviewers have mostly not responded to the rebuttal let alone increase the score.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Healthy_Horse_2183\" target=\"_blank\"> /u/Healthy_Horse_2183 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pztniz/n_acl_2026_arr_jan_2026_no_rebuttal_period/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pztniz/n_acl_2026_arr_jan_2026_no_rebuttal_period/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228980460781893636","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzsx3i/p_topasdspl_a_15m_param_dualstream_recursive/","title":"[P] TOPAS-DSPL: A 15M param Dual-Stream Recursive Transformer achieving 24% on ARC-2","description":"Abstract: We have released the code and weights for TOPAS-DSPL , a neuro-symbolic baseline designed to test the efficacy of \"Bicameral\" latent spaces in small-scale reasoning models. By separating algorithmic planning ( Logic Stream ) from execution state ( Canvas Stream ) via Dynamic AdaLN conditioning, we observed a reduction in \"Compositional Drift\" compared to monolithic recursive models (e.g., TRM). Experimental Results: Benchmark: ARC-AGI-2 Evaluation Set Accuracy: 24% (Exact Match) Baseline Comparison: ~3x improvement over standard Tiny Recursive Models (~8%). Parameter Count: ~15M (Consumer hardware accessible) Methodology: The architecture addresses the \"forgetting\" problem in recursive loops by functionally decoupling the rule generation from the state update. The Logic Stream acts as a controller, modulating the Canvas Stream's weights at each timestep. We utilized Test-Time Training (TTT) for instance-specific adaptation and MuonClip for optimization stability. Reproduction: We have open-sourced the full training pipeline, data augmentation scripts, and evaluation harness to allow for independent verification of these results. We (Bitterbot AI) are very excited about this and I'll just say, one of the many reasons is because this is actually are least accurate and efficient model - this is the one we are comfortable open sourcing with the public. But we have already achieved MUCH more. I do not want this to be flagged for self promotion or spam so I will add a link to our repo (code) and paper below. submitted by /u/Doug_Bitterbot [link] [comments]","published_date":"2025-12-30T20:31:28.710Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p><strong>Abstract:</strong> We have released the code and weights for <strong>TOPAS-DSPL</strong>, a neuro-symbolic baseline designed to test the efficacy of \"Bicameral\" latent spaces in small-scale reasoning models.</p> <p>By separating algorithmic planning (<strong>Logic Stream</strong>) from execution state (<strong>Canvas Stream</strong>) via Dynamic AdaLN conditioning, we observed a reduction in \"Compositional Drift\" compared to monolithic recursive models (e.g., TRM).</p> <p><strong>Experimental Results:</strong></p> <ul> <li><strong>Benchmark:</strong> ARC-AGI-2 Evaluation Set</li> <li><strong>Accuracy:</strong> 24% (Exact Match)</li> <li><strong>Baseline Comparison:</strong> ~3x improvement over standard Tiny Recursive Models (~8%).</li> <li><strong>Parameter Count:</strong> ~15M (Consumer hardware accessible)</li> </ul> <p><strong>Methodology:</strong> The architecture addresses the \"forgetting\" problem in recursive loops by functionally decoupling the rule generation from the state update. The Logic Stream acts as a controller, modulating the Canvas Stream's weights at each timestep. We utilized <strong>Test-Time Training (TTT)</strong> for instance-specific adaptation and <strong>MuonClip</strong> for optimization stability.</p> <p><strong>Reproduction:</strong> We have open-sourced the full training pipeline, data augmentation scripts, and evaluation harness to allow for independent verification of these results.</p> <p>We (Bitterbot AI) are very excited about this and I'll just say, one of the many reasons is because this is actually are least accurate and efficient model - this is the one we are comfortable open sourcing with the public. But we have already achieved MUCH more.</p> <p>I do not want this to be flagged for self promotion or spam so I will add a link to our repo (code) and paper below.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Doug_Bitterbot\" target=\"_blank\"> /u/Doug_Bitterbot </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzsx3i/p_topasdspl_a_15m_param_dualstream_recursive/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzsx3i/p_topasdspl_a_15m_param_dualstream_recursive/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228931745616209920","type":"socialMedia","url":"https://x.com/dotey/status/2006087115537575997","title":"一个是看内容对目标受众提供的价值，情绪价值或者知识价值 一个是看发布内容的人","description":"一个是看内容对目标受众提供的价值，情绪价值或者知识价值 一个是看发布内容的人 大罗SEO: 从内容创作者的角度来思考，在AI 支持下内容生产越来越容易的未来，什么样的内容真正能够得到目标受众的注意？","published_date":"2025-12-30T19:36:54.895Z","authors":"宝玉","source":"twitter-宝玉","details":{"content_html":"一个是看内容对目标受众提供的价值，情绪价值或者知识价值<br>一个是看发布内容的人<div><br><br>大罗SEO: 从内容创作者的角度来思考，在AI 支持下内容生产越来越容易的未来，什么样的内容真正能够得到目标受众的注意？<br></div>"}},{"id":"228980460781893637","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzrfbf/p_the_state_of_llms_2025_progress_problems_and/","title":"[P] The State Of LLMs 2025: Progress, Problems, and Predictions","description":"[图片: [P] The State Of LLMs 2025: Progress, Problems, and Predictions https://external-preview.redd.it/ip3t1phQ469yOBa2kbOD__RHIhAqj8C7dU-KA_Pn0lI.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=859212246454f6bb28f9d882875d0a6ae9694d87] submitted by /u/seraschka [link] [comments]","published_date":"2025-12-30T19:33:26.793Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzrfbf/p_the_state_of_llms_2025_progress_problems_and/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/ip3t1phQ469yOBa2kbOD__RHIhAqj8C7dU-KA_Pn0lI.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=859212246454f6bb28f9d882875d0a6ae9694d87\" alt=\"[P] The State Of LLMs 2025: Progress, Problems, and Predictions\" title=\"[P] The State Of LLMs 2025: Progress, Problems, and Predictions\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/seraschka\" target=\"_blank\"> /u/seraschka </a> <br> <span><a href=\"https://magazine.sebastianraschka.com/p/state-of-llms-2025\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzrfbf/p_the_state_of_llms_2025_progress_problems_and/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"228933042865666048","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzqr9e/alexa_ai_overreach/","title":"Alexa+ AI overreach","description":"Normally I'm not one to make a big deal about overly-intrusive AI. Google putting AI summary at the top of the search order? Meh, sometimes a useful synopsis, sometimes just something to scroll past along with sponsored results. Copilot putting up little notifications encouraging me to use AI? Annoying, but you can click the X or just ignore them. Amazon took it a step further, and this one grinds my gears. My Echo Show 8 started plugging Alexa+ at the end of responses or on the screen a couple months ago, and it was a few weeks before the advertising confirmed my suspicion that it was an AI platform. Whatever, I didn't want it enough to opt in and ignored the advertising. Then it integrated the AI without an opt-in. Again, I rolled my eyes at the slightly more talkative software. It was slightly better at getting my song requests right so I didn't mind. Here's the line in the sand for me. You know how ChatGPT is known for asking questions at the end of responses to prompt more user feedback? My Echo cues up the mic after it responds to instructions. Play a playlist, add an item to the shopping list, read the day's weather? The echo responds, then turns on the mic again. I've yelled at it to shut up or stop prompting for more input and it just gives a snarky response. I'm not one to say \"oh my god they're spying on you,\" but this is REALLY intrusive. To me, this is AI overreach. submitted by /u/DrunkenBandit1 [link] [comments]","published_date":"2025-12-30T19:07:45.339Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Normally I'm not one to make a big deal about overly-intrusive AI. Google putting AI summary at the top of the search order? Meh, sometimes a useful synopsis, sometimes just something to scroll past along with sponsored results. Copilot putting up little notifications encouraging me to use AI? Annoying, but you can click the X or just ignore them.</p> <p>Amazon took it a step further, and this one grinds my gears. </p> <p>My Echo Show 8 started plugging Alexa+ at the end of responses or on the screen a couple months ago, and it was a few weeks before the advertising confirmed my suspicion that it was an AI platform. Whatever, I didn't want it enough to opt in and ignored the advertising.</p> <p>Then it integrated the AI without an opt-in. Again, I rolled my eyes at the slightly more talkative software. It was slightly better at getting my song requests right so I didn't mind. </p> <p>Here's the line in the sand for me. You know how ChatGPT is known for asking questions at the end of responses to prompt more user feedback? </p> <p>My Echo cues up the mic after it responds to instructions. Play a playlist, add an item to the shopping list, read the day's weather? The echo responds, then turns on the mic again. I've yelled at it to shut up or stop prompting for more input and it just gives a snarky response. </p> <p>I'm not one to say \"oh my god they're spying on you,\" but this is REALLY intrusive. To me, this is AI overreach. </p> </div>   submitted by   <a href=\"https://www.reddit.com/user/DrunkenBandit1\" target=\"_blank\"> /u/DrunkenBandit1 </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqr9e/alexa_ai_overreach/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqr9e/alexa_ai_overreach/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228933042865666049","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzqa9z/my_son_and_i_vibecoded_our_first_game_called/","title":"My son and I vibecoded our first game called SUPERSNAKES using Gemini","description":"Using Google's Antigravity with the help of Gemini 3 pro and a bit of Claude my son and I created our first game called SUPERSNAKES. You can play for free at: https://supersnakes.io/ It's a spin-off from the popular IO snake game genre. But rather than just cutting off snakes, this game contains a few extra features. Pickup power-up elements on the playfield to get upgrades, but watch out for the bombs. Every minute a boss snake spawns which you can only kill with a gun. Pickup a gun from the playing field when a boss as active to try and kill it. Unlock skins by getting more points, and boss skins by killing them. It took about 3-4 weeks of vibecoding to get where we are now. submitted by /u/RealMrBoon [link] [comments]","published_date":"2025-12-30T18:50:18.371Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Using Google's Antigravity with the help of Gemini 3 pro and a bit of Claude my son and I created our first game called SUPERSNAKES.</p> <p>You can play for free at: <a href=\"https://supersnakes.io/\" target=\"_blank\">https://supersnakes.io/</a></p> <p>It's a spin-off from the popular IO snake game genre. But rather than just cutting off snakes, this game contains a few extra features. Pickup power-up elements on the playfield to get upgrades, but watch out for the bombs.</p> <p>Every minute a boss snake spawns which you can only kill with a gun. Pickup a gun from the playing field when a boss as active to try and kill it.</p> <p>Unlock skins by getting more points, and boss skins by killing them.</p> <p>It took about 3-4 weeks of vibecoding to get where we are now.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/RealMrBoon\" target=\"_blank\"> /u/RealMrBoon </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqa9z/my_son_and_i_vibecoded_our_first_game_called/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzqa9z/my_son_and_i_vibecoded_our_first_game_called/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228901489340335104","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzq50l/r_new_ssm_architecture_exceeds_transformer/","title":"[R] New SSM architecture (exceeds Transformer baseline) - reproducible benchmarks (feedback wanted)","description":"Transformers have revolutionized natural language processing, but their O(L^2) complexity limits their applicability to very long sequences. Recent advances in SSMs and Linear Attention have proposed O(L) alternatives. This new SSM contributes to this line of work by combining the ability of delta-rule updates with the representational power of gated convolutions. You can reproduce the results and find more information here (github): exponentialXP/GDN: Gated Delta Networks as a novel sequence modelling architecture with O(n) complexity and is a strong baseline. This new SSM exceeds our transformer baseline's speed and performance/loss significantly at even relatively small sequence lengths, with mildly optimised triton kernels. I need your help - please suggest ways to improve this architecture! submitted by /u/Otherwise-Desk5672 [link] [comments]","published_date":"2025-12-30T18:44:54.408Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p><a href=\"https://www.reddit.com/r/MachineLearning/?f=flair_name%3A%22Discussion%22\" target=\"_blank\"></a>Transformers have revolutionized natural language processing, but their O(L^2) complexity limits their applicability to very long sequences. Recent advances in SSMs and Linear Attention have proposed O(L) alternatives. This new SSM contributes to this line of work by combining the ability of delta-rule updates with the representational power of gated convolutions.</p> <p>You can reproduce the results and find more information here (github): <a href=\"https://github.com/exponentialXP/GDN\" target=\"_blank\">exponentialXP/GDN: Gated Delta Networks as a novel sequence modelling architecture with O(n) complexity and is a strong baseline.</a></p> <p>This new SSM exceeds our transformer baseline's speed and performance/loss significantly at even relatively small sequence lengths, with mildly optimised triton kernels.</p> <p>I need your help - please suggest ways to improve this architecture!</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/Otherwise-Desk5672\" target=\"_blank\"> /u/Otherwise-Desk5672 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzq50l/r_new_ssm_architecture_exceeds_transformer/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzq50l/r_new_ssm_architecture_exceeds_transformer/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228933042865666050","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pznrz8/tencent_hymotion_10_a_billionparameter/","title":"Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model","description":"[图片: Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model https://preview.redd.it/yq8uriwhxaag1.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=d990cf5383783b3e2aa22351ddeb29ebac5eb2b2] submitted by /u/jferments [link] [comments]","published_date":"2025-12-30T17:16:24.018Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1pznrz8/tencent_hymotion_10_a_billionparameter/\" target=\"_blank\"> <img src=\"https://preview.redd.it/yq8uriwhxaag1.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=d990cf5383783b3e2aa22351ddeb29ebac5eb2b2\" alt=\"Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model\" title=\"Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/jferments\" target=\"_blank\"> /u/jferments </a> <br> <span><a href=\"https://i.redd.it/yq8uriwhxaag1.jpeg\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pznrz8/tencent_hymotion_10_a_billionparameter/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}},{"id":"228901489340335105","type":"socialMedia","url":"https://www.reddit.com/r/MachineLearning/comments/1pzndfo/d_phd_parttime_remotely_in_mldl/","title":"[D] PhD part-time remotely in ML/DL?","description":"Hello, so basically I am full-time working, but I am interested in doing a PhD in Applied AI, basically in argument mining, and I am interested to see if there are chances in Europe or elsewhere to do it on a part-time basis while working in Europe. I have a masters in Applied AI, that is industrial oriented and thus can't pursue a PhD with in France, but outside it is possible, any programs you know of, cheap and flexible ? Thanks submitted by /u/jiii95 [link] [comments]","published_date":"2025-12-30T17:01:06.718Z","authors":"","source":"newest submissions : MachineLearning","details":{"content_html":"<div><p>Hello, so basically I am full-time working, but I am interested in doing a PhD in Applied AI, basically in argument mining, and I am interested to see if there are chances in Europe or elsewhere to do it on a part-time basis while working in Europe. I have a masters in Applied AI, that is industrial oriented and thus can't pursue a PhD with in France, but outside it is possible, any programs you know of, cheap and flexible ? Thanks</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/jiii95\" target=\"_blank\"> /u/jiii95 </a> <br> <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzndfo/d_phd_parttime_remotely_in_mldl/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/MachineLearning/comments/1pzndfo/d_phd_parttime_remotely_in_mldl/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228933042865666051","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzlda5/its_been_a_big_week_for_ai_here_are_10_massive/","title":"It's been a big week for AI ; Here are 10 massive updates you might've missed:","description":"Nvidia acquires Groq in largest deal on record OpenAI hiring for critical safety role Your 2025 ChatGPT Wrapped is here A collection of AI Updates! 🧵 1. OpenAI Launches \"Your Year with ChatGPT\" Wrapped Rolling out to US, UK, Canada, New Zealand, and Australia users with saved memory and chat history enabled. Access via updated app or ask \"show me my year with ChatGPT.\" ChatGPT gets Spotify Wrapped-style recap. 2. Groq Licenses Inference Technology to Nvidia Non-exclusive agreement for Groq's inference tech. Founder Jonathan Ross and President Sunny Madra joining Nvidia with other team members. Groq stays independent under new CEO Simon Edwards. GroqCloud continues operating. Major AI inference technology consolidation. 3. OpenAI Hiring Head of Preparedness for Model Safety Sam Altman said: Models now are finding critical security vulnerabilities and presenting mental health challenges. Role will tackle enabling defenders while preventing attacker abuse, biological capabilities, and self-improving systems. \"Stressful job, deep end immediately.\" AI safety becoming an urgent priority. 4. MiniMax AI Releases M2.1 Open-Source Coding Model 10B-activated model scores 72.5% on SWE-multilingual, 88.6% on VIBE-bench. Exceeds Gemini 3 Pro and Claude 4.5 Sonnet. Built for real-world coding and AI-native organizations. Most powerful open-source model for agentic era. 5. ManusAI Launches Design View with Mark Tool New way to close design gap between vision and final image. Use Mark Tool to show exactly where to make changes instead of wrestling with prompts. Granular control over image generation. Visual editing replaces text prompts. 6. Liquid AI Releases Alleged “Strongest 3B Model on Market” LFM2-2.6B-Exp built with pure reinforcement learning. Outperforms other 3B models in instruction following, knowledge, and math. IFBench score surpasses DeepSeek R1-0528 (263x larger). Now available on Hugging Face. Have yet to try it myself. 7. Typeless Launches AI Voice Keyboard for iOS Turns speech into polished writing 4x faster than typing. Speak naturally to write and edit across all apps - WhatsApp, Slack, Mail, Notes. Works in 100+ languages with privacy protection. Native communication seems to be a bigger player in AI day by day. 8. Codex Launches GPT-5.2-Codex-XMas Holiday Model Christmas-themed model from the Codex team. Performs same as GPT-5.2-Codex with festive personality upgrade. \"Enjoy coding with Santa Codex!\" Seasonal LLM model drop. 9. SoftBank Acquires DigitalBridge for $4B to Scale AI Infrastructure $3B equity purchase ($4B enterprise value) at 65% premium. DigitalBridge invests in data centers and cell towers. SoftBank gaining exposure to AI infrastructure boom. Massive bet on AI data center infrastructure. 10. Nvidia Releases NitroGen Gaming AI Foundation Model Universal simulator covering 1,000+ game titles. Trained to play 1,000+ games with access to 40K hours of gameplay. Built using large-scale behavior cloning. Open foundation model for generalist gaming agents. AI now trained on gaming at scale. That's a wrap on this week's AI news. Which update impacts you the most? Anything else you want to see? LMK if this was helpful | More weekly AI + Agentic content releasing ever week! submitted by /u/SolanaDeFi [link] [comments]","published_date":"2025-12-30T15:44:24.827Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><ul> <li>Nvidia acquires Groq in largest deal on record</li> <li>OpenAI hiring for critical safety role</li> <li>Your 2025 ChatGPT Wrapped is here</li> </ul> <p>A collection of AI Updates! 🧵</p> <p><strong>1. OpenAI Launches \"Your Year with ChatGPT\" Wrapped</strong></p> <p>Rolling out to US, UK, Canada, New Zealand, and Australia users with saved memory and chat history enabled. Access via updated app or ask \"show me my year with ChatGPT.\"</p> <p>ChatGPT gets Spotify Wrapped-style recap.</p> <p><strong>2. Groq Licenses Inference Technology to Nvidia</strong></p> <p>Non-exclusive agreement for Groq's inference tech. Founder Jonathan Ross and President Sunny Madra joining Nvidia with other team members. Groq stays independent under new CEO Simon Edwards. GroqCloud continues operating.</p> <p>Major AI inference technology consolidation.</p> <p><strong>3. OpenAI Hiring Head of Preparedness for Model Safety</strong></p> <p>Sam Altman said: Models now are finding critical security vulnerabilities and presenting mental health challenges. Role will tackle enabling defenders while preventing attacker abuse, biological capabilities, and self-improving systems. \"Stressful job, deep end immediately.\"</p> <p>AI safety becoming an urgent priority.</p> <p><strong>4. MiniMax AI Releases M2.1 Open-Source Coding Model</strong></p> <p>10B-activated model scores 72.5% on SWE-multilingual, 88.6% on VIBE-bench. Exceeds Gemini 3 Pro and Claude 4.5 Sonnet. Built for real-world coding and AI-native organizations.</p> <p>Most powerful open-source model for agentic era.</p> <p><strong>5. ManusAI Launches Design View with Mark Tool</strong></p> <p>New way to close design gap between vision and final image. Use Mark Tool to show exactly where to make changes instead of wrestling with prompts. Granular control over image generation.</p> <p>Visual editing replaces text prompts.</p> <p><strong>6. Liquid AI Releases Alleged “Strongest 3B Model on Market”</strong></p> <p>LFM2-2.6B-Exp built with pure reinforcement learning. Outperforms other 3B models in instruction following, knowledge, and math. IFBench score surpasses DeepSeek R1-0528 (263x larger). Now available on Hugging Face.</p> <p>Have yet to try it myself.</p> <p><strong>7. Typeless Launches AI Voice Keyboard for iOS</strong></p> <p>Turns speech into polished writing 4x faster than typing. Speak naturally to write and edit across all apps - WhatsApp, Slack, Mail, Notes. Works in 100+ languages with privacy protection.</p> <p>Native communication seems to be a bigger player in AI day by day.</p> <p><strong>8. Codex Launches GPT-5.2-Codex-XMas Holiday Model</strong></p> <p>Christmas-themed model from the Codex team. Performs same as GPT-5.2-Codex with festive personality upgrade. \"Enjoy coding with Santa Codex!\"</p> <p>Seasonal LLM model drop.</p> <p><strong>9. SoftBank Acquires DigitalBridge for $4B to Scale AI Infrastructure</strong></p> <p>$3B equity purchase ($4B enterprise value) at 65% premium. DigitalBridge invests in data centers and cell towers. SoftBank gaining exposure to AI infrastructure boom.</p> <p>Massive bet on AI data center infrastructure.</p> <p><strong>10. Nvidia Releases NitroGen Gaming AI Foundation Model</strong></p> <p>Universal simulator covering 1,000+ game titles. Trained to play 1,000+ games with access to 40K hours of gameplay. Built using large-scale behavior cloning. Open foundation model for generalist gaming agents.</p> <p>AI now trained on gaming at scale.</p> <p><strong>That's a wrap on this week's AI news.</strong></p> <p>Which update impacts you the most? Anything else you want to see?</p> <p>LMK if this was helpful | More weekly AI + Agentic content releasing ever week!</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/SolanaDeFi\" target=\"_blank\"> /u/SolanaDeFi </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzlda5/its_been_a_big_week_for_ai_here_are_10_massive/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzlda5/its_been_a_big_week_for_ai_here_are_10_massive/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228849571790095360","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzkdf1/training_ai_coscientists_using_rubric_rewards/","title":"Training AI Co-Scientists using Rubric Rewards","description":"Research released today by Meta: A general, scalable recipe to train AI to assist scientists in achieving their open-ended research goals: Extract research goals and goal-specific grading rubrics from the large corpus of existing scientific papers with an LLM, and use them for RL training. Reward plans generated during training with self-grading by the initial model, which is provided the rubrics to create a generator-verifier gap. Finetuning Qwen3-30B with self-grading leads to improved research plans according to human experts for 70% research goals in Machine Learning. The 30B model matches Grok-4-Thinking, though GPT-5-Thinking is a cut above the rest. OpenAI models really capable of accelerating science! The paper also shows significant cross-domain generalization as evidence for the vision of generalist AI co-scientists. submitted by /u/logisbase2 [link] [comments]","published_date":"2025-12-30T15:04:37.295Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p>Research released today by Meta: A general, scalable recipe to train AI to assist scientists in achieving their open-ended research goals:</p> <ol> <li><p>Extract research goals and goal-specific grading rubrics from the large corpus of existing scientific papers with an LLM, and use them for RL training. </p></li> <li><p>Reward plans generated during training with self-grading by the initial model, which is provided the rubrics to create a generator-verifier gap.</p></li> </ol> <p>Finetuning Qwen3-30B with self-grading leads to improved research plans according to human experts for 70% research goals in Machine Learning. The 30B model matches Grok-4-Thinking, though GPT-5-Thinking is a cut above the rest. </p> <p>OpenAI models really capable of accelerating science! The paper also shows significant cross-domain generalization as evidence for the vision of generalist AI co-scientists.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/logisbase2\" target=\"_blank\"> /u/logisbase2 </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzkdf1/training_ai_coscientists_using_rubric_rewards/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzkdf1/training_ai_coscientists_using_rubric_rewards/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228849571790095361","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzjryg/the_gate_of_coherence/","title":"The Gate of Coherence","description":"Why some users think AI is shallow — and others don’t Full essay here: https://sphill33.substack.com/p/the-gate-of-coherence Why do some people find AI shallow and limited, while others experience something startlingly deep? The usual explanations don’t account for the gap. This essay explores a less comfortable possibility: the quality of attention you bring determines the quality of intelligence you meet. Coherence unlocks depth; fragmentation guarantees flatness. And coherence, it turns out, is difficult to distinguish from ethical maturity. I examine how coherence works, why it so closely parallels ethical development, and how two users can speak to the same model and walk away convinced they met entirely different minds. submitted by /u/SusanHill33 [link] [comments]","published_date":"2025-12-30T14:39:58.754Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<div><p><em>Why some users think AI is shallow — and others don’t</em></p> <p>Full essay here: <a href=\"https://sphill33.substack.com/p/the-gate-of-coherence\" target=\"_blank\">https://sphill33.substack.com/p/the-gate-of-coherence</a></p> <p>Why do some people find AI shallow and limited, while others experience something startlingly deep? </p> <p>The usual explanations don’t account for the gap. This essay explores a less comfortable possibility: the quality of attention you bring determines the quality of intelligence you meet. </p> <p>Coherence unlocks depth; fragmentation guarantees flatness. And coherence, it turns out, is difficult to distinguish from ethical maturity. </p> <p>I examine how coherence works, why it so closely parallels ethical development, and how two users can speak to the same model and walk away convinced they met entirely different minds.</p> </div>   submitted by   <a href=\"https://www.reddit.com/user/SusanHill33\" target=\"_blank\"> /u/SusanHill33 </a> <br> <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzjryg/the_gate_of_coherence/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzjryg/the_gate_of_coherence/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228849571790095362","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzjlmx/are_you_a_superrecognizer_ai_faces_are_harder/","title":"Are You a Super-Recognizer? AI Faces Are Harder Than Ever to Identify","description":"submitted by /u/chusskaptaan [link] [comments]","published_date":"2025-12-30T14:32:43.168Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"submitted by   <a href=\"https://www.reddit.com/user/chusskaptaan\" target=\"_blank\"> /u/chusskaptaan </a> <br> <span><a href=\"https://www.extremetech.com/science/are-you-a-super-recognizer-ai-faces-are-harder-than-ever-to-identify\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzjlmx/are_you_a_superrecognizer_ai_faces_are_harder/\" target=\"_blank\">[comments]</a></span>"}},{"id":"228849571790095363","type":"socialMedia","url":"https://www.reddit.com/r/artificial/comments/1pzjjmj/generative_ai_growth_vs_mobile_vs_internet/","title":"Generative AI Growth vs Mobile vs Internet","description":"[图片: Generative AI Growth vs Mobile vs Internet https://external-preview.redd.it/1DNy7uqddG-HrGqsxih7L-maKm0XvpfLUzEkfEDzgng.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=413e39675f40f7f108e9a7314d64f7423685dcc6] submitted by /u/robauto-dot-ai [link] [comments]","published_date":"2025-12-30T14:30:29.932Z","authors":"","source":"newest submissions : artificial","details":{"content_html":"<table> <tbody><tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1pzjjmj/generative_ai_growth_vs_mobile_vs_internet/\" target=\"_blank\"> <img src=\"https://external-preview.redd.it/1DNy7uqddG-HrGqsxih7L-maKm0XvpfLUzEkfEDzgng.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=413e39675f40f7f108e9a7314d64f7423685dcc6\" alt=\"Generative AI Growth vs Mobile vs Internet\" title=\"Generative AI Growth vs Mobile vs Internet\"> </a> </td><td>   submitted by   <a href=\"https://www.reddit.com/user/robauto-dot-ai\" target=\"_blank\"> /u/robauto-dot-ai </a> <br> <span><a href=\"https://robauto.ai/generative-ai-growth-vs-mobile-vs-internet/\" target=\"_blank\">[link]</a></span>   <span><a href=\"https://www.reddit.com/r/artificial/comments/1pzjjmj/generative_ai_growth_vs_mobile_vs_internet/\" target=\"_blank\">[comments]</a></span> </td></tr></tbody></table>"}}]